Not using distributed mode
Namespace(R_threshold=0.5, aa='rand-m9-mstd0.5-inc1', arch='deit_base', batch_size=128, classifiers=[10], clip_grad=None, color_jitter=0.4, cooldown_epochs=10, cutmix=1.0, cutmix_minmax=None, data_path='../data/', data_set='CIFAR10', decay_rate=0.1, device='cuda', dist_eval=False, dist_url='env://', distill=False, distillation_alpha=0.5, distillation_tau=1.0, distillation_type='none', distributed=False, drop=0.0, drop_path=0.1, epochs=100, eval=False, finetune='', inat_category='name', input_size=224, lr=0.0005, lr_noise=None, lr_noise_pct=0.67, lr_noise_std=1.0, lr_pruner=0.0025, min_lr=1e-05, mixup=0.8, mixup_mode='batch', mixup_prob=1.0, mixup_switch_prob=0.5, model_ema=True, model_ema_decay=0.99996, model_ema_force_cpu=False, model_path='./checkpoint/deit_small_distilled_patch16_224-649709d9.pth', momentum=0.9, num_workers=10, opt='adamw', opt_betas=None, opt_eps=1e-08, output_dir='/cifar', patience_epochs=10, pin_mem=True, recount=1, remode='pixel', repeated_aug=True, reprob=0.25, resplit=False, resume='', save_epoch=0, sched='cosine', seed=0, smoothing=0.1, start_epoch=0, teacher_model='regnety_160', teacher_path='', train_interpolation='bicubic', warmup_epochs=0, warmup_lr=1e-06, weight_decay=0.05, world_size=1)
2022-12-18 05:31:01.313804: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.
Files already downloaded and verified
Files already downloaded and verified
using stride: 16, and patch number is num_y14 * num_x14
using drop_out rate is : 0.0
using attn_drop_out rate is : 0.0
using drop_path rate is : 0.1
number of params: 85871060
Start training for 100 epochs
## Using lr  0.0001250 for BACKBONE, cosine lr = 0.0025000 for PRUNER
Epoch: [0]  [  0/390]  eta: 1:06:41  lr: 0.000125  loss: 4.8002 (4.8002)  time: 10.2609  data: 1.8037  max mem: 13475
Epoch: [0]  [ 10/390]  eta: 0:07:29  lr: 0.000125  loss: 27.2923 (31.1626)  time: 1.1825  data: 0.1642  max mem: 14471
Epoch: [0]  [ 20/390]  eta: 0:04:37  lr: 0.000125  loss: 64.2220 (66.5108)  time: 0.2745  data: 0.0003  max mem: 14471
Epoch: [0]  [ 30/390]  eta: 0:03:35  lr: 0.000125  loss: 139.0891 (103.1833)  time: 0.2757  data: 0.0003  max mem: 14471
Epoch: [0]  [ 40/390]  eta: 0:03:01  lr: 0.000125  loss: 213.2993 (140.1723)  time: 0.2761  data: 0.0003  max mem: 14471
Epoch: [0]  [ 50/390]  eta: 0:02:40  lr: 0.000125  loss: 288.4734 (177.3515)  time: 0.2758  data: 0.0003  max mem: 14471
Epoch: [0]  [ 60/390]  eta: 0:02:24  lr: 0.000125  loss: 363.7849 (214.5962)  time: 0.2752  data: 0.0003  max mem: 14471
Epoch: [0]  [ 70/390]  eta: 0:02:13  lr: 0.000125  loss: 438.2833 (251.8815)  time: 0.2756  data: 0.0003  max mem: 14471
Epoch: [0]  [ 80/390]  eta: 0:02:03  lr: 0.000125  loss: 513.0593 (289.2450)  time: 0.2769  data: 0.0004  max mem: 14471
Epoch: [0]  [ 90/390]  eta: 0:01:55  lr: 0.000125  loss: 587.8920 (326.6266)  time: 0.2756  data: 0.0004  max mem: 14471
Epoch: [0]  [100/390]  eta: 0:01:48  lr: 0.000125  loss: 663.6923 (364.0493)  time: 0.2751  data: 0.0003  max mem: 14471
Epoch: [0]  [110/390]  eta: 0:01:42  lr: 0.000125  loss: 738.4634 (401.4617)  time: 0.2763  data: 0.0003  max mem: 14471
Epoch: [0]  [120/390]  eta: 0:01:36  lr: 0.000125  loss: 812.8835 (438.8947)  time: 0.2756  data: 0.0003  max mem: 14471
Epoch: [0]  [130/390]  eta: 0:01:31  lr: 0.000125  loss: 887.3579 (476.3180)  time: 0.2739  data: 0.0003  max mem: 14471
Epoch: [0]  [140/390]  eta: 0:01:26  lr: 0.000125  loss: 963.0005 (513.7526)  time: 0.2763  data: 0.0003  max mem: 14471
Epoch: [0]  [150/390]  eta: 0:01:22  lr: 0.000125  loss: 1037.9473 (551.1950)  time: 0.2768  data: 0.0003  max mem: 14471
Epoch: [0]  [160/390]  eta: 0:01:17  lr: 0.000125  loss: 1112.2312 (588.6540)  time: 0.2739  data: 0.0003  max mem: 14471
Epoch: [0]  [170/390]  eta: 0:01:13  lr: 0.000125  loss: 1188.3120 (626.1094)  time: 0.2741  data: 0.0003  max mem: 14471
Epoch: [0]  [180/390]  eta: 0:01:09  lr: 0.000125  loss: 1263.0538 (663.5563)  time: 0.2742  data: 0.0007  max mem: 14471
Epoch: [0]  [190/390]  eta: 0:01:05  lr: 0.000125  loss: 1338.3519 (701.0151)  time: 0.2730  data: 0.0006  max mem: 14471
Epoch: [0]  [200/390]  eta: 0:01:01  lr: 0.000125  loss: 1412.4717 (738.4692)  time: 0.2725  data: 0.0003  max mem: 14471
Epoch: [0]  [210/390]  eta: 0:00:58  lr: 0.000125  loss: 1487.4781 (775.9343)  time: 0.2725  data: 0.0003  max mem: 14471
Epoch: [0]  [220/390]  eta: 0:00:54  lr: 0.000125  loss: 1563.3368 (813.4000)  time: 0.2743  data: 0.0002  max mem: 14471
Epoch: [0]  [230/390]  eta: 0:00:50  lr: 0.000125  loss: 1638.0969 (850.8727)  time: 0.2740  data: 0.0003  max mem: 14471
Epoch: [0]  [240/390]  eta: 0:00:47  lr: 0.000125  loss: 1711.7809 (888.3430)  time: 0.2725  data: 0.0002  max mem: 14471
Epoch: [0]  [250/390]  eta: 0:00:44  lr: 0.000125  loss: 1787.7422 (925.8095)  time: 0.2739  data: 0.0003  max mem: 14471
Epoch: [0]  [260/390]  eta: 0:00:40  lr: 0.000125  loss: 1862.6260 (963.2770)  time: 0.2748  data: 0.0003  max mem: 14471
Epoch: [0]  [270/390]  eta: 0:00:37  lr: 0.000125  loss: 1937.8362 (1000.7496)  time: 0.2736  data: 0.0003  max mem: 14471
Epoch: [0]  [280/390]  eta: 0:00:34  lr: 0.000125  loss: 2013.0424 (1038.2326)  time: 0.2739  data: 0.0002  max mem: 14471
Epoch: [0]  [290/390]  eta: 0:00:30  lr: 0.000125  loss: 2087.5417 (1075.7065)  time: 0.2746  data: 0.0003  max mem: 14471
Epoch: [0]  [300/390]  eta: 0:00:27  lr: 0.000125  loss: 2161.8518 (1113.1795)  time: 0.2733  data: 0.0003  max mem: 14471
Epoch: [0]  [310/390]  eta: 0:00:24  lr: 0.000125  loss: 2237.3479 (1150.6596)  time: 0.2727  data: 0.0002  max mem: 14471
Epoch: [0]  [320/390]  eta: 0:00:21  lr: 0.000125  loss: 2312.9001 (1188.1521)  time: 0.2732  data: 0.0003  max mem: 14471
Epoch: [0]  [330/390]  eta: 0:00:18  lr: 0.000125  loss: 2387.9778 (1225.6364)  time: 0.2736  data: 0.0003  max mem: 14471
Epoch: [0]  [340/390]  eta: 0:00:15  lr: 0.000125  loss: 2461.3862 (1263.1239)  time: 0.2730  data: 0.0003  max mem: 14471
Epoch: [0]  [350/390]  eta: 0:00:12  lr: 0.000125  loss: 2538.0063 (1300.6078)  time: 0.2720  data: 0.0003  max mem: 14471
Epoch: [0]  [360/390]  eta: 0:00:09  lr: 0.000125  loss: 2613.1936 (1338.0889)  time: 0.2722  data: 0.0003  max mem: 14471
Epoch: [0]  [370/390]  eta: 0:00:06  lr: 0.000125  loss: 2686.9082 (1375.5701)  time: 0.2824  data: 0.0003  max mem: 14471
Epoch: [0]  [380/390]  eta: 0:00:03  lr: 0.000125  loss: 2761.6440 (1413.0537)  time: 0.2811  data: 0.0002  max mem: 14471
Epoch: [0]  [389/390]  eta: 0:00:00  lr: 0.000125  loss: 2829.7546 (1446.7851)  time: 0.2704  data: 0.0001  max mem: 14471
Epoch: [0] Total time: 0:01:57 (0.3005 s / it)
Averaged stats: lr: 0.000125  loss: 2829.7546 (1446.7851)
Test:  [ 0/53]  eta: 0:01:08  loss: 0.2841 (0.2841)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  acc1_10: 92.1875 (92.1875)  acc5_10: 100.0000 (100.0000)  time: 1.2889  data: 1.0263  max mem: 14471
Test:  [10/53]  eta: 0:00:11  loss: 0.2694 (0.2706)  acc1: 95.8333 (95.7386)  acc5: 100.0000 (100.0000)  acc1_10: 94.2708 (93.7974)  acc5_10: 100.0000 (100.0000)  time: 0.2706  data: 0.0957  max mem: 14471
Test:  [20/53]  eta: 0:00:06  loss: 0.2694 (0.2724)  acc1: 95.8333 (95.7837)  acc5: 100.0000 (99.9504)  acc1_10: 94.2708 (94.0972)  acc5_10: 100.0000 (99.9256)  time: 0.1524  data: 0.0014  max mem: 14471
Test:  [30/53]  eta: 0:00:04  loss: 0.2681 (0.2730)  acc1: 96.3542 (95.6989)  acc5: 100.0000 (99.9664)  acc1_10: 94.2708 (94.0356)  acc5_10: 100.0000 (99.9496)  time: 0.1281  data: 0.0003  max mem: 14471
Test:  [40/53]  eta: 0:00:02  loss: 0.2661 (0.2703)  acc1: 96.3542 (95.9223)  acc5: 100.0000 (99.9746)  acc1_10: 94.7917 (94.3344)  acc5_10: 100.0000 (99.9365)  time: 0.1195  data: 0.0002  max mem: 14471
Test:  [50/53]  eta: 0:00:00  loss: 0.2554 (0.2682)  acc1: 96.3542 (95.9457)  acc5: 100.0000 (99.9796)  acc1_10: 95.3125 (94.4342)  acc5_10: 100.0000 (99.9489)  time: 0.1181  data: 0.0001  max mem: 14471
Test:  [52/53]  eta: 0:00:00  loss: 0.2605 (0.2666)  acc1: 96.3542 (95.9700)  acc5: 100.0000 (99.9800)  acc1_10: 95.3125 (94.4100)  acc5_10: 100.0000 (99.9500)  time: 0.1141  data: 0.0001  max mem: 14471
Test: Total time: 0:00:08 (0.1542 s / it)
* Acc@1 95.970 Acc@5 99.980 loss 0.267
classifiers_10 : Acc@1 94.410 Acc@5 99.950
Accuracy of the network on the 10000 test images: 96.0%
Saved model checkpoint to [DIR: /cifar]
Max accuracy: 95.97%
## Using lr  0.0001250 for BACKBONE, cosine lr = 0.0024994 for PRUNER
Epoch: [1]  [  0/390]  eta: 0:10:58  lr: 0.000125  loss: 2912.8901 (2912.8901)  time: 1.6879  data: 1.2972  max mem: 14471
Epoch: [1]  [ 10/390]  eta: 0:02:33  lr: 0.000125  loss: 2949.8979 (2949.9677)  time: 0.4049  data: 0.1182  max mem: 14473
Epoch: [1]  [ 20/390]  eta: 0:02:06  lr: 0.000125  loss: 2987.7271 (2987.4125)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [1]  [ 30/390]  eta: 0:01:55  lr: 0.000125  loss: 3062.4976 (3024.8242)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [1]  [ 40/390]  eta: 0:01:48  lr: 0.000125  loss: 3137.4773 (3062.3604)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [1]  [ 50/390]  eta: 0:01:42  lr: 0.000125  loss: 3212.4275 (3099.8528)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [1]  [ 60/390]  eta: 0:01:37  lr: 0.000125  loss: 3287.7183 (3137.3018)  time: 0.2720  data: 0.0002  max mem: 14473
Epoch: [1]  [ 70/390]  eta: 0:01:33  lr: 0.000125  loss: 3361.9512 (3174.7353)  time: 0.2718  data: 0.0002  max mem: 14473
Epoch: [1]  [ 80/390]  eta: 0:01:30  lr: 0.000125  loss: 3437.4976 (3212.1615)  time: 0.2713  data: 0.0003  max mem: 14473
Epoch: [1]  [ 90/390]  eta: 0:01:26  lr: 0.000125  loss: 3511.9504 (3249.6275)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [1]  [100/390]  eta: 0:01:23  lr: 0.000125  loss: 3587.0906 (3287.1304)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [1]  [110/390]  eta: 0:01:20  lr: 0.000125  loss: 3662.1746 (3324.5974)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [1]  [120/390]  eta: 0:01:16  lr: 0.000125  loss: 3737.4114 (3362.0848)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [1]  [130/390]  eta: 0:01:13  lr: 0.000125  loss: 3812.1738 (3399.5578)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [1]  [140/390]  eta: 0:01:10  lr: 0.000125  loss: 3886.2939 (3437.0167)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [1]  [150/390]  eta: 0:01:07  lr: 0.000125  loss: 3961.9216 (3474.4882)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [1]  [160/390]  eta: 0:01:04  lr: 0.000125  loss: 4036.7461 (3511.9587)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [1]  [170/390]  eta: 0:01:02  lr: 0.000125  loss: 4111.8369 (3549.4401)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [1]  [180/390]  eta: 0:00:59  lr: 0.000125  loss: 4186.8994 (3586.9148)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [1]  [190/390]  eta: 0:00:56  lr: 0.000125  loss: 4261.5806 (3624.3841)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [1]  [200/390]  eta: 0:00:53  lr: 0.000125  loss: 4336.8149 (3661.8535)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [1]  [210/390]  eta: 0:00:50  lr: 0.000125  loss: 4411.7412 (3699.3130)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [1]  [220/390]  eta: 0:00:47  lr: 0.000125  loss: 4485.1206 (3736.7785)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [1]  [230/390]  eta: 0:00:44  lr: 0.000125  loss: 4560.9863 (3774.2521)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [1]  [240/390]  eta: 0:00:41  lr: 0.000125  loss: 4636.4297 (3811.7163)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [1]  [250/390]  eta: 0:00:39  lr: 0.000125  loss: 4711.0820 (3849.1736)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [1]  [260/390]  eta: 0:00:36  lr: 0.000125  loss: 4784.7026 (3886.6336)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [1]  [270/390]  eta: 0:00:33  lr: 0.000125  loss: 4861.3687 (3924.0781)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [1]  [280/390]  eta: 0:00:30  lr: 0.000125  loss: 4934.5288 (3961.5453)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [1]  [290/390]  eta: 0:00:27  lr: 0.000125  loss: 5011.0068 (3999.0044)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [1]  [300/390]  eta: 0:00:25  lr: 0.000125  loss: 5085.5552 (4036.4488)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [1]  [310/390]  eta: 0:00:22  lr: 0.000125  loss: 5159.1064 (4073.8995)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [1]  [320/390]  eta: 0:00:19  lr: 0.000125  loss: 5235.2642 (4111.3489)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [1]  [330/390]  eta: 0:00:16  lr: 0.000125  loss: 5308.5776 (4148.7933)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [1]  [340/390]  eta: 0:00:13  lr: 0.000125  loss: 5384.7935 (4186.2405)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [1]  [350/390]  eta: 0:00:11  lr: 0.000125  loss: 5459.5327 (4223.6950)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [1]  [360/390]  eta: 0:00:08  lr: 0.000125  loss: 5534.8882 (4261.1322)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [1]  [370/390]  eta: 0:00:05  lr: 0.000125  loss: 5609.3057 (4298.5697)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [1]  [380/390]  eta: 0:00:02  lr: 0.000125  loss: 5684.1729 (4336.0083)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [1]  [389/390]  eta: 0:00:00  lr: 0.000125  loss: 5751.1797 (4369.6988)  time: 0.2707  data: 0.0001  max mem: 14473
Epoch: [1] Total time: 0:01:48 (0.2775 s / it)
Averaged stats: lr: 0.000125  loss: 5751.1797 (4369.6988)
Test:  [ 0/53]  eta: 0:01:17  loss: 0.3003 (0.3003)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 94.7917 (94.7917)  acc5_10: 100.0000 (100.0000)  time: 1.4558  data: 1.2886  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2958 (0.2952)  acc1: 95.8333 (96.2121)  acc5: 100.0000 (99.9053)  acc1_10: 94.7917 (94.9337)  acc5_10: 100.0000 (99.9527)  time: 0.2516  data: 0.1175  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2939 (0.2975)  acc1: 95.8333 (96.2550)  acc5: 100.0000 (99.9008)  acc1_10: 94.7917 (95.0397)  acc5_10: 100.0000 (99.8264)  time: 0.1268  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2939 (0.2962)  acc1: 95.8333 (96.2870)  acc5: 100.0000 (99.9160)  acc1_10: 95.3125 (95.1781)  acc5_10: 100.0000 (99.8824)  time: 0.1224  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2930 (0.2967)  acc1: 95.8333 (96.3288)  acc5: 100.0000 (99.9238)  acc1_10: 95.3125 (95.2363)  acc5_10: 100.0000 (99.8984)  time: 0.1210  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2923 (0.2957)  acc1: 96.3542 (96.3644)  acc5: 100.0000 (99.9387)  acc1_10: 95.8333 (95.2614)  acc5_10: 100.0000 (99.9183)  time: 0.1189  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2915 (0.2935)  acc1: 96.3542 (96.3700)  acc5: 100.0000 (99.9400)  acc1_10: 95.8333 (95.2600)  acc5_10: 100.0000 (99.9200)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1485 s / it)
* Acc@1 96.370 Acc@5 99.940 loss 0.293
classifiers_10 : Acc@1 95.260 Acc@5 99.920
Accuracy of the network on the 10000 test images: 96.4%
Saved model checkpoint to [DIR: /cifar]
Max accuracy: 96.37%
## Using lr  0.0001249 for BACKBONE, cosine lr = 0.0024975 for PRUNER
Epoch: [2]  [  0/390]  eta: 0:09:15  lr: 0.000125  loss: 5833.7334 (5833.7334)  time: 1.4242  data: 1.0744  max mem: 14473
Epoch: [2]  [ 10/390]  eta: 0:02:26  lr: 0.000125  loss: 5870.3970 (5870.5017)  time: 0.3861  data: 0.0979  max mem: 14473
Epoch: [2]  [ 20/390]  eta: 0:02:03  lr: 0.000125  loss: 5907.5107 (5907.8834)  time: 0.2796  data: 0.0003  max mem: 14473
Epoch: [2]  [ 30/390]  eta: 0:01:53  lr: 0.000125  loss: 5982.9839 (5945.0427)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [2]  [ 40/390]  eta: 0:01:47  lr: 0.000125  loss: 6056.2769 (5982.4352)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [2]  [ 50/390]  eta: 0:01:41  lr: 0.000125  loss: 6131.8770 (6019.7003)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [2]  [ 60/390]  eta: 0:01:37  lr: 0.000125  loss: 6205.6880 (6056.9916)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [2]  [ 70/390]  eta: 0:01:33  lr: 0.000125  loss: 6280.7886 (6094.2615)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [2]  [ 80/390]  eta: 0:01:29  lr: 0.000125  loss: 6355.7344 (6131.5479)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [2]  [ 90/390]  eta: 0:01:26  lr: 0.000125  loss: 6430.0288 (6168.8155)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [2]  [100/390]  eta: 0:01:23  lr: 0.000125  loss: 6504.1025 (6206.0496)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [2]  [110/390]  eta: 0:01:20  lr: 0.000125  loss: 6578.8032 (6243.2665)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [2]  [120/390]  eta: 0:01:16  lr: 0.000125  loss: 6652.3232 (6280.4884)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [2]  [130/390]  eta: 0:01:13  lr: 0.000125  loss: 6727.4346 (6317.6955)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [2]  [140/390]  eta: 0:01:10  lr: 0.000125  loss: 6800.7207 (6354.8976)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [2]  [150/390]  eta: 0:01:07  lr: 0.000125  loss: 6875.8599 (6392.0872)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [2]  [160/390]  eta: 0:01:04  lr: 0.000125  loss: 6949.8599 (6429.2304)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [2]  [170/390]  eta: 0:01:02  lr: 0.000125  loss: 7023.5825 (6466.3339)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [2]  [180/390]  eta: 0:00:59  lr: 0.000125  loss: 7096.7212 (6503.4487)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [2]  [190/390]  eta: 0:00:56  lr: 0.000125  loss: 7171.8394 (6540.5391)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [2]  [200/390]  eta: 0:00:53  lr: 0.000125  loss: 7244.7627 (6577.5960)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [2]  [210/390]  eta: 0:00:50  lr: 0.000125  loss: 7318.9839 (6614.6330)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [2]  [220/390]  eta: 0:00:47  lr: 0.000125  loss: 7392.3018 (6651.6363)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [2]  [230/390]  eta: 0:00:44  lr: 0.000125  loss: 7465.1836 (6688.6181)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [2]  [240/390]  eta: 0:00:41  lr: 0.000125  loss: 7539.0571 (6725.5530)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [2]  [250/390]  eta: 0:00:39  lr: 0.000125  loss: 7611.9043 (6762.4423)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [2]  [260/390]  eta: 0:00:36  lr: 0.000125  loss: 7684.7031 (6799.3098)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [2]  [270/390]  eta: 0:00:33  lr: 0.000125  loss: 7757.7881 (6836.1262)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [2]  [280/390]  eta: 0:00:30  lr: 0.000125  loss: 7828.9551 (6872.9050)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [2]  [290/390]  eta: 0:00:27  lr: 0.000125  loss: 7901.2534 (6909.6280)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [2]  [300/390]  eta: 0:00:25  lr: 0.000125  loss: 7974.4707 (6946.2961)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [2]  [310/390]  eta: 0:00:22  lr: 0.000125  loss: 8044.7559 (6982.9093)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [2]  [320/390]  eta: 0:00:19  lr: 0.000125  loss: 8117.2778 (7019.4615)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [2]  [330/390]  eta: 0:00:16  lr: 0.000125  loss: 8188.5977 (7055.9501)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [2]  [340/390]  eta: 0:00:13  lr: 0.000125  loss: 8259.2393 (7092.3697)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [2]  [350/390]  eta: 0:00:11  lr: 0.000125  loss: 8328.4863 (7128.7138)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [2]  [360/390]  eta: 0:00:08  lr: 0.000125  loss: 8399.9326 (7164.9642)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [2]  [370/390]  eta: 0:00:05  lr: 0.000125  loss: 8467.7217 (7201.1291)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [2]  [380/390]  eta: 0:00:02  lr: 0.000125  loss: 8537.8721 (7237.1976)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [2]  [389/390]  eta: 0:00:00  lr: 0.000125  loss: 8598.1963 (7269.5699)  time: 0.2721  data: 0.0001  max mem: 14473
Epoch: [2] Total time: 0:01:48 (0.2776 s / it)
Averaged stats: lr: 0.000125  loss: 8598.1963 (7269.5699)
Test:  [ 0/53]  eta: 0:01:34  loss: 0.2540 (0.2540)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 94.7917 (94.7917)  acc5_10: 100.0000 (100.0000)  time: 1.7848  data: 1.6329  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2472 (0.2460)  acc1: 96.3542 (96.5909)  acc5: 100.0000 (99.9527)  acc1_10: 95.8333 (95.9754)  acc5_10: 100.0000 (100.0000)  time: 0.2755  data: 0.1487  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2563 (0.2508)  acc1: 96.3542 (96.6270)  acc5: 100.0000 (99.9008)  acc1_10: 96.3542 (96.0566)  acc5_10: 100.0000 (99.9256)  time: 0.1226  data: 0.0002  max mem: 14473
Test:  [30/53]  eta: 0:00:04  loss: 0.2520 (0.2490)  acc1: 96.8750 (96.8246)  acc5: 100.0000 (99.9160)  acc1_10: 96.3542 (96.1190)  acc5_10: 100.0000 (99.9496)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2484 (0.2501)  acc1: 96.8750 (96.8877)  acc5: 100.0000 (99.9365)  acc1_10: 95.8333 (96.1636)  acc5_10: 100.0000 (99.9492)  time: 0.1202  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2414 (0.2483)  acc1: 97.3958 (96.9873)  acc5: 100.0000 (99.9489)  acc1_10: 96.3542 (96.2827)  acc5_10: 100.0000 (99.9592)  time: 0.1190  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2404 (0.2467)  acc1: 97.3958 (97.0000)  acc5: 100.0000 (99.9500)  acc1_10: 96.3542 (96.2500)  acc5_10: 100.0000 (99.9600)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1529 s / it)
* Acc@1 97.000 Acc@5 99.950 loss 0.247
classifiers_10 : Acc@1 96.250 Acc@5 99.960
Accuracy of the network on the 10000 test images: 97.0%
Saved model checkpoint to [DIR: /cifar]
Max accuracy: 97.00%
## Using lr  0.0001247 for BACKBONE, cosine lr = 0.0024945 for PRUNER
Epoch: [3]  [  0/390]  eta: 0:10:32  lr: 0.000125  loss: 8673.8311 (8673.8311)  time: 1.6227  data: 1.2887  max mem: 14473
Epoch: [3]  [ 10/390]  eta: 0:02:31  lr: 0.000125  loss: 8707.6396 (8707.5753)  time: 0.3997  data: 0.1174  max mem: 14473
Epoch: [3]  [ 20/390]  eta: 0:02:05  lr: 0.000125  loss: 8740.7207 (8740.8933)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [3]  [ 30/390]  eta: 0:01:54  lr: 0.000125  loss: 8806.4697 (8773.9448)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [3]  [ 40/390]  eta: 0:01:47  lr: 0.000125  loss: 8872.6445 (8806.7101)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [3]  [ 50/390]  eta: 0:01:42  lr: 0.000125  loss: 8936.5371 (8839.1847)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [3]  [ 60/390]  eta: 0:01:37  lr: 0.000125  loss: 9000.2988 (8871.3824)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [3]  [ 70/390]  eta: 0:01:33  lr: 0.000125  loss: 9063.9893 (8903.2627)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [3]  [ 80/390]  eta: 0:01:29  lr: 0.000125  loss: 9125.7637 (8934.7735)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [3]  [ 90/390]  eta: 0:01:26  lr: 0.000125  loss: 9185.7783 (8965.9564)  time: 0.2717  data: 0.0003  max mem: 14473
Epoch: [3]  [100/390]  eta: 0:01:23  lr: 0.000125  loss: 9245.0029 (8996.7420)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [3]  [110/390]  eta: 0:01:19  lr: 0.000125  loss: 9301.8984 (9027.1094)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [3]  [120/390]  eta: 0:01:16  lr: 0.000125  loss: 9359.2012 (9057.0210)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [3]  [130/390]  eta: 0:01:13  lr: 0.000125  loss: 9413.8887 (9086.4406)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [3]  [140/390]  eta: 0:01:10  lr: 0.000125  loss: 9466.1582 (9115.3395)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [3]  [150/390]  eta: 0:01:07  lr: 0.000125  loss: 9516.0908 (9143.6973)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [3]  [160/390]  eta: 0:01:04  lr: 0.000125  loss: 9564.5098 (9171.5094)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [3]  [170/390]  eta: 0:01:01  lr: 0.000125  loss: 9612.3545 (9198.7149)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [3]  [180/390]  eta: 0:00:59  lr: 0.000125  loss: 9656.9102 (9225.2782)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [3]  [190/390]  eta: 0:00:56  lr: 0.000125  loss: 9698.2480 (9251.1671)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [3]  [200/390]  eta: 0:00:53  lr: 0.000125  loss: 9737.3633 (9276.3420)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [3]  [210/390]  eta: 0:00:50  lr: 0.000125  loss: 9773.2471 (9300.7618)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [3]  [220/390]  eta: 0:00:47  lr: 0.000125  loss: 9806.6064 (9324.3798)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [3]  [230/390]  eta: 0:00:44  lr: 0.000125  loss: 9836.0479 (9347.1578)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [3]  [240/390]  eta: 0:00:41  lr: 0.000125  loss: 9862.1934 (9369.0624)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [3]  [250/390]  eta: 0:00:39  lr: 0.000125  loss: 9884.8584 (9390.0321)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [3]  [260/390]  eta: 0:00:36  lr: 0.000125  loss: 9903.7266 (9410.0375)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [3]  [270/390]  eta: 0:00:33  lr: 0.000125  loss: 9919.2246 (9429.0284)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [3]  [280/390]  eta: 0:00:30  lr: 0.000125  loss: 9928.8242 (9446.9714)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [3]  [290/390]  eta: 0:00:27  lr: 0.000125  loss: 9935.7041 (9463.8186)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [3]  [300/390]  eta: 0:00:25  lr: 0.000125  loss: 9936.8350 (9479.5118)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [3]  [310/390]  eta: 0:00:22  lr: 0.000125  loss: 9933.4551 (9494.0150)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [3]  [320/390]  eta: 0:00:19  lr: 0.000125  loss: 9924.9717 (9507.2806)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [3]  [330/390]  eta: 0:00:16  lr: 0.000125  loss: 9912.8232 (9519.2843)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [3]  [340/390]  eta: 0:00:13  lr: 0.000125  loss: 9894.0566 (9529.9820)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [3]  [350/390]  eta: 0:00:11  lr: 0.000125  loss: 9871.0850 (9539.3278)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [3]  [360/390]  eta: 0:00:08  lr: 0.000125  loss: 9841.3516 (9547.2738)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [3]  [370/390]  eta: 0:00:05  lr: 0.000125  loss: 9807.1406 (9553.7954)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [3]  [380/390]  eta: 0:00:02  lr: 0.000125  loss: 9766.9062 (9558.8496)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [3]  [389/390]  eta: 0:00:00  lr: 0.000125  loss: 9725.7744 (9562.1243)  time: 0.2726  data: 0.0001  max mem: 14473
Epoch: [3] Total time: 0:01:48 (0.2776 s / it)
Averaged stats: lr: 0.000125  loss: 9725.7744 (9562.1243)
Test:  [ 0/53]  eta: 0:01:14  loss: 0.2797 (0.2797)  acc1: 97.3958 (97.3958)  acc5: 100.0000 (100.0000)  acc1_10: 97.3958 (97.3958)  acc5_10: 100.0000 (100.0000)  time: 1.4011  data: 1.2388  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2744 (0.2738)  acc1: 97.3958 (97.4432)  acc5: 100.0000 (100.0000)  acc1_10: 96.8750 (97.0170)  acc5_10: 100.0000 (99.9527)  time: 0.2462  data: 0.1129  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2800 (0.2837)  acc1: 96.8750 (97.1726)  acc5: 100.0000 (99.9752)  acc1_10: 96.3542 (96.6022)  acc5_10: 100.0000 (99.8760)  time: 0.1267  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2917 (0.2835)  acc1: 96.8750 (97.1774)  acc5: 100.0000 (99.9496)  acc1_10: 96.3542 (96.5390)  acc5_10: 100.0000 (99.8488)  time: 0.1227  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2902 (0.2856)  acc1: 96.8750 (97.1418)  acc5: 100.0000 (99.9111)  acc1_10: 96.3542 (96.5701)  acc5_10: 100.0000 (99.8603)  time: 0.1210  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2895 (0.2853)  acc1: 96.8750 (97.1303)  acc5: 100.0000 (99.9081)  acc1_10: 96.3542 (96.4563)  acc5_10: 100.0000 (99.8672)  time: 0.1188  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2855 (0.2843)  acc1: 96.8750 (97.1300)  acc5: 100.0000 (99.9100)  acc1_10: 95.8333 (96.4200)  acc5_10: 100.0000 (99.8700)  time: 0.1143  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1473 s / it)
* Acc@1 97.130 Acc@5 99.910 loss 0.284
classifiers_10 : Acc@1 96.420 Acc@5 99.870
Accuracy of the network on the 10000 test images: 97.1%
Saved model checkpoint to [DIR: /cifar]
Max accuracy: 97.13%
## Using lr  0.0001245 for BACKBONE, cosine lr = 0.0024902 for PRUNER
Epoch: [4]  [  0/390]  eta: 0:10:35  lr: 0.000125  loss: 9673.7266 (9673.7266)  time: 1.6294  data: 1.2851  max mem: 14473
Epoch: [4]  [ 10/390]  eta: 0:02:33  lr: 0.000125  loss: 9646.8262 (9646.3930)  time: 0.4027  data: 0.1171  max mem: 14473
Epoch: [4]  [ 20/390]  eta: 0:02:06  lr: 0.000125  loss: 9612.5410 (9616.8039)  time: 0.2770  data: 0.0003  max mem: 14473
Epoch: [4]  [ 30/390]  eta: 0:01:54  lr: 0.000125  loss: 9549.6572 (9585.2645)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [4]  [ 40/390]  eta: 0:01:47  lr: 0.000125  loss: 9480.8018 (9551.7530)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [4]  [ 50/390]  eta: 0:01:42  lr: 0.000125  loss: 9406.1699 (9516.2419)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [4]  [ 60/390]  eta: 0:01:37  lr: 0.000125  loss: 9326.4395 (9478.7854)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [4]  [ 70/390]  eta: 0:01:33  lr: 0.000125  loss: 9240.1846 (9439.4328)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [4]  [ 80/390]  eta: 0:01:30  lr: 0.000125  loss: 9148.7715 (9398.1559)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [4]  [ 90/390]  eta: 0:01:26  lr: 0.000125  loss: 9050.9561 (9354.9246)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [4]  [100/390]  eta: 0:01:23  lr: 0.000125  loss: 8947.3438 (9309.8233)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [4]  [110/390]  eta: 0:01:20  lr: 0.000125  loss: 8839.3730 (9262.8914)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [4]  [120/390]  eta: 0:01:16  lr: 0.000125  loss: 8724.7256 (9214.1030)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [4]  [130/390]  eta: 0:01:13  lr: 0.000125  loss: 8606.1279 (9163.4754)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [4]  [140/390]  eta: 0:01:10  lr: 0.000125  loss: 8482.6494 (9111.0674)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [4]  [150/390]  eta: 0:01:07  lr: 0.000125  loss: 8352.9365 (9056.8343)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [4]  [160/390]  eta: 0:01:04  lr: 0.000125  loss: 8218.1475 (9000.8384)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [4]  [170/390]  eta: 0:01:02  lr: 0.000125  loss: 8078.5532 (8943.1304)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [4]  [180/390]  eta: 0:00:59  lr: 0.000125  loss: 7934.7866 (8883.7110)  time: 0.2824  data: 0.0003  max mem: 14473
Epoch: [4]  [190/390]  eta: 0:00:56  lr: 0.000125  loss: 7785.5815 (8822.6179)  time: 0.2830  data: 0.0003  max mem: 14473
Epoch: [4]  [200/390]  eta: 0:00:53  lr: 0.000125  loss: 7632.5088 (8759.9114)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [4]  [210/390]  eta: 0:00:50  lr: 0.000125  loss: 7476.1138 (8695.6323)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [4]  [220/390]  eta: 0:00:47  lr: 0.000125  loss: 7314.0039 (8629.8109)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [4]  [230/390]  eta: 0:00:44  lr: 0.000125  loss: 7150.1826 (8562.4841)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [4]  [240/390]  eta: 0:00:42  lr: 0.000125  loss: 6982.4189 (8493.7293)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [4]  [250/390]  eta: 0:00:39  lr: 0.000125  loss: 6810.8071 (8423.5679)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [4]  [260/390]  eta: 0:00:36  lr: 0.000125  loss: 6637.2900 (8352.0770)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [4]  [270/390]  eta: 0:00:33  lr: 0.000125  loss: 6459.5508 (8279.3024)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [4]  [280/390]  eta: 0:00:30  lr: 0.000125  loss: 6281.4126 (8205.2957)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [4]  [290/390]  eta: 0:00:27  lr: 0.000125  loss: 6099.3115 (8130.1160)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [4]  [300/390]  eta: 0:00:25  lr: 0.000125  loss: 5916.6548 (8053.8340)  time: 0.2756  data: 0.0002  max mem: 14473
Epoch: [4]  [310/390]  eta: 0:00:22  lr: 0.000125  loss: 5732.8584 (7976.5038)  time: 0.2764  data: 0.0002  max mem: 14473
Epoch: [4]  [320/390]  eta: 0:00:19  lr: 0.000125  loss: 5546.5908 (7898.2080)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [4]  [330/390]  eta: 0:00:16  lr: 0.000125  loss: 5360.5850 (7818.9825)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [4]  [340/390]  eta: 0:00:13  lr: 0.000125  loss: 5172.0952 (7738.9029)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [4]  [350/390]  eta: 0:00:11  lr: 0.000125  loss: 4985.5508 (7658.0459)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [4]  [360/390]  eta: 0:00:08  lr: 0.000125  loss: 4797.2368 (7576.4485)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [4]  [370/390]  eta: 0:00:05  lr: 0.000125  loss: 4609.8569 (7494.2020)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [4]  [380/390]  eta: 0:00:02  lr: 0.000125  loss: 4421.5537 (7411.3617)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [4]  [389/390]  eta: 0:00:00  lr: 0.000125  loss: 4254.3862 (7336.3515)  time: 0.2723  data: 0.0001  max mem: 14473
Epoch: [4] Total time: 0:01:48 (0.2785 s / it)
Averaged stats: lr: 0.000125  loss: 4254.3862 (7336.3515)
Test:  [ 0/53]  eta: 0:01:12  loss: 0.2543 (0.2543)  acc1: 97.3958 (97.3958)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.3713  data: 1.2125  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2545 (0.2606)  acc1: 96.8750 (96.5436)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.1648)  acc5_10: 100.0000 (100.0000)  time: 0.2477  data: 0.1106  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2705 (0.2706)  acc1: 96.3542 (96.2550)  acc5: 100.0000 (99.9008)  acc1_10: 95.3125 (95.5605)  acc5_10: 100.0000 (99.8512)  time: 0.1311  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2698 (0.2713)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (99.8992)  acc1_10: 95.3125 (95.5645)  acc5_10: 100.0000 (99.8656)  time: 0.1241  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2672 (0.2720)  acc1: 96.3542 (96.3288)  acc5: 100.0000 (99.8857)  acc1_10: 95.8333 (95.5031)  acc5_10: 100.0000 (99.8603)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2768 (0.2714)  acc1: 96.3542 (96.2929)  acc5: 100.0000 (99.9081)  acc1_10: 94.7917 (95.4453)  acc5_10: 100.0000 (99.8877)  time: 0.1192  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2806 (0.2707)  acc1: 95.8333 (96.2900)  acc5: 100.0000 (99.9100)  acc1_10: 94.2708 (95.4000)  acc5_10: 100.0000 (99.8900)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1484 s / it)
* Acc@1 96.290 Acc@5 99.910 loss 0.271
classifiers_10 : Acc@1 95.400 Acc@5 99.890
Accuracy of the network on the 10000 test images: 96.3%
## Using lr  0.0001243 for BACKBONE, cosine lr = 0.0024847 for PRUNER
Epoch: [5]  [  0/390]  eta: 0:11:22  lr: 0.000124  loss: 4068.0544 (4068.0544)  time: 1.7490  data: 1.4305  max mem: 14473
Epoch: [5]  [ 10/390]  eta: 0:02:36  lr: 0.000124  loss: 3975.7217 (3975.5211)  time: 0.4109  data: 0.1303  max mem: 14473
Epoch: [5]  [ 20/390]  eta: 0:02:07  lr: 0.000124  loss: 3865.7598 (3883.4713)  time: 0.2756  data: 0.0002  max mem: 14473
Epoch: [5]  [ 30/390]  eta: 0:01:56  lr: 0.000124  loss: 3681.8604 (3791.9946)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [5]  [ 40/390]  eta: 0:01:48  lr: 0.000124  loss: 3499.2180 (3700.9889)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [5]  [ 50/390]  eta: 0:01:43  lr: 0.000124  loss: 3319.9792 (3610.4861)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [5]  [ 60/390]  eta: 0:01:38  lr: 0.000124  loss: 3141.0137 (3520.6088)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [5]  [ 70/390]  eta: 0:01:34  lr: 0.000124  loss: 2965.1409 (3431.2589)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [5]  [ 80/390]  eta: 0:01:30  lr: 0.000124  loss: 2790.7175 (3342.5832)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [5]  [ 90/390]  eta: 0:01:27  lr: 0.000124  loss: 2618.5996 (3254.5379)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [5]  [100/390]  eta: 0:01:23  lr: 0.000124  loss: 2447.6104 (3167.1512)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [5]  [110/390]  eta: 0:01:20  lr: 0.000124  loss: 2280.2617 (3080.4709)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [5]  [120/390]  eta: 0:01:17  lr: 0.000124  loss: 2113.4666 (2994.5398)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [5]  [130/390]  eta: 0:01:14  lr: 0.000124  loss: 1951.1355 (2909.3331)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [5]  [140/390]  eta: 0:01:11  lr: 0.000124  loss: 1789.4432 (2824.9030)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [5]  [150/390]  eta: 0:01:08  lr: 0.000124  loss: 1630.9263 (2741.2067)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [5]  [160/390]  eta: 0:01:05  lr: 0.000124  loss: 1475.9785 (2658.3077)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [5]  [170/390]  eta: 0:01:02  lr: 0.000124  loss: 1321.5215 (2576.1797)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [5]  [180/390]  eta: 0:00:59  lr: 0.000124  loss: 1170.9550 (2494.8531)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [5]  [190/390]  eta: 0:00:56  lr: 0.000124  loss: 1023.0175 (2414.3322)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [5]  [200/390]  eta: 0:00:53  lr: 0.000124  loss: 876.9203 (2334.6057)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [5]  [210/390]  eta: 0:00:50  lr: 0.000124  loss: 733.7336 (2256.0451)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [5]  [220/390]  eta: 0:00:47  lr: 0.000124  loss: 606.2119 (2178.5840)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [5]  [230/390]  eta: 0:00:44  lr: 0.000124  loss: 467.4237 (2101.8754)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [5]  [240/390]  eta: 0:00:42  lr: 0.000124  loss: 332.6682 (2025.9606)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [5]  [250/390]  eta: 0:00:39  lr: 0.000124  loss: 198.7457 (1950.8237)  time: 0.2769  data: 0.0003  max mem: 14473
Epoch: [5]  [260/390]  eta: 0:00:36  lr: 0.000124  loss: 69.0566 (1876.9718)  time: 0.2779  data: 0.0003  max mem: 14473
Epoch: [5]  [270/390]  eta: 0:00:33  lr: 0.000124  loss: 3.5409 (1807.8310)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [5]  [280/390]  eta: 0:00:30  lr: 0.000124  loss: 3.2104 (1743.6113)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [5]  [290/390]  eta: 0:00:27  lr: 0.000124  loss: 3.1825 (1683.8008)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [5]  [300/390]  eta: 0:00:25  lr: 0.000124  loss: 3.0927 (1627.9646)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [5]  [310/390]  eta: 0:00:22  lr: 0.000124  loss: 3.0139 (1575.7218)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [5]  [320/390]  eta: 0:00:19  lr: 0.000124  loss: 3.2759 (1526.7384)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [5]  [330/390]  eta: 0:00:16  lr: 0.000124  loss: 3.5121 (1480.7176)  time: 0.2746  data: 0.0002  max mem: 14473
Epoch: [5]  [340/390]  eta: 0:00:13  lr: 0.000124  loss: 3.4898 (1437.3875)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [5]  [350/390]  eta: 0:00:11  lr: 0.000124  loss: 3.3081 (1396.5259)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [5]  [360/390]  eta: 0:00:08  lr: 0.000124  loss: 3.3037 (1357.9260)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [5]  [370/390]  eta: 0:00:05  lr: 0.000124  loss: 3.3606 (1321.4162)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [5]  [380/390]  eta: 0:00:02  lr: 0.000124  loss: 3.5133 (1286.8260)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [5]  [389/390]  eta: 0:00:00  lr: 0.000124  loss: 3.4286 (1257.2043)  time: 0.2719  data: 0.0002  max mem: 14473
Epoch: [5] Total time: 0:01:48 (0.2788 s / it)
Averaged stats: lr: 0.000124  loss: 3.4286 (1257.2043)
Test:  [ 0/53]  eta: 0:00:58  loss: 0.4521 (0.4521)  acc1: 93.2292 (93.2292)  acc5: 100.0000 (100.0000)  acc1_10: 94.7917 (94.7917)  acc5_10: 99.4792 (99.4792)  time: 1.1065  data: 0.9591  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.4287 (0.4325)  acc1: 93.7500 (93.6553)  acc5: 100.0000 (99.8580)  acc1_10: 93.2292 (93.1818)  acc5_10: 100.0000 (99.7633)  time: 0.2439  data: 0.1073  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.4396 (0.4397)  acc1: 93.2292 (93.4028)  acc5: 100.0000 (99.7520)  acc1_10: 92.1875 (92.4851)  acc5_10: 100.0000 (99.7520)  time: 0.1401  data: 0.0112  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.4487 (0.4390)  acc1: 92.7083 (93.2964)  acc5: 100.0000 (99.7648)  acc1_10: 91.6667 (92.3555)  acc5_10: 100.0000 (99.7816)  time: 0.1237  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.4361 (0.4369)  acc1: 93.2292 (93.3943)  acc5: 100.0000 (99.8095)  acc1_10: 92.1875 (92.4289)  acc5_10: 100.0000 (99.7586)  time: 0.1224  data: 0.0003  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.4315 (0.4364)  acc1: 93.7500 (93.3517)  acc5: 100.0000 (99.8366)  acc1_10: 92.1875 (92.3713)  acc5_10: 100.0000 (99.7855)  time: 0.1195  data: 0.0002  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.4315 (0.4350)  acc1: 93.7500 (93.3100)  acc5: 100.0000 (99.8300)  acc1_10: 92.1875 (92.3200)  acc5_10: 100.0000 (99.7800)  time: 0.1146  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1475 s / it)
* Acc@1 93.310 Acc@5 99.830 loss 0.435
classifiers_10 : Acc@1 92.320 Acc@5 99.780
Accuracy of the network on the 10000 test images: 93.3%
## Using lr  0.0001240 for BACKBONE, cosine lr = 0.0024779 for PRUNER
Epoch: [6]  [  0/390]  eta: 0:10:34  lr: 0.000124  loss: 3.3392 (3.3392)  time: 1.6282  data: 1.2837  max mem: 14473
Epoch: [6]  [ 10/390]  eta: 0:02:32  lr: 0.000124  loss: 3.3392 (3.1595)  time: 0.4021  data: 0.1170  max mem: 14473
Epoch: [6]  [ 20/390]  eta: 0:02:06  lr: 0.000124  loss: 2.9915 (3.0871)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [6]  [ 30/390]  eta: 0:01:54  lr: 0.000124  loss: 2.9798 (3.0922)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [6]  [ 40/390]  eta: 0:01:47  lr: 0.000124  loss: 3.2162 (3.1604)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [6]  [ 50/390]  eta: 0:01:42  lr: 0.000124  loss: 3.3052 (3.1402)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [6]  [ 60/390]  eta: 0:01:38  lr: 0.000124  loss: 3.0573 (3.1371)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [6]  [ 70/390]  eta: 0:01:34  lr: 0.000124  loss: 3.3647 (3.1731)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [6]  [ 80/390]  eta: 0:01:30  lr: 0.000124  loss: 3.3721 (3.1581)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [6]  [ 90/390]  eta: 0:01:26  lr: 0.000124  loss: 3.1589 (3.1641)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [6]  [100/390]  eta: 0:01:23  lr: 0.000124  loss: 3.3506 (3.1822)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [6]  [110/390]  eta: 0:01:20  lr: 0.000124  loss: 3.3506 (3.1900)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [6]  [120/390]  eta: 0:01:17  lr: 0.000124  loss: 3.3785 (3.1967)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [6]  [130/390]  eta: 0:01:14  lr: 0.000124  loss: 3.1922 (3.1871)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [6]  [140/390]  eta: 0:01:11  lr: 0.000124  loss: 2.8599 (3.1767)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [6]  [150/390]  eta: 0:01:07  lr: 0.000124  loss: 3.1768 (3.1887)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [6]  [160/390]  eta: 0:01:05  lr: 0.000124  loss: 3.1768 (3.1809)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [6]  [170/390]  eta: 0:01:02  lr: 0.000124  loss: 2.9373 (3.1673)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [6]  [180/390]  eta: 0:00:59  lr: 0.000124  loss: 3.1249 (3.1737)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [6]  [190/390]  eta: 0:00:56  lr: 0.000124  loss: 3.3824 (3.1811)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [6]  [200/390]  eta: 0:00:53  lr: 0.000124  loss: 3.2952 (3.1716)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [6]  [210/390]  eta: 0:00:50  lr: 0.000124  loss: 3.1677 (3.1747)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [6]  [220/390]  eta: 0:00:47  lr: 0.000124  loss: 3.4651 (3.1916)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [6]  [230/390]  eta: 0:00:44  lr: 0.000124  loss: 3.4651 (3.2009)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [6]  [240/390]  eta: 0:00:41  lr: 0.000124  loss: 3.3342 (3.1993)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [6]  [250/390]  eta: 0:00:39  lr: 0.000124  loss: 3.1996 (3.1940)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [6]  [260/390]  eta: 0:00:36  lr: 0.000124  loss: 3.1996 (3.1955)  time: 0.2789  data: 0.0003  max mem: 14473
Epoch: [6]  [270/390]  eta: 0:00:33  lr: 0.000124  loss: 3.0157 (3.1835)  time: 0.2810  data: 0.0003  max mem: 14473
Epoch: [6]  [280/390]  eta: 0:00:30  lr: 0.000124  loss: 3.0070 (3.1875)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [6]  [290/390]  eta: 0:00:27  lr: 0.000124  loss: 3.2024 (3.1876)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [6]  [300/390]  eta: 0:00:25  lr: 0.000124  loss: 3.1687 (3.1934)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [6]  [310/390]  eta: 0:00:22  lr: 0.000124  loss: 3.4901 (3.1925)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [6]  [320/390]  eta: 0:00:19  lr: 0.000124  loss: 3.5270 (3.1929)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [6]  [330/390]  eta: 0:00:16  lr: 0.000124  loss: 3.3998 (3.1953)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [6]  [340/390]  eta: 0:00:13  lr: 0.000124  loss: 3.2951 (3.1973)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [6]  [350/390]  eta: 0:00:11  lr: 0.000124  loss: 3.4339 (3.1978)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [6]  [360/390]  eta: 0:00:08  lr: 0.000124  loss: 3.3372 (3.1984)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [6]  [370/390]  eta: 0:00:05  lr: 0.000124  loss: 3.2680 (3.2006)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [6]  [380/390]  eta: 0:00:02  lr: 0.000124  loss: 3.1440 (3.1991)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [6]  [389/390]  eta: 0:00:00  lr: 0.000124  loss: 3.2003 (3.2020)  time: 0.2713  data: 0.0001  max mem: 14473
Epoch: [6] Total time: 0:01:48 (0.2780 s / it)
Averaged stats: lr: 0.000124  loss: 3.2003 (3.2020)
Test:  [ 0/53]  eta: 0:01:27  loss: 0.4138 (0.4138)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  acc1_10: 94.2708 (94.2708)  acc5_10: 100.0000 (100.0000)  time: 1.6449  data: 1.4892  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.4161 (0.4234)  acc1: 93.2292 (92.9924)  acc5: 100.0000 (99.8580)  acc1_10: 92.1875 (91.9981)  acc5_10: 99.4792 (99.6686)  time: 0.2660  data: 0.1357  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.4201 (0.4244)  acc1: 92.7083 (92.7827)  acc5: 100.0000 (99.6776)  acc1_10: 92.1875 (92.1875)  acc5_10: 99.4792 (99.5784)  time: 0.1247  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.4201 (0.4240)  acc1: 92.7083 (92.8259)  acc5: 99.4792 (99.6640)  acc1_10: 92.1875 (92.0531)  acc5_10: 99.4792 (99.6304)  time: 0.1219  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.4208 (0.4238)  acc1: 93.2292 (92.7464)  acc5: 100.0000 (99.6824)  acc1_10: 91.6667 (92.0097)  acc5_10: 100.0000 (99.6570)  time: 0.1210  data: 0.0003  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.4178 (0.4219)  acc1: 92.7083 (92.7185)  acc5: 100.0000 (99.7243)  acc1_10: 91.6667 (92.0547)  acc5_10: 100.0000 (99.6834)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.4178 (0.4196)  acc1: 92.7083 (92.6300)  acc5: 100.0000 (99.7200)  acc1_10: 91.6667 (91.9900)  acc5_10: 100.0000 (99.6900)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1512 s / it)
* Acc@1 92.630 Acc@5 99.720 loss 0.420
classifiers_10 : Acc@1 91.990 Acc@5 99.690
Accuracy of the network on the 10000 test images: 92.6%
## Using lr  0.0001236 for BACKBONE, cosine lr = 0.0024700 for PRUNER
Epoch: [7]  [  0/390]  eta: 0:11:12  lr: 0.000124  loss: 2.9284 (2.9284)  time: 1.7232  data: 1.3850  max mem: 14473
Epoch: [7]  [ 10/390]  eta: 0:02:35  lr: 0.000124  loss: 2.6328 (2.6899)  time: 0.4091  data: 0.1262  max mem: 14473
Epoch: [7]  [ 20/390]  eta: 0:02:07  lr: 0.000124  loss: 2.8617 (2.8942)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [7]  [ 30/390]  eta: 0:01:55  lr: 0.000124  loss: 3.1172 (2.8827)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [7]  [ 40/390]  eta: 0:01:48  lr: 0.000124  loss: 3.3730 (3.0234)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [7]  [ 50/390]  eta: 0:01:42  lr: 0.000124  loss: 3.4135 (3.0384)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [7]  [ 60/390]  eta: 0:01:38  lr: 0.000124  loss: 2.9665 (3.0291)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [7]  [ 70/390]  eta: 0:01:34  lr: 0.000124  loss: 2.8884 (3.0273)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [7]  [ 80/390]  eta: 0:01:30  lr: 0.000124  loss: 3.2687 (3.0434)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [7]  [ 90/390]  eta: 0:01:27  lr: 0.000124  loss: 3.2687 (3.0440)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [7]  [100/390]  eta: 0:01:23  lr: 0.000124  loss: 2.9787 (3.0431)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [7]  [110/390]  eta: 0:01:20  lr: 0.000124  loss: 2.9548 (3.0394)  time: 0.2762  data: 0.0002  max mem: 14473
Epoch: [7]  [120/390]  eta: 0:01:17  lr: 0.000124  loss: 2.9326 (3.0238)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [7]  [130/390]  eta: 0:01:14  lr: 0.000124  loss: 2.6403 (2.9883)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [7]  [140/390]  eta: 0:01:11  lr: 0.000124  loss: 2.7231 (2.9935)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [7]  [150/390]  eta: 0:01:08  lr: 0.000124  loss: 3.2014 (2.9975)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [7]  [160/390]  eta: 0:01:05  lr: 0.000124  loss: 3.0299 (2.9875)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [7]  [170/390]  eta: 0:01:02  lr: 0.000124  loss: 3.0047 (3.0004)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [7]  [180/390]  eta: 0:00:59  lr: 0.000124  loss: 3.0388 (2.9948)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [7]  [190/390]  eta: 0:00:56  lr: 0.000124  loss: 2.9913 (2.9966)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [7]  [200/390]  eta: 0:00:53  lr: 0.000124  loss: 3.2778 (3.0093)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [7]  [210/390]  eta: 0:00:50  lr: 0.000124  loss: 3.3581 (3.0259)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [7]  [220/390]  eta: 0:00:47  lr: 0.000124  loss: 3.1964 (3.0213)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [7]  [230/390]  eta: 0:00:44  lr: 0.000124  loss: 2.8910 (3.0216)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [7]  [240/390]  eta: 0:00:42  lr: 0.000124  loss: 3.0814 (3.0245)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [7]  [250/390]  eta: 0:00:39  lr: 0.000124  loss: 3.0857 (3.0283)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [7]  [260/390]  eta: 0:00:36  lr: 0.000124  loss: 3.1226 (3.0324)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [7]  [270/390]  eta: 0:00:33  lr: 0.000124  loss: 3.0717 (3.0314)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [7]  [280/390]  eta: 0:00:30  lr: 0.000124  loss: 3.0099 (3.0356)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [7]  [290/390]  eta: 0:00:27  lr: 0.000124  loss: 3.2268 (3.0415)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [7]  [300/390]  eta: 0:00:25  lr: 0.000124  loss: 3.1298 (3.0330)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [7]  [310/390]  eta: 0:00:22  lr: 0.000124  loss: 3.1923 (3.0407)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [7]  [320/390]  eta: 0:00:19  lr: 0.000124  loss: 3.2905 (3.0434)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [7]  [330/390]  eta: 0:00:16  lr: 0.000124  loss: 3.2365 (3.0419)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [7]  [340/390]  eta: 0:00:13  lr: 0.000124  loss: 2.9038 (3.0398)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [7]  [350/390]  eta: 0:00:11  lr: 0.000124  loss: 2.9038 (3.0384)  time: 0.2755  data: 0.0002  max mem: 14473
Epoch: [7]  [360/390]  eta: 0:00:08  lr: 0.000124  loss: 2.9918 (3.0353)  time: 0.2757  data: 0.0002  max mem: 14473
Epoch: [7]  [370/390]  eta: 0:00:05  lr: 0.000124  loss: 3.2870 (3.0427)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [7]  [380/390]  eta: 0:00:02  lr: 0.000124  loss: 3.2870 (3.0408)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [7]  [389/390]  eta: 0:00:00  lr: 0.000124  loss: 2.9656 (3.0424)  time: 0.2738  data: 0.0001  max mem: 14473
Epoch: [7] Total time: 0:01:48 (0.2787 s / it)
Averaged stats: lr: 0.000124  loss: 2.9656 (3.0424)
Test:  [ 0/53]  eta: 0:01:27  loss: 0.3460 (0.3460)  acc1: 95.3125 (95.3125)  acc5: 99.4792 (99.4792)  acc1_10: 94.7917 (94.7917)  acc5_10: 100.0000 (100.0000)  time: 1.6551  data: 1.5169  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.3595 (0.3583)  acc1: 94.7917 (94.9337)  acc5: 100.0000 (99.7633)  acc1_10: 94.2708 (94.2235)  acc5_10: 100.0000 (99.8106)  time: 0.2667  data: 0.1382  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3660 (0.3650)  acc1: 94.7917 (94.8165)  acc5: 100.0000 (99.7520)  acc1_10: 94.2708 (94.1220)  acc5_10: 100.0000 (99.7768)  time: 0.1244  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3717 (0.3662)  acc1: 94.7917 (94.7413)  acc5: 100.0000 (99.7816)  acc1_10: 94.2708 (93.9180)  acc5_10: 100.0000 (99.7984)  time: 0.1215  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3607 (0.3634)  acc1: 95.3125 (94.8679)  acc5: 100.0000 (99.7967)  acc1_10: 94.2708 (93.9533)  acc5_10: 100.0000 (99.7840)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3525 (0.3600)  acc1: 95.3125 (94.8427)  acc5: 100.0000 (99.8366)  acc1_10: 94.2708 (94.0257)  acc5_10: 100.0000 (99.8264)  time: 0.1198  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3437 (0.3587)  acc1: 95.3125 (94.8100)  acc5: 100.0000 (99.8400)  acc1_10: 94.2708 (94.0000)  acc5_10: 100.0000 (99.8300)  time: 0.1153  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1515 s / it)
* Acc@1 94.810 Acc@5 99.840 loss 0.359
classifiers_10 : Acc@1 94.000 Acc@5 99.830
Accuracy of the network on the 10000 test images: 94.8%
## Using lr  0.0001232 for BACKBONE, cosine lr = 0.0024609 for PRUNER
Epoch: [8]  [  0/390]  eta: 0:10:24  lr: 0.000123  loss: 3.1264 (3.1264)  time: 1.6004  data: 1.2683  max mem: 14473
Epoch: [8]  [ 10/390]  eta: 0:02:32  lr: 0.000123  loss: 2.9385 (2.9318)  time: 0.4003  data: 0.1156  max mem: 14473
Epoch: [8]  [ 20/390]  eta: 0:02:05  lr: 0.000123  loss: 2.8257 (2.8537)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [8]  [ 30/390]  eta: 0:01:54  lr: 0.000123  loss: 2.8319 (2.9206)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [8]  [ 40/390]  eta: 0:01:49  lr: 0.000123  loss: 3.1698 (2.9543)  time: 0.2825  data: 0.0003  max mem: 14473
Epoch: [8]  [ 50/390]  eta: 0:01:43  lr: 0.000123  loss: 3.0904 (3.0014)  time: 0.2816  data: 0.0003  max mem: 14473
Epoch: [8]  [ 60/390]  eta: 0:01:38  lr: 0.000123  loss: 3.0904 (3.0136)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [8]  [ 70/390]  eta: 0:01:34  lr: 0.000123  loss: 3.0311 (2.9937)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [8]  [ 80/390]  eta: 0:01:30  lr: 0.000123  loss: 3.2091 (3.0251)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [8]  [ 90/390]  eta: 0:01:27  lr: 0.000123  loss: 3.2988 (3.0272)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [8]  [100/390]  eta: 0:01:23  lr: 0.000123  loss: 3.2389 (3.0384)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [8]  [110/390]  eta: 0:01:20  lr: 0.000123  loss: 3.2189 (3.0456)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [8]  [120/390]  eta: 0:01:17  lr: 0.000123  loss: 3.3060 (3.0766)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [8]  [130/390]  eta: 0:01:14  lr: 0.000123  loss: 3.3060 (3.0732)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [8]  [140/390]  eta: 0:01:11  lr: 0.000123  loss: 3.0447 (3.0720)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [8]  [150/390]  eta: 0:01:08  lr: 0.000123  loss: 3.0064 (3.0604)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [8]  [160/390]  eta: 0:01:05  lr: 0.000123  loss: 2.8552 (3.0570)  time: 0.2792  data: 0.0003  max mem: 14473
Epoch: [8]  [170/390]  eta: 0:01:02  lr: 0.000123  loss: 2.8708 (3.0574)  time: 0.2770  data: 0.0003  max mem: 14473
Epoch: [8]  [180/390]  eta: 0:00:59  lr: 0.000123  loss: 3.1780 (3.0614)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [8]  [190/390]  eta: 0:00:56  lr: 0.000123  loss: 3.3390 (3.0728)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [8]  [200/390]  eta: 0:00:53  lr: 0.000123  loss: 3.3604 (3.0709)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [8]  [210/390]  eta: 0:00:50  lr: 0.000123  loss: 2.9116 (3.0536)  time: 0.2749  data: 0.0008  max mem: 14473
Epoch: [8]  [220/390]  eta: 0:00:47  lr: 0.000123  loss: 2.7332 (3.0402)  time: 0.2751  data: 0.0008  max mem: 14473
Epoch: [8]  [230/390]  eta: 0:00:44  lr: 0.000123  loss: 3.1198 (3.0430)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [8]  [240/390]  eta: 0:00:42  lr: 0.000123  loss: 3.1835 (3.0397)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [8]  [250/390]  eta: 0:00:39  lr: 0.000123  loss: 3.0570 (3.0405)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [8]  [260/390]  eta: 0:00:36  lr: 0.000123  loss: 3.1915 (3.0436)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [8]  [270/390]  eta: 0:00:33  lr: 0.000123  loss: 3.2840 (3.0457)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [8]  [280/390]  eta: 0:00:30  lr: 0.000123  loss: 3.0907 (3.0383)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [8]  [290/390]  eta: 0:00:27  lr: 0.000123  loss: 3.1457 (3.0482)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [8]  [300/390]  eta: 0:00:25  lr: 0.000123  loss: 3.2041 (3.0465)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [8]  [310/390]  eta: 0:00:22  lr: 0.000123  loss: 2.9988 (3.0435)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [8]  [320/390]  eta: 0:00:19  lr: 0.000123  loss: 2.7760 (3.0373)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [8]  [330/390]  eta: 0:00:16  lr: 0.000123  loss: 2.7819 (3.0395)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [8]  [340/390]  eta: 0:00:13  lr: 0.000123  loss: 3.2714 (3.0421)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [8]  [350/390]  eta: 0:00:11  lr: 0.000123  loss: 3.0488 (3.0341)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [8]  [360/390]  eta: 0:00:08  lr: 0.000123  loss: 3.0285 (3.0344)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [8]  [370/390]  eta: 0:00:05  lr: 0.000123  loss: 2.9186 (3.0304)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [8]  [380/390]  eta: 0:00:02  lr: 0.000123  loss: 2.9266 (3.0300)  time: 0.2717  data: 0.0002  max mem: 14473
Epoch: [8]  [389/390]  eta: 0:00:00  lr: 0.000123  loss: 3.2822 (3.0341)  time: 0.2714  data: 0.0001  max mem: 14473
Epoch: [8] Total time: 0:01:48 (0.2783 s / it)
Averaged stats: lr: 0.000123  loss: 3.2822 (3.0341)
Test:  [ 0/53]  eta: 0:01:14  loss: 0.3943 (0.3943)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.3978  data: 1.2483  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.3920 (0.3944)  acc1: 95.3125 (94.8864)  acc5: 100.0000 (99.9527)  acc1_10: 93.7500 (94.1288)  acc5_10: 100.0000 (99.8580)  time: 0.2486  data: 0.1138  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3920 (0.3994)  acc1: 94.7917 (94.6677)  acc5: 100.0000 (99.6280)  acc1_10: 93.7500 (93.7252)  acc5_10: 100.0000 (99.6528)  time: 0.1282  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.4008 (0.4011)  acc1: 93.7500 (94.3212)  acc5: 100.0000 (99.6808)  acc1_10: 93.7500 (93.5988)  acc5_10: 100.0000 (99.6808)  time: 0.1225  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3916 (0.3971)  acc1: 94.2708 (94.6265)  acc5: 100.0000 (99.7332)  acc1_10: 93.7500 (93.8897)  acc5_10: 100.0000 (99.6951)  time: 0.1209  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3875 (0.3955)  acc1: 94.7917 (94.6283)  acc5: 100.0000 (99.7651)  acc1_10: 94.2708 (93.9338)  acc5_10: 100.0000 (99.7549)  time: 0.1192  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3875 (0.3936)  acc1: 94.7917 (94.6400)  acc5: 100.0000 (99.7600)  acc1_10: 94.2708 (93.9000)  acc5_10: 100.0000 (99.7500)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1479 s / it)
* Acc@1 94.640 Acc@5 99.760 loss 0.394
classifiers_10 : Acc@1 93.900 Acc@5 99.750
Accuracy of the network on the 10000 test images: 94.6%
## Using lr  0.0001227 for BACKBONE, cosine lr = 0.0024506 for PRUNER
Epoch: [9]  [  0/390]  eta: 0:11:46  lr: 0.000123  loss: 2.2904 (2.2904)  time: 1.8118  data: 1.4809  max mem: 14473
Epoch: [9]  [ 10/390]  eta: 0:02:38  lr: 0.000123  loss: 2.8108 (2.7075)  time: 0.4173  data: 0.1349  max mem: 14473
Epoch: [9]  [ 20/390]  eta: 0:02:09  lr: 0.000123  loss: 2.8201 (2.8109)  time: 0.2759  data: 0.0002  max mem: 14473
Epoch: [9]  [ 30/390]  eta: 0:01:56  lr: 0.000123  loss: 2.9493 (2.8772)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [9]  [ 40/390]  eta: 0:01:49  lr: 0.000123  loss: 2.9787 (2.8691)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [9]  [ 50/390]  eta: 0:01:43  lr: 0.000123  loss: 3.2253 (2.9512)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [9]  [ 60/390]  eta: 0:01:39  lr: 0.000123  loss: 3.3118 (2.9593)  time: 0.2783  data: 0.0003  max mem: 14473
Epoch: [9]  [ 70/390]  eta: 0:01:35  lr: 0.000123  loss: 3.2753 (3.0037)  time: 0.2783  data: 0.0003  max mem: 14473
Epoch: [9]  [ 80/390]  eta: 0:01:31  lr: 0.000123  loss: 3.2753 (3.0306)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [9]  [ 90/390]  eta: 0:01:27  lr: 0.000123  loss: 3.1846 (3.0128)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [9]  [100/390]  eta: 0:01:24  lr: 0.000123  loss: 3.0298 (3.0173)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [9]  [110/390]  eta: 0:01:20  lr: 0.000123  loss: 3.1310 (3.0385)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [9]  [120/390]  eta: 0:01:17  lr: 0.000123  loss: 3.1341 (3.0445)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [9]  [130/390]  eta: 0:01:14  lr: 0.000123  loss: 3.1341 (3.0414)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [9]  [140/390]  eta: 0:01:11  lr: 0.000123  loss: 3.1359 (3.0521)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [9]  [150/390]  eta: 0:01:08  lr: 0.000123  loss: 3.1555 (3.0512)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [9]  [160/390]  eta: 0:01:05  lr: 0.000123  loss: 3.2854 (3.0571)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [9]  [170/390]  eta: 0:01:02  lr: 0.000123  loss: 3.0842 (3.0505)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [9]  [180/390]  eta: 0:00:59  lr: 0.000123  loss: 2.9547 (3.0506)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [9]  [190/390]  eta: 0:00:56  lr: 0.000123  loss: 2.9792 (3.0414)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [9]  [200/390]  eta: 0:00:53  lr: 0.000123  loss: 2.9792 (3.0347)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [9]  [210/390]  eta: 0:00:50  lr: 0.000123  loss: 3.0116 (3.0364)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [9]  [220/390]  eta: 0:00:47  lr: 0.000123  loss: 3.2558 (3.0434)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [9]  [230/390]  eta: 0:00:45  lr: 0.000123  loss: 3.2558 (3.0490)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [9]  [240/390]  eta: 0:00:42  lr: 0.000123  loss: 3.1451 (3.0389)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [9]  [250/390]  eta: 0:00:39  lr: 0.000123  loss: 3.0361 (3.0409)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [9]  [260/390]  eta: 0:00:36  lr: 0.000123  loss: 3.1624 (3.0466)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [9]  [270/390]  eta: 0:00:33  lr: 0.000123  loss: 3.1211 (3.0363)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [9]  [280/390]  eta: 0:00:30  lr: 0.000123  loss: 3.1214 (3.0442)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [9]  [290/390]  eta: 0:00:28  lr: 0.000123  loss: 3.1737 (3.0458)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [9]  [300/390]  eta: 0:00:25  lr: 0.000123  loss: 3.0598 (3.0424)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [9]  [310/390]  eta: 0:00:22  lr: 0.000123  loss: 2.9875 (3.0371)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [9]  [320/390]  eta: 0:00:19  lr: 0.000123  loss: 3.3128 (3.0416)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [9]  [330/390]  eta: 0:00:16  lr: 0.000123  loss: 3.2064 (3.0341)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [9]  [340/390]  eta: 0:00:13  lr: 0.000123  loss: 3.0968 (3.0370)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [9]  [350/390]  eta: 0:00:11  lr: 0.000123  loss: 3.0628 (3.0314)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [9]  [360/390]  eta: 0:00:08  lr: 0.000123  loss: 3.0171 (3.0318)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [9]  [370/390]  eta: 0:00:05  lr: 0.000123  loss: 2.9891 (3.0254)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [9]  [380/390]  eta: 0:00:02  lr: 0.000123  loss: 2.9726 (3.0242)  time: 0.2718  data: 0.0002  max mem: 14473
Epoch: [9]  [389/390]  eta: 0:00:00  lr: 0.000123  loss: 3.0544 (3.0199)  time: 0.2711  data: 0.0001  max mem: 14473
Epoch: [9] Total time: 0:01:48 (0.2790 s / it)
Averaged stats: lr: 0.000123  loss: 3.0544 (3.0199)
Test:  [ 0/53]  eta: 0:01:25  loss: 0.3335 (0.3335)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.6128  data: 1.4542  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.3339 (0.3405)  acc1: 94.7917 (94.6970)  acc5: 100.0000 (99.9527)  acc1_10: 94.7917 (94.2708)  acc5_10: 100.0000 (99.8580)  time: 0.2627  data: 0.1325  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3409 (0.3428)  acc1: 94.7917 (94.6429)  acc5: 100.0000 (99.8016)  acc1_10: 93.7500 (94.0476)  acc5_10: 100.0000 (99.8016)  time: 0.1256  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3463 (0.3425)  acc1: 94.7917 (94.6237)  acc5: 100.0000 (99.8320)  acc1_10: 93.7500 (94.0692)  acc5_10: 100.0000 (99.8152)  time: 0.1230  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3455 (0.3438)  acc1: 94.7917 (94.6773)  acc5: 100.0000 (99.8349)  acc1_10: 94.2708 (94.0422)  acc5_10: 100.0000 (99.8476)  time: 0.1209  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3492 (0.3445)  acc1: 94.7917 (94.5670)  acc5: 100.0000 (99.8366)  acc1_10: 93.7500 (94.0462)  acc5_10: 100.0000 (99.8468)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3492 (0.3423)  acc1: 94.7917 (94.5600)  acc5: 100.0000 (99.8400)  acc1_10: 93.7500 (94.0300)  acc5_10: 100.0000 (99.8400)  time: 0.1146  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1510 s / it)
* Acc@1 94.560 Acc@5 99.840 loss 0.342
classifiers_10 : Acc@1 94.030 Acc@5 99.840
Accuracy of the network on the 10000 test images: 94.6%
## Using lr  0.0001222 for BACKBONE, cosine lr = 0.0024391 for PRUNER
Epoch: [10]  [  0/390]  eta: 0:10:58  lr: 0.000122  loss: 3.1316 (3.1316)  time: 1.6894  data: 1.3639  max mem: 14473
Epoch: [10]  [ 10/390]  eta: 0:02:35  lr: 0.000122  loss: 2.9748 (2.9524)  time: 0.4098  data: 0.1242  max mem: 14473
Epoch: [10]  [ 20/390]  eta: 0:02:07  lr: 0.000122  loss: 2.9748 (2.9801)  time: 0.2784  data: 0.0003  max mem: 14473
Epoch: [10]  [ 30/390]  eta: 0:01:56  lr: 0.000122  loss: 2.9318 (2.9119)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [10]  [ 40/390]  eta: 0:01:48  lr: 0.000122  loss: 2.9277 (2.9027)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [10]  [ 50/390]  eta: 0:01:43  lr: 0.000122  loss: 3.0171 (2.8880)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [10]  [ 60/390]  eta: 0:01:38  lr: 0.000122  loss: 3.0373 (2.9200)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [10]  [ 70/390]  eta: 0:01:34  lr: 0.000122  loss: 3.2917 (2.9768)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [10]  [ 80/390]  eta: 0:01:30  lr: 0.000122  loss: 3.3010 (2.9903)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [10]  [ 90/390]  eta: 0:01:27  lr: 0.000122  loss: 3.2502 (2.9864)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [10]  [100/390]  eta: 0:01:23  lr: 0.000122  loss: 2.7823 (2.9822)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [10]  [110/390]  eta: 0:01:20  lr: 0.000122  loss: 2.6905 (2.9649)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [10]  [120/390]  eta: 0:01:17  lr: 0.000122  loss: 2.9623 (2.9704)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [10]  [130/390]  eta: 0:01:14  lr: 0.000122  loss: 2.9623 (2.9695)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [10]  [140/390]  eta: 0:01:11  lr: 0.000122  loss: 3.1677 (2.9872)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [10]  [150/390]  eta: 0:01:08  lr: 0.000122  loss: 3.1782 (3.0065)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [10]  [160/390]  eta: 0:01:05  lr: 0.000122  loss: 3.3050 (3.0088)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [10]  [170/390]  eta: 0:01:02  lr: 0.000122  loss: 2.9458 (2.9839)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [10]  [180/390]  eta: 0:00:59  lr: 0.000122  loss: 2.3975 (2.9761)  time: 0.2723  data: 0.0002  max mem: 14473
Epoch: [10]  [190/390]  eta: 0:00:56  lr: 0.000122  loss: 2.6769 (2.9605)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [10]  [200/390]  eta: 0:00:53  lr: 0.000122  loss: 2.6749 (2.9536)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [10]  [210/390]  eta: 0:00:50  lr: 0.000122  loss: 2.9719 (2.9503)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [10]  [220/390]  eta: 0:00:47  lr: 0.000122  loss: 2.8645 (2.9410)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [10]  [230/390]  eta: 0:00:44  lr: 0.000122  loss: 2.8057 (2.9440)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [10]  [240/390]  eta: 0:00:41  lr: 0.000122  loss: 2.9078 (2.9430)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [10]  [250/390]  eta: 0:00:39  lr: 0.000122  loss: 2.9164 (2.9385)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [10]  [260/390]  eta: 0:00:36  lr: 0.000122  loss: 2.8630 (2.9372)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [10]  [270/390]  eta: 0:00:33  lr: 0.000122  loss: 3.1029 (2.9451)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [10]  [280/390]  eta: 0:00:30  lr: 0.000122  loss: 3.2619 (2.9548)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [10]  [290/390]  eta: 0:00:27  lr: 0.000122  loss: 3.2164 (2.9564)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [10]  [300/390]  eta: 0:00:25  lr: 0.000122  loss: 2.8862 (2.9485)  time: 0.2721  data: 0.0003  max mem: 14473
Epoch: [10]  [310/390]  eta: 0:00:22  lr: 0.000122  loss: 3.0458 (2.9559)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [10]  [320/390]  eta: 0:00:19  lr: 0.000122  loss: 3.2172 (2.9605)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [10]  [330/390]  eta: 0:00:16  lr: 0.000122  loss: 2.9622 (2.9533)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [10]  [340/390]  eta: 0:00:13  lr: 0.000122  loss: 2.9622 (2.9553)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [10]  [350/390]  eta: 0:00:11  lr: 0.000122  loss: 3.1285 (2.9572)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [10]  [360/390]  eta: 0:00:08  lr: 0.000122  loss: 3.0613 (2.9595)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [10]  [370/390]  eta: 0:00:05  lr: 0.000122  loss: 2.7598 (2.9508)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [10]  [380/390]  eta: 0:00:02  lr: 0.000122  loss: 2.9031 (2.9555)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [10]  [389/390]  eta: 0:00:00  lr: 0.000122  loss: 2.9173 (2.9543)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [10] Total time: 0:01:48 (0.2778 s / it)
Averaged stats: lr: 0.000122  loss: 2.9173 (2.9543)
Test:  [ 0/53]  eta: 0:01:36  loss: 0.3034 (0.3034)  acc1: 94.2708 (94.2708)  acc5: 99.4792 (99.4792)  acc1_10: 94.7917 (94.7917)  acc5_10: 100.0000 (100.0000)  time: 1.8176  data: 1.6629  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2895 (0.2953)  acc1: 95.8333 (95.7860)  acc5: 99.4792 (99.6212)  acc1_10: 95.3125 (95.7386)  acc5_10: 100.0000 (99.8580)  time: 0.2781  data: 0.1514  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3004 (0.3040)  acc1: 95.3125 (95.3373)  acc5: 99.4792 (99.6032)  acc1_10: 94.7917 (95.0645)  acc5_10: 100.0000 (99.7520)  time: 0.1234  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:04  loss: 0.3006 (0.3021)  acc1: 94.7917 (95.2789)  acc5: 100.0000 (99.6808)  acc1_10: 94.2708 (95.0269)  acc5_10: 100.0000 (99.7984)  time: 0.1227  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2885 (0.3007)  acc1: 94.7917 (95.4268)  acc5: 100.0000 (99.6824)  acc1_10: 95.3125 (95.2236)  acc5_10: 100.0000 (99.7713)  time: 0.1212  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2910 (0.2985)  acc1: 95.8333 (95.5372)  acc5: 100.0000 (99.7243)  acc1_10: 95.8333 (95.3023)  acc5_10: 100.0000 (99.7958)  time: 0.1193  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2988 (0.2988)  acc1: 95.3125 (95.5100)  acc5: 100.0000 (99.7200)  acc1_10: 95.3125 (95.2600)  acc5_10: 100.0000 (99.7900)  time: 0.1149  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1542 s / it)
* Acc@1 95.510 Acc@5 99.720 loss 0.299
classifiers_10 : Acc@1 95.260 Acc@5 99.790
Accuracy of the network on the 10000 test images: 95.5%
## Using lr  0.0001216 for BACKBONE, cosine lr = 0.0024264 for PRUNER
Epoch: [11]  [  0/390]  eta: 0:11:15  lr: 0.000122  loss: 3.3840 (3.3840)  time: 1.7311  data: 1.4278  max mem: 14473
Epoch: [11]  [ 10/390]  eta: 0:02:35  lr: 0.000122  loss: 2.9212 (2.8351)  time: 0.4088  data: 0.1301  max mem: 14473
Epoch: [11]  [ 20/390]  eta: 0:02:07  lr: 0.000122  loss: 2.8789 (2.8636)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [11]  [ 30/390]  eta: 0:01:55  lr: 0.000122  loss: 3.1004 (2.9497)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [11]  [ 40/390]  eta: 0:01:48  lr: 0.000122  loss: 3.1199 (2.9398)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [11]  [ 50/390]  eta: 0:01:42  lr: 0.000122  loss: 3.0579 (2.9257)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [11]  [ 60/390]  eta: 0:01:38  lr: 0.000122  loss: 3.0666 (2.9038)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [11]  [ 70/390]  eta: 0:01:34  lr: 0.000122  loss: 3.1118 (2.9320)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [11]  [ 80/390]  eta: 0:01:30  lr: 0.000122  loss: 3.2211 (2.9477)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [11]  [ 90/390]  eta: 0:01:26  lr: 0.000122  loss: 3.1227 (2.9484)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [11]  [100/390]  eta: 0:01:23  lr: 0.000122  loss: 2.8902 (2.9556)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [11]  [110/390]  eta: 0:01:20  lr: 0.000122  loss: 3.1048 (2.9696)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [11]  [120/390]  eta: 0:01:17  lr: 0.000122  loss: 3.0766 (2.9735)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [11]  [130/390]  eta: 0:01:14  lr: 0.000122  loss: 2.9543 (2.9594)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [11]  [140/390]  eta: 0:01:10  lr: 0.000122  loss: 2.6498 (2.9460)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [11]  [150/390]  eta: 0:01:07  lr: 0.000122  loss: 3.1917 (2.9594)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [11]  [160/390]  eta: 0:01:04  lr: 0.000122  loss: 3.1966 (2.9636)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [11]  [170/390]  eta: 0:01:02  lr: 0.000122  loss: 2.8641 (2.9475)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [11]  [180/390]  eta: 0:00:59  lr: 0.000122  loss: 3.0935 (2.9660)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [11]  [190/390]  eta: 0:00:56  lr: 0.000122  loss: 3.2921 (2.9691)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [11]  [200/390]  eta: 0:00:53  lr: 0.000122  loss: 2.8824 (2.9515)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [11]  [210/390]  eta: 0:00:50  lr: 0.000122  loss: 2.8870 (2.9582)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [11]  [220/390]  eta: 0:00:47  lr: 0.000122  loss: 3.2169 (2.9669)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [11]  [230/390]  eta: 0:00:44  lr: 0.000122  loss: 3.0487 (2.9593)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [11]  [240/390]  eta: 0:00:41  lr: 0.000122  loss: 3.0732 (2.9605)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [11]  [250/390]  eta: 0:00:39  lr: 0.000122  loss: 3.0838 (2.9571)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [11]  [260/390]  eta: 0:00:36  lr: 0.000122  loss: 3.0470 (2.9592)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [11]  [270/390]  eta: 0:00:33  lr: 0.000122  loss: 3.0181 (2.9587)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [11]  [280/390]  eta: 0:00:30  lr: 0.000122  loss: 3.0465 (2.9624)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [11]  [290/390]  eta: 0:00:27  lr: 0.000122  loss: 3.0967 (2.9682)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [11]  [300/390]  eta: 0:00:25  lr: 0.000122  loss: 3.1095 (2.9732)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [11]  [310/390]  eta: 0:00:22  lr: 0.000122  loss: 3.0742 (2.9702)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [11]  [320/390]  eta: 0:00:19  lr: 0.000122  loss: 2.8191 (2.9644)  time: 0.2822  data: 0.0002  max mem: 14473
Epoch: [11]  [330/390]  eta: 0:00:16  lr: 0.000122  loss: 2.8191 (2.9670)  time: 0.2831  data: 0.0003  max mem: 14473
Epoch: [11]  [340/390]  eta: 0:00:13  lr: 0.000122  loss: 3.0320 (2.9650)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [11]  [350/390]  eta: 0:00:11  lr: 0.000122  loss: 3.0538 (2.9709)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [11]  [360/390]  eta: 0:00:08  lr: 0.000122  loss: 3.0538 (2.9682)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [11]  [370/390]  eta: 0:00:05  lr: 0.000122  loss: 3.0907 (2.9735)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [11]  [380/390]  eta: 0:00:02  lr: 0.000122  loss: 3.0907 (2.9752)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [11]  [389/390]  eta: 0:00:00  lr: 0.000122  loss: 3.0705 (2.9755)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [11] Total time: 0:01:48 (0.2781 s / it)
Averaged stats: lr: 0.000122  loss: 3.0705 (2.9755)
Test:  [ 0/53]  eta: 0:01:14  loss: 0.3195 (0.3195)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 94.2708 (94.2708)  acc5_10: 100.0000 (100.0000)  time: 1.4114  data: 1.2520  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2972 (0.2960)  acc1: 96.3542 (96.0227)  acc5: 100.0000 (99.8580)  acc1_10: 95.8333 (95.5492)  acc5_10: 100.0000 (99.8580)  time: 0.2496  data: 0.1142  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2979 (0.3079)  acc1: 95.8333 (95.5109)  acc5: 100.0000 (99.7520)  acc1_10: 94.7917 (94.9653)  acc5_10: 100.0000 (99.7520)  time: 0.1281  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3077 (0.3059)  acc1: 94.7917 (95.5813)  acc5: 100.0000 (99.7816)  acc1_10: 94.7917 (95.1613)  acc5_10: 100.0000 (99.7984)  time: 0.1221  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3006 (0.3036)  acc1: 95.8333 (95.8079)  acc5: 100.0000 (99.8095)  acc1_10: 95.8333 (95.4395)  acc5_10: 100.0000 (99.7967)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2955 (0.3035)  acc1: 95.8333 (95.8129)  acc5: 100.0000 (99.8366)  acc1_10: 95.8333 (95.5168)  acc5_10: 100.0000 (99.8162)  time: 0.1189  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2988 (0.3022)  acc1: 95.8333 (95.8100)  acc5: 100.0000 (99.8400)  acc1_10: 95.8333 (95.4900)  acc5_10: 100.0000 (99.8200)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1479 s / it)
* Acc@1 95.810 Acc@5 99.840 loss 0.302
classifiers_10 : Acc@1 95.490 Acc@5 99.820
Accuracy of the network on the 10000 test images: 95.8%
## Using lr  0.0001210 for BACKBONE, cosine lr = 0.0024126 for PRUNER
Epoch: [12]  [  0/390]  eta: 0:10:10  lr: 0.000121  loss: 2.9871 (2.9871)  time: 1.5648  data: 1.2322  max mem: 14473
Epoch: [12]  [ 10/390]  eta: 0:02:30  lr: 0.000121  loss: 3.1359 (3.0067)  time: 0.3951  data: 0.1123  max mem: 14473
Epoch: [12]  [ 20/390]  eta: 0:02:04  lr: 0.000121  loss: 3.2219 (3.0843)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [12]  [ 30/390]  eta: 0:01:53  lr: 0.000121  loss: 3.2246 (3.0131)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [12]  [ 40/390]  eta: 0:01:47  lr: 0.000121  loss: 3.2246 (3.0476)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [12]  [ 50/390]  eta: 0:01:42  lr: 0.000121  loss: 3.2064 (2.9947)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [12]  [ 60/390]  eta: 0:01:37  lr: 0.000121  loss: 3.1485 (3.0168)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [12]  [ 70/390]  eta: 0:01:33  lr: 0.000121  loss: 3.1977 (3.0047)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [12]  [ 80/390]  eta: 0:01:30  lr: 0.000121  loss: 3.0840 (2.9925)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [12]  [ 90/390]  eta: 0:01:26  lr: 0.000121  loss: 2.9998 (2.9762)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [12]  [100/390]  eta: 0:01:23  lr: 0.000121  loss: 3.0158 (2.9786)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [12]  [110/390]  eta: 0:01:20  lr: 0.000121  loss: 3.0841 (2.9749)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [12]  [120/390]  eta: 0:01:16  lr: 0.000121  loss: 3.0137 (2.9635)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [12]  [130/390]  eta: 0:01:13  lr: 0.000121  loss: 2.8844 (2.9588)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [12]  [140/390]  eta: 0:01:10  lr: 0.000121  loss: 2.9415 (2.9644)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [12]  [150/390]  eta: 0:01:07  lr: 0.000121  loss: 2.9748 (2.9500)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [12]  [160/390]  eta: 0:01:04  lr: 0.000121  loss: 2.9748 (2.9556)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [12]  [170/390]  eta: 0:01:01  lr: 0.000121  loss: 3.1698 (2.9512)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [12]  [180/390]  eta: 0:00:59  lr: 0.000121  loss: 2.9325 (2.9385)  time: 0.2735  data: 0.0002  max mem: 14473
Epoch: [12]  [190/390]  eta: 0:00:56  lr: 0.000121  loss: 2.5087 (2.9194)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [12]  [200/390]  eta: 0:00:53  lr: 0.000121  loss: 2.6928 (2.9192)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [12]  [210/390]  eta: 0:00:50  lr: 0.000121  loss: 3.0120 (2.9211)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [12]  [220/390]  eta: 0:00:47  lr: 0.000121  loss: 2.9482 (2.9138)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [12]  [230/390]  eta: 0:00:44  lr: 0.000121  loss: 2.7436 (2.9134)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [12]  [240/390]  eta: 0:00:41  lr: 0.000121  loss: 3.0828 (2.9194)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [12]  [250/390]  eta: 0:00:39  lr: 0.000121  loss: 3.0828 (2.9181)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [12]  [260/390]  eta: 0:00:36  lr: 0.000121  loss: 3.1868 (2.9277)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [12]  [270/390]  eta: 0:00:33  lr: 0.000121  loss: 3.1981 (2.9254)  time: 0.2755  data: 0.0002  max mem: 14473
Epoch: [12]  [280/390]  eta: 0:00:30  lr: 0.000121  loss: 2.9652 (2.9287)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [12]  [290/390]  eta: 0:00:27  lr: 0.000121  loss: 2.9373 (2.9246)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [12]  [300/390]  eta: 0:00:25  lr: 0.000121  loss: 3.0827 (2.9364)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [12]  [310/390]  eta: 0:00:22  lr: 0.000121  loss: 3.1669 (2.9387)  time: 0.2755  data: 0.0007  max mem: 14473
Epoch: [12]  [320/390]  eta: 0:00:19  lr: 0.000121  loss: 3.1115 (2.9445)  time: 0.2749  data: 0.0007  max mem: 14473
Epoch: [12]  [330/390]  eta: 0:00:16  lr: 0.000121  loss: 3.0258 (2.9415)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [12]  [340/390]  eta: 0:00:13  lr: 0.000121  loss: 3.0695 (2.9446)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [12]  [350/390]  eta: 0:00:11  lr: 0.000121  loss: 3.0003 (2.9400)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [12]  [360/390]  eta: 0:00:08  lr: 0.000121  loss: 2.9754 (2.9394)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [12]  [370/390]  eta: 0:00:05  lr: 0.000121  loss: 2.9940 (2.9372)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [12]  [380/390]  eta: 0:00:02  lr: 0.000121  loss: 3.0504 (2.9416)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [12]  [389/390]  eta: 0:00:00  lr: 0.000121  loss: 2.9630 (2.9379)  time: 0.2729  data: 0.0001  max mem: 14473
Epoch: [12] Total time: 0:01:48 (0.2776 s / it)
Averaged stats: lr: 0.000121  loss: 2.9630 (2.9379)
Test:  [ 0/53]  eta: 0:01:12  loss: 0.3420 (0.3420)  acc1: 95.8333 (95.8333)  acc5: 98.9583 (98.9583)  acc1_10: 95.3125 (95.3125)  acc5_10: 99.4792 (99.4792)  time: 1.3678  data: 1.2058  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.3357 (0.3353)  acc1: 95.8333 (95.4072)  acc5: 100.0000 (99.8106)  acc1_10: 94.7917 (95.0284)  acc5_10: 100.0000 (99.8106)  time: 0.2567  data: 0.1223  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3398 (0.3451)  acc1: 94.7917 (95.1141)  acc5: 100.0000 (99.6280)  acc1_10: 94.7917 (94.3700)  acc5_10: 100.0000 (99.7024)  time: 0.1339  data: 0.0071  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3458 (0.3441)  acc1: 94.7917 (94.9765)  acc5: 99.4792 (99.6640)  acc1_10: 94.2708 (94.4220)  acc5_10: 100.0000 (99.7480)  time: 0.1222  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3343 (0.3423)  acc1: 95.3125 (95.1347)  acc5: 100.0000 (99.6951)  acc1_10: 94.7917 (94.5503)  acc5_10: 100.0000 (99.7840)  time: 0.1211  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3343 (0.3414)  acc1: 95.3125 (95.1185)  acc5: 100.0000 (99.7345)  acc1_10: 94.7917 (94.5772)  acc5_10: 100.0000 (99.7958)  time: 0.1193  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3313 (0.3390)  acc1: 95.3125 (95.1200)  acc5: 100.0000 (99.7400)  acc1_10: 94.7917 (94.5900)  acc5_10: 100.0000 (99.8000)  time: 0.1147  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1495 s / it)
* Acc@1 95.120 Acc@5 99.740 loss 0.339
classifiers_10 : Acc@1 94.590 Acc@5 99.800
Accuracy of the network on the 10000 test images: 95.1%
## Using lr  0.0001203 for BACKBONE, cosine lr = 0.0023976 for PRUNER
Epoch: [13]  [  0/390]  eta: 0:11:01  lr: 0.000120  loss: 2.0893 (2.0893)  time: 1.6964  data: 1.3542  max mem: 14473
Epoch: [13]  [ 10/390]  eta: 0:02:35  lr: 0.000120  loss: 2.9365 (2.7590)  time: 0.4079  data: 0.1234  max mem: 14473
Epoch: [13]  [ 20/390]  eta: 0:02:07  lr: 0.000120  loss: 2.9314 (2.7881)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [13]  [ 30/390]  eta: 0:01:55  lr: 0.000120  loss: 2.7541 (2.7276)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [13]  [ 40/390]  eta: 0:01:48  lr: 0.000120  loss: 2.8050 (2.8124)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [13]  [ 50/390]  eta: 0:01:42  lr: 0.000120  loss: 3.0480 (2.8260)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [13]  [ 60/390]  eta: 0:01:38  lr: 0.000120  loss: 3.0480 (2.8716)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [13]  [ 70/390]  eta: 0:01:34  lr: 0.000120  loss: 3.1674 (2.9088)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [13]  [ 80/390]  eta: 0:01:30  lr: 0.000120  loss: 3.1674 (2.9126)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [13]  [ 90/390]  eta: 0:01:27  lr: 0.000120  loss: 2.9576 (2.9146)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [13]  [100/390]  eta: 0:01:23  lr: 0.000120  loss: 2.9296 (2.9154)  time: 0.2778  data: 0.0003  max mem: 14473
Epoch: [13]  [110/390]  eta: 0:01:20  lr: 0.000120  loss: 3.2180 (2.9389)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [13]  [120/390]  eta: 0:01:17  lr: 0.000120  loss: 3.1317 (2.9201)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [13]  [130/390]  eta: 0:01:14  lr: 0.000120  loss: 2.9297 (2.9265)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [13]  [140/390]  eta: 0:01:11  lr: 0.000120  loss: 3.2082 (2.9388)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [13]  [150/390]  eta: 0:01:08  lr: 0.000120  loss: 3.1822 (2.9397)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [13]  [160/390]  eta: 0:01:05  lr: 0.000120  loss: 2.9753 (2.9282)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [13]  [170/390]  eta: 0:01:02  lr: 0.000120  loss: 3.1562 (2.9476)  time: 0.2720  data: 0.0003  max mem: 14473
Epoch: [13]  [180/390]  eta: 0:00:59  lr: 0.000120  loss: 3.1562 (2.9418)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [13]  [190/390]  eta: 0:00:56  lr: 0.000120  loss: 2.9765 (2.9427)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [13]  [200/390]  eta: 0:00:53  lr: 0.000120  loss: 3.0677 (2.9429)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [13]  [210/390]  eta: 0:00:50  lr: 0.000120  loss: 3.1599 (2.9480)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [13]  [220/390]  eta: 0:00:47  lr: 0.000120  loss: 3.0743 (2.9521)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [13]  [230/390]  eta: 0:00:44  lr: 0.000120  loss: 3.1448 (2.9568)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [13]  [240/390]  eta: 0:00:42  lr: 0.000120  loss: 3.1109 (2.9558)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [13]  [250/390]  eta: 0:00:39  lr: 0.000120  loss: 2.7088 (2.9427)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [13]  [260/390]  eta: 0:00:36  lr: 0.000120  loss: 2.7088 (2.9438)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [13]  [270/390]  eta: 0:00:33  lr: 0.000120  loss: 3.0865 (2.9453)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [13]  [280/390]  eta: 0:00:30  lr: 0.000120  loss: 3.1835 (2.9497)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [13]  [290/390]  eta: 0:00:27  lr: 0.000120  loss: 3.0692 (2.9409)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [13]  [300/390]  eta: 0:00:25  lr: 0.000120  loss: 2.6342 (2.9360)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [13]  [310/390]  eta: 0:00:22  lr: 0.000120  loss: 2.6744 (2.9370)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [13]  [320/390]  eta: 0:00:19  lr: 0.000120  loss: 2.9962 (2.9296)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [13]  [330/390]  eta: 0:00:16  lr: 0.000120  loss: 3.0938 (2.9397)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [13]  [340/390]  eta: 0:00:13  lr: 0.000120  loss: 3.0786 (2.9383)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [13]  [350/390]  eta: 0:00:11  lr: 0.000120  loss: 2.9245 (2.9394)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [13]  [360/390]  eta: 0:00:08  lr: 0.000120  loss: 2.9719 (2.9326)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [13]  [370/390]  eta: 0:00:05  lr: 0.000120  loss: 2.8728 (2.9312)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [13]  [380/390]  eta: 0:00:02  lr: 0.000120  loss: 3.0735 (2.9351)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [13]  [389/390]  eta: 0:00:00  lr: 0.000120  loss: 3.0863 (2.9343)  time: 0.2713  data: 0.0001  max mem: 14473
Epoch: [13] Total time: 0:01:48 (0.2785 s / it)
Averaged stats: lr: 0.000120  loss: 3.0863 (2.9343)
Test:  [ 0/53]  eta: 0:00:58  loss: 0.3190 (0.3190)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.1024  data: 0.9590  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.3078 (0.3093)  acc1: 95.8333 (95.7386)  acc5: 100.0000 (99.9527)  acc1_10: 96.3542 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 0.2454  data: 0.1086  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3107 (0.3187)  acc1: 95.3125 (95.3869)  acc5: 100.0000 (99.7768)  acc1_10: 95.3125 (95.4365)  acc5_10: 100.0000 (99.8016)  time: 0.1417  data: 0.0119  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3211 (0.3188)  acc1: 95.3125 (95.4133)  acc5: 100.0000 (99.7984)  acc1_10: 95.3125 (95.2621)  acc5_10: 100.0000 (99.8320)  time: 0.1227  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3166 (0.3176)  acc1: 95.8333 (95.4776)  acc5: 100.0000 (99.8095)  acc1_10: 95.3125 (95.4014)  acc5_10: 100.0000 (99.8222)  time: 0.1207  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3166 (0.3164)  acc1: 95.8333 (95.4555)  acc5: 100.0000 (99.8366)  acc1_10: 95.3125 (95.4248)  acc5_10: 100.0000 (99.8570)  time: 0.1195  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2964 (0.3146)  acc1: 95.8333 (95.4400)  acc5: 100.0000 (99.8400)  acc1_10: 95.8333 (95.4200)  acc5_10: 100.0000 (99.8500)  time: 0.1150  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1475 s / it)
* Acc@1 95.440 Acc@5 99.840 loss 0.315
classifiers_10 : Acc@1 95.420 Acc@5 99.850
Accuracy of the network on the 10000 test images: 95.4%
## Using lr  0.0001195 for BACKBONE, cosine lr = 0.0023815 for PRUNER
Epoch: [14]  [  0/390]  eta: 0:11:06  lr: 0.000120  loss: 3.2743 (3.2743)  time: 1.7088  data: 1.3783  max mem: 14473
Epoch: [14]  [ 10/390]  eta: 0:02:35  lr: 0.000120  loss: 3.2197 (3.0421)  time: 0.4083  data: 0.1255  max mem: 14473
Epoch: [14]  [ 20/390]  eta: 0:02:07  lr: 0.000120  loss: 3.0006 (2.9441)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [14]  [ 30/390]  eta: 0:01:55  lr: 0.000120  loss: 3.0006 (2.9204)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [14]  [ 40/390]  eta: 0:01:48  lr: 0.000120  loss: 3.0624 (2.8992)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [14]  [ 50/390]  eta: 0:01:42  lr: 0.000120  loss: 3.0624 (2.9071)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [14]  [ 60/390]  eta: 0:01:38  lr: 0.000120  loss: 3.1394 (2.9064)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [14]  [ 70/390]  eta: 0:01:34  lr: 0.000120  loss: 3.0628 (2.8994)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [14]  [ 80/390]  eta: 0:01:30  lr: 0.000120  loss: 3.0211 (2.8903)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [14]  [ 90/390]  eta: 0:01:26  lr: 0.000120  loss: 2.9063 (2.8631)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [14]  [100/390]  eta: 0:01:23  lr: 0.000120  loss: 2.7718 (2.8504)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [14]  [110/390]  eta: 0:01:20  lr: 0.000120  loss: 2.9654 (2.8701)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [14]  [120/390]  eta: 0:01:17  lr: 0.000120  loss: 3.0738 (2.8612)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [14]  [130/390]  eta: 0:01:13  lr: 0.000120  loss: 2.9839 (2.8746)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [14]  [140/390]  eta: 0:01:10  lr: 0.000120  loss: 2.9839 (2.8760)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [14]  [150/390]  eta: 0:01:07  lr: 0.000120  loss: 2.8208 (2.8730)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [14]  [160/390]  eta: 0:01:04  lr: 0.000120  loss: 3.0300 (2.8707)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [14]  [170/390]  eta: 0:01:01  lr: 0.000120  loss: 3.0946 (2.8798)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [14]  [180/390]  eta: 0:00:59  lr: 0.000120  loss: 3.1960 (2.8946)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [14]  [190/390]  eta: 0:00:56  lr: 0.000120  loss: 2.9972 (2.8821)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [14]  [200/390]  eta: 0:00:53  lr: 0.000120  loss: 2.7798 (2.8836)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [14]  [210/390]  eta: 0:00:50  lr: 0.000120  loss: 2.7710 (2.8795)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [14]  [220/390]  eta: 0:00:47  lr: 0.000120  loss: 2.8158 (2.8827)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [14]  [230/390]  eta: 0:00:44  lr: 0.000120  loss: 3.0222 (2.8879)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [14]  [240/390]  eta: 0:00:41  lr: 0.000120  loss: 3.1906 (2.8909)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [14]  [250/390]  eta: 0:00:39  lr: 0.000120  loss: 3.0728 (2.8861)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [14]  [260/390]  eta: 0:00:36  lr: 0.000120  loss: 3.0167 (2.8881)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [14]  [270/390]  eta: 0:00:33  lr: 0.000120  loss: 2.7390 (2.8788)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [14]  [280/390]  eta: 0:00:30  lr: 0.000120  loss: 2.7390 (2.8822)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [14]  [290/390]  eta: 0:00:27  lr: 0.000120  loss: 3.0419 (2.8831)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [14]  [300/390]  eta: 0:00:25  lr: 0.000120  loss: 3.0904 (2.8893)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [14]  [310/390]  eta: 0:00:22  lr: 0.000120  loss: 3.0546 (2.8881)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [14]  [320/390]  eta: 0:00:19  lr: 0.000120  loss: 2.9651 (2.8865)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [14]  [330/390]  eta: 0:00:16  lr: 0.000120  loss: 3.1490 (2.8878)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [14]  [340/390]  eta: 0:00:13  lr: 0.000120  loss: 2.9746 (2.8884)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [14]  [350/390]  eta: 0:00:11  lr: 0.000120  loss: 2.9746 (2.8921)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [14]  [360/390]  eta: 0:00:08  lr: 0.000120  loss: 2.9624 (2.8889)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [14]  [370/390]  eta: 0:00:05  lr: 0.000120  loss: 3.0981 (2.8948)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [14]  [380/390]  eta: 0:00:02  lr: 0.000120  loss: 3.0487 (2.8925)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [14]  [389/390]  eta: 0:00:00  lr: 0.000120  loss: 2.8867 (2.8940)  time: 0.2718  data: 0.0001  max mem: 14473
Epoch: [14] Total time: 0:01:48 (0.2777 s / it)
Averaged stats: lr: 0.000120  loss: 2.8867 (2.8940)
Test:  [ 0/53]  eta: 0:01:00  loss: 0.2868 (0.2868)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.1505  data: 1.0149  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2862 (0.2929)  acc1: 96.8750 (96.4962)  acc5: 99.4792 (99.7159)  acc1_10: 96.3542 (96.0701)  acc5_10: 100.0000 (99.7633)  time: 0.2491  data: 0.1132  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2928 (0.3026)  acc1: 96.3542 (95.9325)  acc5: 99.4792 (99.7024)  acc1_10: 95.3125 (95.5109)  acc5_10: 99.4792 (99.6776)  time: 0.1412  data: 0.0117  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2968 (0.3028)  acc1: 95.3125 (95.8669)  acc5: 100.0000 (99.7480)  acc1_10: 95.3125 (95.5477)  acc5_10: 100.0000 (99.7144)  time: 0.1234  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2990 (0.3026)  acc1: 95.8333 (95.9604)  acc5: 100.0000 (99.7586)  acc1_10: 95.3125 (95.5920)  acc5_10: 100.0000 (99.7332)  time: 0.1213  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2990 (0.3020)  acc1: 96.3542 (95.9048)  acc5: 100.0000 (99.8060)  acc1_10: 95.3125 (95.5576)  acc5_10: 100.0000 (99.7753)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2938 (0.3013)  acc1: 95.8333 (95.9000)  acc5: 100.0000 (99.8100)  acc1_10: 95.3125 (95.5400)  acc5_10: 100.0000 (99.7800)  time: 0.1147  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1484 s / it)
* Acc@1 95.900 Acc@5 99.810 loss 0.301
classifiers_10 : Acc@1 95.540 Acc@5 99.780
Accuracy of the network on the 10000 test images: 95.9%
## Using lr  0.0001187 for BACKBONE, cosine lr = 0.0023643 for PRUNER
Epoch: [15]  [  0/390]  eta: 0:11:05  lr: 0.000119  loss: 2.1723 (2.1723)  time: 1.7058  data: 1.3804  max mem: 14473
Epoch: [15]  [ 10/390]  eta: 0:02:35  lr: 0.000119  loss: 2.8233 (2.8521)  time: 0.4090  data: 0.1258  max mem: 14473
Epoch: [15]  [ 20/390]  eta: 0:02:08  lr: 0.000119  loss: 3.1121 (3.0152)  time: 0.2785  data: 0.0003  max mem: 14473
Epoch: [15]  [ 30/390]  eta: 0:01:56  lr: 0.000119  loss: 3.1121 (3.0156)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [15]  [ 40/390]  eta: 0:01:49  lr: 0.000119  loss: 3.0536 (3.0045)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [15]  [ 50/390]  eta: 0:01:43  lr: 0.000119  loss: 2.5768 (2.8998)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [15]  [ 60/390]  eta: 0:01:38  lr: 0.000119  loss: 2.6694 (2.9265)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [15]  [ 70/390]  eta: 0:01:34  lr: 0.000119  loss: 3.0629 (2.9400)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [15]  [ 80/390]  eta: 0:01:30  lr: 0.000119  loss: 3.1228 (2.9412)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [15]  [ 90/390]  eta: 0:01:27  lr: 0.000119  loss: 3.1923 (2.9491)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [15]  [100/390]  eta: 0:01:23  lr: 0.000119  loss: 3.0990 (2.9502)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [15]  [110/390]  eta: 0:01:20  lr: 0.000119  loss: 2.9914 (2.9119)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [15]  [120/390]  eta: 0:01:17  lr: 0.000119  loss: 2.6304 (2.9125)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [15]  [130/390]  eta: 0:01:14  lr: 0.000119  loss: 3.0550 (2.9274)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [15]  [140/390]  eta: 0:01:11  lr: 0.000119  loss: 2.9674 (2.9265)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [15]  [150/390]  eta: 0:01:08  lr: 0.000119  loss: 2.9086 (2.9295)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [15]  [160/390]  eta: 0:01:05  lr: 0.000119  loss: 3.0830 (2.9311)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [15]  [170/390]  eta: 0:01:02  lr: 0.000119  loss: 2.9238 (2.9298)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [15]  [180/390]  eta: 0:00:59  lr: 0.000119  loss: 2.9163 (2.9237)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [15]  [190/390]  eta: 0:00:56  lr: 0.000119  loss: 2.7492 (2.9082)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [15]  [200/390]  eta: 0:00:53  lr: 0.000119  loss: 2.7514 (2.9056)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [15]  [210/390]  eta: 0:00:50  lr: 0.000119  loss: 2.8206 (2.9080)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [15]  [220/390]  eta: 0:00:47  lr: 0.000119  loss: 3.0961 (2.9205)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [15]  [230/390]  eta: 0:00:44  lr: 0.000119  loss: 3.1370 (2.9214)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [15]  [240/390]  eta: 0:00:42  lr: 0.000119  loss: 3.0688 (2.9244)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [15]  [250/390]  eta: 0:00:39  lr: 0.000119  loss: 2.9326 (2.9164)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [15]  [260/390]  eta: 0:00:36  lr: 0.000119  loss: 2.6358 (2.9059)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [15]  [270/390]  eta: 0:00:33  lr: 0.000119  loss: 2.7981 (2.9059)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [15]  [280/390]  eta: 0:00:30  lr: 0.000119  loss: 2.9873 (2.9024)  time: 0.2847  data: 0.0003  max mem: 14473
Epoch: [15]  [290/390]  eta: 0:00:28  lr: 0.000119  loss: 2.7088 (2.8969)  time: 0.2850  data: 0.0003  max mem: 14473
Epoch: [15]  [300/390]  eta: 0:00:25  lr: 0.000119  loss: 2.6626 (2.8907)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [15]  [310/390]  eta: 0:00:22  lr: 0.000119  loss: 2.7269 (2.8934)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [15]  [320/390]  eta: 0:00:19  lr: 0.000119  loss: 2.8850 (2.8963)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [15]  [330/390]  eta: 0:00:16  lr: 0.000119  loss: 3.0202 (2.9036)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [15]  [340/390]  eta: 0:00:13  lr: 0.000119  loss: 3.1222 (2.9044)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [15]  [350/390]  eta: 0:00:11  lr: 0.000119  loss: 3.1370 (2.9074)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [15]  [360/390]  eta: 0:00:08  lr: 0.000119  loss: 2.7312 (2.8990)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [15]  [370/390]  eta: 0:00:05  lr: 0.000119  loss: 2.7201 (2.8950)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [15]  [380/390]  eta: 0:00:02  lr: 0.000119  loss: 2.8416 (2.8929)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [15]  [389/390]  eta: 0:00:00  lr: 0.000119  loss: 3.0053 (2.8965)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [15] Total time: 0:01:48 (0.2792 s / it)
Averaged stats: lr: 0.000119  loss: 3.0053 (2.8965)
Test:  [ 0/53]  eta: 0:01:31  loss: 0.2923 (0.2923)  acc1: 95.8333 (95.8333)  acc5: 99.4792 (99.4792)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.7256  data: 1.5692  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2801 (0.2841)  acc1: 96.3542 (96.4015)  acc5: 100.0000 (99.8580)  acc1_10: 95.8333 (95.8807)  acc5_10: 100.0000 (99.9053)  time: 0.2708  data: 0.1429  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3034 (0.2988)  acc1: 95.8333 (95.7837)  acc5: 100.0000 (99.7272)  acc1_10: 95.8333 (95.4861)  acc5_10: 100.0000 (99.7024)  time: 0.1235  data: 0.0002  max mem: 14473
Test:  [30/53]  eta: 0:00:04  loss: 0.3048 (0.2998)  acc1: 95.3125 (95.6149)  acc5: 100.0000 (99.7648)  acc1_10: 95.3125 (95.3965)  acc5_10: 99.4792 (99.7312)  time: 0.1217  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2971 (0.3008)  acc1: 95.8333 (95.6936)  acc5: 100.0000 (99.7459)  acc1_10: 95.3125 (95.4776)  acc5_10: 100.0000 (99.7332)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2981 (0.2996)  acc1: 95.8333 (95.6904)  acc5: 100.0000 (99.7855)  acc1_10: 95.3125 (95.5168)  acc5_10: 100.0000 (99.7651)  time: 0.1194  data: 0.0002  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2817 (0.2973)  acc1: 96.3542 (95.7200)  acc5: 100.0000 (99.7900)  acc1_10: 95.8333 (95.5400)  acc5_10: 100.0000 (99.7700)  time: 0.1154  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1524 s / it)
* Acc@1 95.720 Acc@5 99.790 loss 0.297
classifiers_10 : Acc@1 95.540 Acc@5 99.770
Accuracy of the network on the 10000 test images: 95.7%
## Using lr  0.0001179 for BACKBONE, cosine lr = 0.0023460 for PRUNER
Epoch: [16]  [  0/390]  eta: 0:10:33  lr: 0.000118  loss: 3.1741 (3.1741)  time: 1.6252  data: 1.2847  max mem: 14473
Epoch: [16]  [ 10/390]  eta: 0:02:32  lr: 0.000118  loss: 3.1354 (3.0694)  time: 0.4020  data: 0.1171  max mem: 14473
Epoch: [16]  [ 20/390]  eta: 0:02:06  lr: 0.000118  loss: 3.1035 (2.9589)  time: 0.2784  data: 0.0003  max mem: 14473
Epoch: [16]  [ 30/390]  eta: 0:01:55  lr: 0.000118  loss: 3.0178 (3.0129)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [16]  [ 40/390]  eta: 0:01:48  lr: 0.000118  loss: 3.1141 (2.9791)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [16]  [ 50/390]  eta: 0:01:42  lr: 0.000118  loss: 2.9918 (2.9800)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [16]  [ 60/390]  eta: 0:01:38  lr: 0.000118  loss: 3.0124 (2.9990)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [16]  [ 70/390]  eta: 0:01:34  lr: 0.000118  loss: 3.2420 (3.0317)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [16]  [ 80/390]  eta: 0:01:30  lr: 0.000118  loss: 3.0480 (3.0036)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [16]  [ 90/390]  eta: 0:01:26  lr: 0.000118  loss: 3.0205 (2.9882)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [16]  [100/390]  eta: 0:01:23  lr: 0.000118  loss: 3.0245 (2.9805)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [16]  [110/390]  eta: 0:01:20  lr: 0.000118  loss: 3.0343 (2.9708)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [16]  [120/390]  eta: 0:01:17  lr: 0.000118  loss: 3.0607 (2.9607)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [16]  [130/390]  eta: 0:01:14  lr: 0.000118  loss: 2.9419 (2.9531)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [16]  [140/390]  eta: 0:01:10  lr: 0.000118  loss: 3.0379 (2.9624)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [16]  [150/390]  eta: 0:01:07  lr: 0.000118  loss: 2.9235 (2.9561)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [16]  [160/390]  eta: 0:01:05  lr: 0.000118  loss: 2.8336 (2.9493)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [16]  [170/390]  eta: 0:01:02  lr: 0.000118  loss: 2.8848 (2.9401)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [16]  [180/390]  eta: 0:00:59  lr: 0.000118  loss: 3.0911 (2.9504)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [16]  [190/390]  eta: 0:00:56  lr: 0.000118  loss: 2.9213 (2.9337)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [16]  [200/390]  eta: 0:00:53  lr: 0.000118  loss: 2.6939 (2.9271)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [16]  [210/390]  eta: 0:00:50  lr: 0.000118  loss: 2.7373 (2.9155)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [16]  [220/390]  eta: 0:00:47  lr: 0.000118  loss: 2.7373 (2.9078)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [16]  [230/390]  eta: 0:00:44  lr: 0.000118  loss: 2.7778 (2.8987)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [16]  [240/390]  eta: 0:00:41  lr: 0.000118  loss: 2.6985 (2.8905)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [16]  [250/390]  eta: 0:00:39  lr: 0.000118  loss: 2.8317 (2.8893)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [16]  [260/390]  eta: 0:00:36  lr: 0.000118  loss: 2.9861 (2.8831)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [16]  [270/390]  eta: 0:00:33  lr: 0.000118  loss: 3.0425 (2.8920)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [16]  [280/390]  eta: 0:00:30  lr: 0.000118  loss: 3.0425 (2.8890)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [16]  [290/390]  eta: 0:00:27  lr: 0.000118  loss: 2.9259 (2.8904)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [16]  [300/390]  eta: 0:00:25  lr: 0.000118  loss: 3.1438 (2.8978)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [16]  [310/390]  eta: 0:00:22  lr: 0.000118  loss: 3.0638 (2.9021)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [16]  [320/390]  eta: 0:00:19  lr: 0.000118  loss: 2.9219 (2.8984)  time: 0.2766  data: 0.0002  max mem: 14473
Epoch: [16]  [330/390]  eta: 0:00:16  lr: 0.000118  loss: 2.8412 (2.9039)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [16]  [340/390]  eta: 0:00:13  lr: 0.000118  loss: 2.9930 (2.8981)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [16]  [350/390]  eta: 0:00:11  lr: 0.000118  loss: 3.1054 (2.9052)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [16]  [360/390]  eta: 0:00:08  lr: 0.000118  loss: 3.1323 (2.9049)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [16]  [370/390]  eta: 0:00:05  lr: 0.000118  loss: 2.8679 (2.8981)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [16]  [380/390]  eta: 0:00:02  lr: 0.000118  loss: 2.9838 (2.9039)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [16]  [389/390]  eta: 0:00:00  lr: 0.000118  loss: 3.1085 (2.9023)  time: 0.2716  data: 0.0001  max mem: 14473
Epoch: [16] Total time: 0:01:48 (0.2778 s / it)
Averaged stats: lr: 0.000118  loss: 3.1085 (2.9023)
Test:  [ 0/53]  eta: 0:01:22  loss: 0.3684 (0.3684)  acc1: 94.2708 (94.2708)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.5626  data: 1.4088  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.3407 (0.3498)  acc1: 95.8333 (95.8807)  acc5: 100.0000 (99.9053)  acc1_10: 95.3125 (95.6913)  acc5_10: 100.0000 (99.8580)  time: 0.2606  data: 0.1284  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3533 (0.3580)  acc1: 95.8333 (95.5853)  acc5: 100.0000 (99.7768)  acc1_10: 94.7917 (95.2877)  acc5_10: 100.0000 (99.7520)  time: 0.1261  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3533 (0.3558)  acc1: 95.8333 (95.7493)  acc5: 100.0000 (99.7984)  acc1_10: 94.7917 (95.3461)  acc5_10: 99.4792 (99.7480)  time: 0.1225  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3543 (0.3573)  acc1: 96.3542 (95.7825)  acc5: 100.0000 (99.7586)  acc1_10: 95.3125 (95.3633)  acc5_10: 100.0000 (99.7459)  time: 0.1216  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3564 (0.3554)  acc1: 96.3542 (95.8640)  acc5: 100.0000 (99.7958)  acc1_10: 95.8333 (95.4351)  acc5_10: 100.0000 (99.7753)  time: 0.1197  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3539 (0.3526)  acc1: 96.3542 (95.8500)  acc5: 100.0000 (99.8000)  acc1_10: 95.8333 (95.4200)  acc5_10: 100.0000 (99.7800)  time: 0.1152  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1506 s / it)
* Acc@1 95.850 Acc@5 99.800 loss 0.353
classifiers_10 : Acc@1 95.420 Acc@5 99.780
Accuracy of the network on the 10000 test images: 95.9%
## Using lr  0.0001170 for BACKBONE, cosine lr = 0.0023266 for PRUNER
Epoch: [17]  [  0/390]  eta: 0:10:55  lr: 0.000117  loss: 1.8857 (1.8857)  time: 1.6799  data: 1.3443  max mem: 14473
Epoch: [17]  [ 10/390]  eta: 0:02:34  lr: 0.000117  loss: 3.0014 (2.7803)  time: 0.4059  data: 0.1225  max mem: 14473
Epoch: [17]  [ 20/390]  eta: 0:02:06  lr: 0.000117  loss: 2.8685 (2.7997)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [17]  [ 30/390]  eta: 0:01:55  lr: 0.000117  loss: 2.9404 (2.8544)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [17]  [ 40/390]  eta: 0:01:48  lr: 0.000117  loss: 2.9543 (2.8118)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [17]  [ 50/390]  eta: 0:01:42  lr: 0.000117  loss: 2.6355 (2.7758)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [17]  [ 60/390]  eta: 0:01:38  lr: 0.000117  loss: 2.6144 (2.7667)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [17]  [ 70/390]  eta: 0:01:34  lr: 0.000117  loss: 2.9313 (2.8160)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [17]  [ 80/390]  eta: 0:01:30  lr: 0.000117  loss: 3.1198 (2.8474)  time: 0.2756  data: 0.0002  max mem: 14473
Epoch: [17]  [ 90/390]  eta: 0:01:26  lr: 0.000117  loss: 3.0733 (2.8619)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [17]  [100/390]  eta: 0:01:23  lr: 0.000117  loss: 3.0581 (2.8786)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [17]  [110/390]  eta: 0:01:20  lr: 0.000117  loss: 2.8373 (2.8705)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [17]  [120/390]  eta: 0:01:17  lr: 0.000117  loss: 2.4976 (2.8296)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [17]  [130/390]  eta: 0:01:14  lr: 0.000117  loss: 2.4976 (2.8233)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [17]  [140/390]  eta: 0:01:11  lr: 0.000117  loss: 2.6820 (2.8101)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [17]  [150/390]  eta: 0:01:08  lr: 0.000117  loss: 2.9985 (2.8322)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [17]  [160/390]  eta: 0:01:05  lr: 0.000117  loss: 3.1790 (2.8421)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [17]  [170/390]  eta: 0:01:02  lr: 0.000117  loss: 3.1050 (2.8465)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [17]  [180/390]  eta: 0:00:59  lr: 0.000117  loss: 2.9892 (2.8479)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [17]  [190/390]  eta: 0:00:56  lr: 0.000117  loss: 2.9513 (2.8451)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [17]  [200/390]  eta: 0:00:53  lr: 0.000117  loss: 2.7678 (2.8423)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [17]  [210/390]  eta: 0:00:50  lr: 0.000117  loss: 2.7678 (2.8406)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [17]  [220/390]  eta: 0:00:47  lr: 0.000117  loss: 2.6884 (2.8363)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [17]  [230/390]  eta: 0:00:44  lr: 0.000117  loss: 2.7089 (2.8340)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [17]  [240/390]  eta: 0:00:41  lr: 0.000117  loss: 2.6943 (2.8277)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [17]  [250/390]  eta: 0:00:39  lr: 0.000117  loss: 2.7727 (2.8292)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [17]  [260/390]  eta: 0:00:36  lr: 0.000117  loss: 2.9717 (2.8328)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [17]  [270/390]  eta: 0:00:33  lr: 0.000117  loss: 2.9668 (2.8286)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [17]  [280/390]  eta: 0:00:30  lr: 0.000117  loss: 2.6546 (2.8209)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [17]  [290/390]  eta: 0:00:27  lr: 0.000117  loss: 2.6546 (2.8220)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [17]  [300/390]  eta: 0:00:25  lr: 0.000117  loss: 3.0903 (2.8256)  time: 0.2792  data: 0.0003  max mem: 14473
Epoch: [17]  [310/390]  eta: 0:00:22  lr: 0.000117  loss: 2.8492 (2.8249)  time: 0.2776  data: 0.0003  max mem: 14473
Epoch: [17]  [320/390]  eta: 0:00:19  lr: 0.000117  loss: 2.8757 (2.8225)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [17]  [330/390]  eta: 0:00:16  lr: 0.000117  loss: 2.7604 (2.8180)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [17]  [340/390]  eta: 0:00:13  lr: 0.000117  loss: 2.7644 (2.8212)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [17]  [350/390]  eta: 0:00:11  lr: 0.000117  loss: 2.8932 (2.8236)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [17]  [360/390]  eta: 0:00:08  lr: 0.000117  loss: 2.8827 (2.8201)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [17]  [370/390]  eta: 0:00:05  lr: 0.000117  loss: 2.6577 (2.8157)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [17]  [380/390]  eta: 0:00:02  lr: 0.000117  loss: 2.4722 (2.8118)  time: 0.2720  data: 0.0002  max mem: 14473
Epoch: [17]  [389/390]  eta: 0:00:00  lr: 0.000117  loss: 2.8143 (2.8155)  time: 0.2708  data: 0.0001  max mem: 14473
Epoch: [17] Total time: 0:01:48 (0.2779 s / it)
Averaged stats: lr: 0.000117  loss: 2.8143 (2.8155)
Test:  [ 0/53]  eta: 0:01:11  loss: 0.3059 (0.3059)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.3426  data: 1.1821  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.3135 (0.3150)  acc1: 95.8333 (96.0701)  acc5: 100.0000 (99.8580)  acc1_10: 95.8333 (95.9754)  acc5_10: 100.0000 (99.8580)  time: 0.2459  data: 0.1106  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3239 (0.3259)  acc1: 95.8333 (95.7589)  acc5: 100.0000 (99.8264)  acc1_10: 95.8333 (95.5605)  acc5_10: 100.0000 (99.7768)  time: 0.1292  data: 0.0019  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3219 (0.3251)  acc1: 95.8333 (95.9005)  acc5: 100.0000 (99.8320)  acc1_10: 95.8333 (95.7157)  acc5_10: 100.0000 (99.8320)  time: 0.1219  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3213 (0.3248)  acc1: 95.8333 (95.9350)  acc5: 100.0000 (99.7459)  acc1_10: 95.8333 (95.7571)  acc5_10: 100.0000 (99.8095)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3157 (0.3232)  acc1: 95.8333 (95.9967)  acc5: 100.0000 (99.7855)  acc1_10: 95.8333 (95.8640)  acc5_10: 100.0000 (99.8366)  time: 0.1193  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3072 (0.3204)  acc1: 96.3542 (96.0200)  acc5: 100.0000 (99.7900)  acc1_10: 96.3542 (95.8900)  acc5_10: 100.0000 (99.8400)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1472 s / it)
* Acc@1 96.020 Acc@5 99.790 loss 0.320
classifiers_10 : Acc@1 95.890 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.0%
## Using lr  0.0001160 for BACKBONE, cosine lr = 0.0023062 for PRUNER
Epoch: [18]  [  0/390]  eta: 0:11:00  lr: 0.000116  loss: 2.4208 (2.4208)  time: 1.6935  data: 1.3641  max mem: 14473
Epoch: [18]  [ 10/390]  eta: 0:02:34  lr: 0.000116  loss: 2.9937 (2.7772)  time: 0.4068  data: 0.1243  max mem: 14473
Epoch: [18]  [ 20/390]  eta: 0:02:07  lr: 0.000116  loss: 2.8706 (2.7460)  time: 0.2776  data: 0.0003  max mem: 14473
Epoch: [18]  [ 30/390]  eta: 0:01:56  lr: 0.000116  loss: 2.9255 (2.7819)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [18]  [ 40/390]  eta: 0:01:48  lr: 0.000116  loss: 3.1523 (2.8217)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [18]  [ 50/390]  eta: 0:01:43  lr: 0.000116  loss: 3.0966 (2.8552)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [18]  [ 60/390]  eta: 0:01:38  lr: 0.000116  loss: 2.8491 (2.7883)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [18]  [ 70/390]  eta: 0:01:34  lr: 0.000116  loss: 2.5300 (2.8123)  time: 0.2735  data: 0.0002  max mem: 14473
Epoch: [18]  [ 80/390]  eta: 0:01:30  lr: 0.000116  loss: 3.0908 (2.8386)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [18]  [ 90/390]  eta: 0:01:27  lr: 0.000116  loss: 2.6062 (2.8006)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [18]  [100/390]  eta: 0:01:23  lr: 0.000116  loss: 2.5787 (2.8157)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [18]  [110/390]  eta: 0:01:20  lr: 0.000116  loss: 2.9525 (2.8148)  time: 0.2784  data: 0.0003  max mem: 14473
Epoch: [18]  [120/390]  eta: 0:01:17  lr: 0.000116  loss: 2.7883 (2.8077)  time: 0.2774  data: 0.0003  max mem: 14473
Epoch: [18]  [130/390]  eta: 0:01:14  lr: 0.000116  loss: 2.9722 (2.8264)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [18]  [140/390]  eta: 0:01:11  lr: 0.000116  loss: 3.2764 (2.8617)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [18]  [150/390]  eta: 0:01:08  lr: 0.000116  loss: 3.2537 (2.8714)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [18]  [160/390]  eta: 0:01:05  lr: 0.000116  loss: 2.8649 (2.8526)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [18]  [170/390]  eta: 0:01:02  lr: 0.000116  loss: 2.7856 (2.8434)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [18]  [180/390]  eta: 0:00:59  lr: 0.000116  loss: 2.8799 (2.8489)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [18]  [190/390]  eta: 0:00:56  lr: 0.000116  loss: 2.7708 (2.8375)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [18]  [200/390]  eta: 0:00:53  lr: 0.000116  loss: 2.7001 (2.8456)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [18]  [210/390]  eta: 0:00:50  lr: 0.000116  loss: 2.8462 (2.8432)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [18]  [220/390]  eta: 0:00:47  lr: 0.000116  loss: 2.8462 (2.8505)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [18]  [230/390]  eta: 0:00:44  lr: 0.000116  loss: 3.0669 (2.8525)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [18]  [240/390]  eta: 0:00:42  lr: 0.000116  loss: 3.0897 (2.8559)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [18]  [250/390]  eta: 0:00:39  lr: 0.000116  loss: 2.9943 (2.8633)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [18]  [260/390]  eta: 0:00:36  lr: 0.000116  loss: 2.9943 (2.8591)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [18]  [270/390]  eta: 0:00:33  lr: 0.000116  loss: 2.9137 (2.8564)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [18]  [280/390]  eta: 0:00:30  lr: 0.000116  loss: 2.9137 (2.8582)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [18]  [290/390]  eta: 0:00:27  lr: 0.000116  loss: 3.1237 (2.8642)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [18]  [300/390]  eta: 0:00:25  lr: 0.000116  loss: 2.7284 (2.8562)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [18]  [310/390]  eta: 0:00:22  lr: 0.000116  loss: 2.6293 (2.8521)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [18]  [320/390]  eta: 0:00:19  lr: 0.000116  loss: 2.9808 (2.8555)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [18]  [330/390]  eta: 0:00:16  lr: 0.000116  loss: 3.0322 (2.8614)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [18]  [340/390]  eta: 0:00:13  lr: 0.000116  loss: 3.0438 (2.8622)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [18]  [350/390]  eta: 0:00:11  lr: 0.000116  loss: 3.0571 (2.8631)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [18]  [360/390]  eta: 0:00:08  lr: 0.000116  loss: 3.0363 (2.8617)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [18]  [370/390]  eta: 0:00:05  lr: 0.000116  loss: 3.0382 (2.8634)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [18]  [380/390]  eta: 0:00:02  lr: 0.000116  loss: 2.8362 (2.8555)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [18]  [389/390]  eta: 0:00:00  lr: 0.000116  loss: 2.8362 (2.8543)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [18] Total time: 0:01:48 (0.2784 s / it)
Averaged stats: lr: 0.000116  loss: 2.8362 (2.8543)
Test:  [ 0/53]  eta: 0:01:15  loss: 0.2156 (0.2156)  acc1: 97.9167 (97.9167)  acc5: 100.0000 (100.0000)  acc1_10: 97.3958 (97.3958)  acc5_10: 100.0000 (100.0000)  time: 1.4155  data: 1.2542  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2306 (0.2343)  acc1: 96.3542 (96.4962)  acc5: 100.0000 (99.8106)  acc1_10: 96.3542 (96.1648)  acc5_10: 100.0000 (99.8580)  time: 0.2511  data: 0.1163  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2472 (0.2504)  acc1: 95.8333 (95.8581)  acc5: 100.0000 (99.7520)  acc1_10: 95.3125 (95.5853)  acc5_10: 100.0000 (99.7272)  time: 0.1280  data: 0.0014  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2554 (0.2538)  acc1: 95.3125 (95.6989)  acc5: 100.0000 (99.7648)  acc1_10: 94.7917 (95.4301)  acc5_10: 100.0000 (99.7648)  time: 0.1211  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2538 (0.2553)  acc1: 95.3125 (95.6301)  acc5: 100.0000 (99.7713)  acc1_10: 95.8333 (95.4649)  acc5_10: 100.0000 (99.7713)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2492 (0.2544)  acc1: 95.8333 (95.6495)  acc5: 100.0000 (99.7855)  acc1_10: 95.8333 (95.5168)  acc5_10: 100.0000 (99.7958)  time: 0.1199  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2482 (0.2521)  acc1: 95.8333 (95.6900)  acc5: 100.0000 (99.7900)  acc1_10: 95.8333 (95.5400)  acc5_10: 100.0000 (99.8000)  time: 0.1154  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1482 s / it)
* Acc@1 95.690 Acc@5 99.790 loss 0.252
classifiers_10 : Acc@1 95.540 Acc@5 99.800
Accuracy of the network on the 10000 test images: 95.7%
## Using lr  0.0001151 for BACKBONE, cosine lr = 0.0022847 for PRUNER
Epoch: [19]  [  0/390]  eta: 0:10:10  lr: 0.000115  loss: 2.7999 (2.7999)  time: 1.5665  data: 1.2304  max mem: 14473
Epoch: [19]  [ 10/390]  eta: 0:02:29  lr: 0.000115  loss: 2.8679 (2.8626)  time: 0.3936  data: 0.1121  max mem: 14473
Epoch: [19]  [ 20/390]  eta: 0:02:04  lr: 0.000115  loss: 2.8679 (2.8022)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [19]  [ 30/390]  eta: 0:01:54  lr: 0.000115  loss: 2.7911 (2.7765)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [19]  [ 40/390]  eta: 0:01:47  lr: 0.000115  loss: 2.5819 (2.7273)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [19]  [ 50/390]  eta: 0:01:42  lr: 0.000115  loss: 2.6250 (2.7592)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [19]  [ 60/390]  eta: 0:01:37  lr: 0.000115  loss: 3.1526 (2.8159)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [19]  [ 70/390]  eta: 0:01:33  lr: 0.000115  loss: 3.1613 (2.8387)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [19]  [ 80/390]  eta: 0:01:29  lr: 0.000115  loss: 2.7478 (2.8210)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [19]  [ 90/390]  eta: 0:01:26  lr: 0.000115  loss: 2.7046 (2.8157)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [19]  [100/390]  eta: 0:01:23  lr: 0.000115  loss: 2.8497 (2.8153)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [19]  [110/390]  eta: 0:01:20  lr: 0.000115  loss: 2.8462 (2.8134)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [19]  [120/390]  eta: 0:01:17  lr: 0.000115  loss: 2.8882 (2.8185)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [19]  [130/390]  eta: 0:01:13  lr: 0.000115  loss: 2.7715 (2.8011)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [19]  [140/390]  eta: 0:01:10  lr: 0.000115  loss: 2.7715 (2.8139)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [19]  [150/390]  eta: 0:01:07  lr: 0.000115  loss: 2.8300 (2.7934)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [19]  [160/390]  eta: 0:01:04  lr: 0.000115  loss: 2.5678 (2.7764)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [19]  [170/390]  eta: 0:01:02  lr: 0.000115  loss: 2.8017 (2.7835)  time: 0.2818  data: 0.0003  max mem: 14473
Epoch: [19]  [180/390]  eta: 0:00:59  lr: 0.000115  loss: 2.9318 (2.7902)  time: 0.2819  data: 0.0003  max mem: 14473
Epoch: [19]  [190/390]  eta: 0:00:56  lr: 0.000115  loss: 2.9318 (2.7893)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [19]  [200/390]  eta: 0:00:53  lr: 0.000115  loss: 2.8834 (2.7915)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [19]  [210/390]  eta: 0:00:50  lr: 0.000115  loss: 2.8834 (2.7851)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [19]  [220/390]  eta: 0:00:47  lr: 0.000115  loss: 3.0022 (2.7932)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [19]  [230/390]  eta: 0:00:44  lr: 0.000115  loss: 2.9168 (2.7944)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [19]  [240/390]  eta: 0:00:42  lr: 0.000115  loss: 2.7183 (2.7963)  time: 0.2790  data: 0.0003  max mem: 14473
Epoch: [19]  [250/390]  eta: 0:00:39  lr: 0.000115  loss: 2.9384 (2.8010)  time: 0.2781  data: 0.0003  max mem: 14473
Epoch: [19]  [260/390]  eta: 0:00:36  lr: 0.000115  loss: 3.0812 (2.8108)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [19]  [270/390]  eta: 0:00:33  lr: 0.000115  loss: 2.9189 (2.8073)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [19]  [280/390]  eta: 0:00:30  lr: 0.000115  loss: 2.8381 (2.8120)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [19]  [290/390]  eta: 0:00:27  lr: 0.000115  loss: 3.0435 (2.8192)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [19]  [300/390]  eta: 0:00:25  lr: 0.000115  loss: 3.0385 (2.8246)  time: 0.2719  data: 0.0003  max mem: 14473
Epoch: [19]  [310/390]  eta: 0:00:22  lr: 0.000115  loss: 2.5349 (2.8058)  time: 0.2721  data: 0.0002  max mem: 14473
Epoch: [19]  [320/390]  eta: 0:00:19  lr: 0.000115  loss: 2.5134 (2.8109)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [19]  [330/390]  eta: 0:00:16  lr: 0.000115  loss: 2.9153 (2.8068)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [19]  [340/390]  eta: 0:00:13  lr: 0.000115  loss: 2.7316 (2.8045)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [19]  [350/390]  eta: 0:00:11  lr: 0.000115  loss: 2.8498 (2.8072)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [19]  [360/390]  eta: 0:00:08  lr: 0.000115  loss: 2.8498 (2.8045)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [19]  [370/390]  eta: 0:00:05  lr: 0.000115  loss: 2.6372 (2.8031)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [19]  [380/390]  eta: 0:00:02  lr: 0.000115  loss: 2.6372 (2.8077)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [19]  [389/390]  eta: 0:00:00  lr: 0.000115  loss: 2.7271 (2.8055)  time: 0.2740  data: 0.0001  max mem: 14473
Epoch: [19] Total time: 0:01:48 (0.2786 s / it)
Averaged stats: lr: 0.000115  loss: 2.7271 (2.8055)
Test:  [ 0/53]  eta: 0:01:19  loss: 0.2594 (0.2594)  acc1: 97.9167 (97.9167)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.5009  data: 1.3317  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2454 (0.2541)  acc1: 97.3958 (97.1591)  acc5: 100.0000 (99.9527)  acc1_10: 95.8333 (96.3068)  acc5_10: 100.0000 (99.9527)  time: 0.2558  data: 0.1213  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2528 (0.2665)  acc1: 96.8750 (96.5774)  acc5: 100.0000 (99.8264)  acc1_10: 95.8333 (95.9821)  acc5_10: 100.0000 (99.8016)  time: 0.1271  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2617 (0.2644)  acc1: 96.3542 (96.5390)  acc5: 100.0000 (99.8320)  acc1_10: 95.8333 (96.0517)  acc5_10: 100.0000 (99.8152)  time: 0.1223  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2617 (0.2670)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (99.8222)  acc1_10: 95.8333 (95.9858)  acc5_10: 100.0000 (99.7967)  time: 0.1206  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2644 (0.2653)  acc1: 95.8333 (96.3746)  acc5: 100.0000 (99.8468)  acc1_10: 95.8333 (95.9559)  acc5_10: 100.0000 (99.8264)  time: 0.1192  data: 0.0002  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2644 (0.2634)  acc1: 96.3542 (96.3800)  acc5: 100.0000 (99.8400)  acc1_10: 95.8333 (95.9600)  acc5_10: 100.0000 (99.8200)  time: 0.1146  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1493 s / it)
* Acc@1 96.380 Acc@5 99.840 loss 0.263
classifiers_10 : Acc@1 95.960 Acc@5 99.820
Accuracy of the network on the 10000 test images: 96.4%
## Using lr  0.0001140 for BACKBONE, cosine lr = 0.0022622 for PRUNER
Epoch: [20]  [  0/390]  eta: 0:11:23  lr: 0.000114  loss: 3.4017 (3.4017)  time: 1.7518  data: 1.4302  max mem: 14473
Epoch: [20]  [ 10/390]  eta: 0:02:36  lr: 0.000114  loss: 2.8955 (2.8699)  time: 0.4121  data: 0.1303  max mem: 14473
Epoch: [20]  [ 20/390]  eta: 0:02:08  lr: 0.000114  loss: 2.8955 (2.9134)  time: 0.2772  data: 0.0002  max mem: 14473
Epoch: [20]  [ 30/390]  eta: 0:01:56  lr: 0.000114  loss: 2.8834 (2.8479)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [20]  [ 40/390]  eta: 0:01:49  lr: 0.000114  loss: 2.7618 (2.8258)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [20]  [ 50/390]  eta: 0:01:43  lr: 0.000114  loss: 3.1711 (2.8656)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [20]  [ 60/390]  eta: 0:01:38  lr: 0.000114  loss: 2.9187 (2.8351)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [20]  [ 70/390]  eta: 0:01:34  lr: 0.000114  loss: 3.0170 (2.8769)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [20]  [ 80/390]  eta: 0:01:30  lr: 0.000114  loss: 3.0500 (2.8732)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [20]  [ 90/390]  eta: 0:01:27  lr: 0.000114  loss: 3.0123 (2.8690)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [20]  [100/390]  eta: 0:01:24  lr: 0.000114  loss: 3.0365 (2.8766)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [20]  [110/390]  eta: 0:01:20  lr: 0.000114  loss: 3.0195 (2.8851)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [20]  [120/390]  eta: 0:01:17  lr: 0.000114  loss: 2.7482 (2.8620)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [20]  [130/390]  eta: 0:01:14  lr: 0.000114  loss: 2.5856 (2.8552)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [20]  [140/390]  eta: 0:01:11  lr: 0.000114  loss: 3.0740 (2.8697)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [20]  [150/390]  eta: 0:01:08  lr: 0.000114  loss: 3.0576 (2.8717)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [20]  [160/390]  eta: 0:01:05  lr: 0.000114  loss: 2.9162 (2.8638)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [20]  [170/390]  eta: 0:01:02  lr: 0.000114  loss: 2.6349 (2.8424)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [20]  [180/390]  eta: 0:00:59  lr: 0.000114  loss: 2.6349 (2.8406)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [20]  [190/390]  eta: 0:00:56  lr: 0.000114  loss: 2.7356 (2.8345)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [20]  [200/390]  eta: 0:00:53  lr: 0.000114  loss: 2.6809 (2.8262)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [20]  [210/390]  eta: 0:00:50  lr: 0.000114  loss: 2.8442 (2.8243)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [20]  [220/390]  eta: 0:00:47  lr: 0.000114  loss: 2.8868 (2.8281)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [20]  [230/390]  eta: 0:00:44  lr: 0.000114  loss: 2.6297 (2.8201)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [20]  [240/390]  eta: 0:00:42  lr: 0.000114  loss: 2.9275 (2.8214)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [20]  [250/390]  eta: 0:00:39  lr: 0.000114  loss: 2.9275 (2.8118)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [20]  [260/390]  eta: 0:00:36  lr: 0.000114  loss: 2.8650 (2.8098)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [20]  [270/390]  eta: 0:00:33  lr: 0.000114  loss: 3.1276 (2.8211)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [20]  [280/390]  eta: 0:00:30  lr: 0.000114  loss: 3.2124 (2.8230)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [20]  [290/390]  eta: 0:00:28  lr: 0.000114  loss: 3.0447 (2.8287)  time: 0.2836  data: 0.0003  max mem: 14473
Epoch: [20]  [300/390]  eta: 0:00:25  lr: 0.000114  loss: 3.0256 (2.8259)  time: 0.2850  data: 0.0003  max mem: 14473
Epoch: [20]  [310/390]  eta: 0:00:22  lr: 0.000114  loss: 2.9953 (2.8225)  time: 0.2774  data: 0.0003  max mem: 14473
Epoch: [20]  [320/390]  eta: 0:00:19  lr: 0.000114  loss: 2.8378 (2.8245)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [20]  [330/390]  eta: 0:00:16  lr: 0.000114  loss: 3.0271 (2.8297)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [20]  [340/390]  eta: 0:00:14  lr: 0.000114  loss: 2.7705 (2.8244)  time: 0.2759  data: 0.0002  max mem: 14473
Epoch: [20]  [350/390]  eta: 0:00:11  lr: 0.000114  loss: 2.7705 (2.8291)  time: 0.2755  data: 0.0002  max mem: 14473
Epoch: [20]  [360/390]  eta: 0:00:08  lr: 0.000114  loss: 2.8619 (2.8254)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [20]  [370/390]  eta: 0:00:05  lr: 0.000114  loss: 2.7954 (2.8249)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [20]  [380/390]  eta: 0:00:02  lr: 0.000114  loss: 2.8674 (2.8243)  time: 0.2721  data: 0.0002  max mem: 14473
Epoch: [20]  [389/390]  eta: 0:00:00  lr: 0.000114  loss: 3.0725 (2.8236)  time: 0.2712  data: 0.0001  max mem: 14473
Epoch: [20] Total time: 0:01:48 (0.2795 s / it)
Averaged stats: lr: 0.000114  loss: 3.0725 (2.8236)
Test:  [ 0/53]  eta: 0:01:21  loss: 0.2875 (0.2875)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.5373  data: 1.3742  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2771 (0.2809)  acc1: 96.3542 (96.8750)  acc5: 100.0000 (99.9527)  acc1_10: 96.3542 (96.5436)  acc5_10: 100.0000 (99.9053)  time: 0.2598  data: 0.1274  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2930 (0.2950)  acc1: 96.3542 (96.3046)  acc5: 100.0000 (99.8264)  acc1_10: 95.8333 (95.9821)  acc5_10: 100.0000 (99.8016)  time: 0.1275  data: 0.0015  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3057 (0.2965)  acc1: 95.3125 (96.1862)  acc5: 100.0000 (99.8824)  acc1_10: 95.8333 (95.9173)  acc5_10: 100.0000 (99.8320)  time: 0.1221  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2930 (0.2939)  acc1: 95.8333 (96.3288)  acc5: 100.0000 (99.8476)  acc1_10: 95.8333 (96.1255)  acc5_10: 100.0000 (99.8222)  time: 0.1206  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2877 (0.2922)  acc1: 96.3542 (96.3337)  acc5: 100.0000 (99.8775)  acc1_10: 96.3542 (96.1908)  acc5_10: 100.0000 (99.8570)  time: 0.1199  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2804 (0.2905)  acc1: 96.3542 (96.3200)  acc5: 100.0000 (99.8800)  acc1_10: 96.3542 (96.1800)  acc5_10: 100.0000 (99.8600)  time: 0.1154  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1503 s / it)
* Acc@1 96.320 Acc@5 99.880 loss 0.290
classifiers_10 : Acc@1 96.180 Acc@5 99.860
Accuracy of the network on the 10000 test images: 96.3%
## Using lr  0.0001129 for BACKBONE, cosine lr = 0.0022387 for PRUNER
Epoch: [21]  [  0/390]  eta: 0:10:58  lr: 0.000113  loss: 3.0136 (3.0136)  time: 1.6882  data: 1.3591  max mem: 14473
Epoch: [21]  [ 10/390]  eta: 0:02:34  lr: 0.000113  loss: 2.6940 (2.6970)  time: 0.4057  data: 0.1238  max mem: 14473
Epoch: [21]  [ 20/390]  eta: 0:02:06  lr: 0.000113  loss: 2.6940 (2.7493)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [21]  [ 30/390]  eta: 0:01:55  lr: 0.000113  loss: 2.7024 (2.7330)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [21]  [ 40/390]  eta: 0:01:48  lr: 0.000113  loss: 2.9390 (2.7531)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [21]  [ 50/390]  eta: 0:01:43  lr: 0.000113  loss: 2.8212 (2.7365)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [21]  [ 60/390]  eta: 0:01:38  lr: 0.000113  loss: 2.8212 (2.7341)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [21]  [ 70/390]  eta: 0:01:34  lr: 0.000113  loss: 3.0131 (2.7961)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [21]  [ 80/390]  eta: 0:01:30  lr: 0.000113  loss: 3.2189 (2.8362)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [21]  [ 90/390]  eta: 0:01:27  lr: 0.000113  loss: 3.0283 (2.8264)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [21]  [100/390]  eta: 0:01:23  lr: 0.000113  loss: 2.8267 (2.8451)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [21]  [110/390]  eta: 0:01:20  lr: 0.000113  loss: 2.8753 (2.8343)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [21]  [120/390]  eta: 0:01:17  lr: 0.000113  loss: 2.6818 (2.8084)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [21]  [130/390]  eta: 0:01:14  lr: 0.000113  loss: 2.7580 (2.8076)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [21]  [140/390]  eta: 0:01:11  lr: 0.000113  loss: 2.9485 (2.8069)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [21]  [150/390]  eta: 0:01:08  lr: 0.000113  loss: 2.8417 (2.8084)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [21]  [160/390]  eta: 0:01:05  lr: 0.000113  loss: 2.7899 (2.7985)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [21]  [170/390]  eta: 0:01:02  lr: 0.000113  loss: 3.0054 (2.8090)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [21]  [180/390]  eta: 0:00:59  lr: 0.000113  loss: 3.0607 (2.8039)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [21]  [190/390]  eta: 0:00:56  lr: 0.000113  loss: 2.9206 (2.8085)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [21]  [200/390]  eta: 0:00:53  lr: 0.000113  loss: 2.9106 (2.8142)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [21]  [210/390]  eta: 0:00:50  lr: 0.000113  loss: 2.8892 (2.8177)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [21]  [220/390]  eta: 0:00:47  lr: 0.000113  loss: 2.9990 (2.8267)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [21]  [230/390]  eta: 0:00:44  lr: 0.000113  loss: 2.7824 (2.8119)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [21]  [240/390]  eta: 0:00:42  lr: 0.000113  loss: 2.6901 (2.8160)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [21]  [250/390]  eta: 0:00:39  lr: 0.000113  loss: 2.9390 (2.8128)  time: 0.2759  data: 0.0002  max mem: 14473
Epoch: [21]  [260/390]  eta: 0:00:36  lr: 0.000113  loss: 3.1140 (2.8238)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [21]  [270/390]  eta: 0:00:33  lr: 0.000113  loss: 3.1128 (2.8265)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [21]  [280/390]  eta: 0:00:30  lr: 0.000113  loss: 2.8347 (2.8226)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [21]  [290/390]  eta: 0:00:27  lr: 0.000113  loss: 2.8163 (2.8205)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [21]  [300/390]  eta: 0:00:25  lr: 0.000113  loss: 2.8045 (2.8178)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [21]  [310/390]  eta: 0:00:22  lr: 0.000113  loss: 2.8491 (2.8253)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [21]  [320/390]  eta: 0:00:19  lr: 0.000113  loss: 3.1492 (2.8345)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [21]  [330/390]  eta: 0:00:16  lr: 0.000113  loss: 3.0211 (2.8282)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [21]  [340/390]  eta: 0:00:13  lr: 0.000113  loss: 2.9372 (2.8337)  time: 0.2789  data: 0.0003  max mem: 14473
Epoch: [21]  [350/390]  eta: 0:00:11  lr: 0.000113  loss: 3.1320 (2.8416)  time: 0.2826  data: 0.0003  max mem: 14473
Epoch: [21]  [360/390]  eta: 0:00:08  lr: 0.000113  loss: 3.1088 (2.8415)  time: 0.2789  data: 0.0003  max mem: 14473
Epoch: [21]  [370/390]  eta: 0:00:05  lr: 0.000113  loss: 2.9967 (2.8415)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [21]  [380/390]  eta: 0:00:02  lr: 0.000113  loss: 3.0186 (2.8418)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [21]  [389/390]  eta: 0:00:00  lr: 0.000113  loss: 2.9764 (2.8401)  time: 0.2736  data: 0.0001  max mem: 14473
Epoch: [21] Total time: 0:01:48 (0.2791 s / it)
Averaged stats: lr: 0.000113  loss: 2.9764 (2.8401)
Test:  [ 0/53]  eta: 0:01:21  loss: 0.2703 (0.2703)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.5313  data: 1.3800  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2628 (0.2590)  acc1: 96.3542 (96.4489)  acc5: 100.0000 (99.9053)  acc1_10: 96.3542 (96.2121)  acc5_10: 100.0000 (99.9527)  time: 0.2593  data: 0.1258  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2673 (0.2712)  acc1: 96.3542 (96.1806)  acc5: 100.0000 (99.8264)  acc1_10: 95.8333 (95.7589)  acc5_10: 100.0000 (99.8760)  time: 0.1268  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2719 (0.2736)  acc1: 95.8333 (96.0013)  acc5: 100.0000 (99.8656)  acc1_10: 95.8333 (95.7997)  acc5_10: 100.0000 (99.8992)  time: 0.1215  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2802 (0.2751)  acc1: 95.8333 (95.9477)  acc5: 100.0000 (99.8476)  acc1_10: 95.8333 (95.7825)  acc5_10: 100.0000 (99.8857)  time: 0.1205  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2733 (0.2734)  acc1: 95.8333 (96.0172)  acc5: 100.0000 (99.8672)  acc1_10: 96.3542 (95.9048)  acc5_10: 100.0000 (99.8979)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2724 (0.2719)  acc1: 96.3542 (96.0100)  acc5: 100.0000 (99.8600)  acc1_10: 95.8333 (95.8800)  acc5_10: 100.0000 (99.8900)  time: 0.1147  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1497 s / it)
* Acc@1 96.010 Acc@5 99.860 loss 0.272
classifiers_10 : Acc@1 95.880 Acc@5 99.890
Accuracy of the network on the 10000 test images: 96.0%
## Using lr  0.0001118 for BACKBONE, cosine lr = 0.0022143 for PRUNER
Epoch: [22]  [  0/390]  eta: 0:10:10  lr: 0.000112  loss: 2.9611 (2.9611)  time: 1.5650  data: 1.2412  max mem: 14473
Epoch: [22]  [ 10/390]  eta: 0:02:32  lr: 0.000112  loss: 2.9683 (2.7719)  time: 0.4009  data: 0.1131  max mem: 14473
Epoch: [22]  [ 20/390]  eta: 0:02:06  lr: 0.000112  loss: 3.0919 (2.8500)  time: 0.2815  data: 0.0003  max mem: 14473
Epoch: [22]  [ 30/390]  eta: 0:01:55  lr: 0.000112  loss: 3.0213 (2.8664)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [22]  [ 40/390]  eta: 0:01:48  lr: 0.000112  loss: 2.9830 (2.8967)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [22]  [ 50/390]  eta: 0:01:42  lr: 0.000112  loss: 2.9830 (2.8935)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [22]  [ 60/390]  eta: 0:01:38  lr: 0.000112  loss: 2.7740 (2.8642)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [22]  [ 70/390]  eta: 0:01:34  lr: 0.000112  loss: 2.7740 (2.8598)  time: 0.2761  data: 0.0002  max mem: 14473
Epoch: [22]  [ 80/390]  eta: 0:01:30  lr: 0.000112  loss: 2.7284 (2.8225)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [22]  [ 90/390]  eta: 0:01:27  lr: 0.000112  loss: 2.6475 (2.8104)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [22]  [100/390]  eta: 0:01:23  lr: 0.000112  loss: 2.9032 (2.8025)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [22]  [110/390]  eta: 0:01:20  lr: 0.000112  loss: 2.8050 (2.7886)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [22]  [120/390]  eta: 0:01:17  lr: 0.000112  loss: 2.8395 (2.7846)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [22]  [130/390]  eta: 0:01:14  lr: 0.000112  loss: 2.9792 (2.7904)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [22]  [140/390]  eta: 0:01:11  lr: 0.000112  loss: 2.8681 (2.7964)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [22]  [150/390]  eta: 0:01:08  lr: 0.000112  loss: 2.8681 (2.7915)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [22]  [160/390]  eta: 0:01:05  lr: 0.000112  loss: 2.9768 (2.8126)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [22]  [170/390]  eta: 0:01:02  lr: 0.000112  loss: 2.9212 (2.8145)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [22]  [180/390]  eta: 0:00:59  lr: 0.000112  loss: 2.8420 (2.8201)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [22]  [190/390]  eta: 0:00:56  lr: 0.000112  loss: 2.7532 (2.8164)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [22]  [200/390]  eta: 0:00:53  lr: 0.000112  loss: 2.8571 (2.8209)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [22]  [210/390]  eta: 0:00:50  lr: 0.000112  loss: 3.0228 (2.8278)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [22]  [220/390]  eta: 0:00:47  lr: 0.000112  loss: 2.9910 (2.8235)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [22]  [230/390]  eta: 0:00:44  lr: 0.000112  loss: 2.6822 (2.8200)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [22]  [240/390]  eta: 0:00:42  lr: 0.000112  loss: 2.6822 (2.8174)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [22]  [250/390]  eta: 0:00:39  lr: 0.000112  loss: 2.8771 (2.8226)  time: 0.2772  data: 0.0003  max mem: 14473
Epoch: [22]  [260/390]  eta: 0:00:36  lr: 0.000112  loss: 2.8786 (2.8240)  time: 0.2772  data: 0.0003  max mem: 14473
Epoch: [22]  [270/390]  eta: 0:00:33  lr: 0.000112  loss: 2.8786 (2.8215)  time: 0.2769  data: 0.0003  max mem: 14473
Epoch: [22]  [280/390]  eta: 0:00:30  lr: 0.000112  loss: 3.0495 (2.8272)  time: 0.2772  data: 0.0003  max mem: 14473
Epoch: [22]  [290/390]  eta: 0:00:27  lr: 0.000112  loss: 3.0943 (2.8274)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [22]  [300/390]  eta: 0:00:25  lr: 0.000112  loss: 2.7472 (2.8227)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [22]  [310/390]  eta: 0:00:22  lr: 0.000112  loss: 2.7067 (2.8198)  time: 0.2773  data: 0.0003  max mem: 14473
Epoch: [22]  [320/390]  eta: 0:00:19  lr: 0.000112  loss: 2.7067 (2.8192)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [22]  [330/390]  eta: 0:00:16  lr: 0.000112  loss: 3.0053 (2.8215)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [22]  [340/390]  eta: 0:00:13  lr: 0.000112  loss: 2.9369 (2.8217)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [22]  [350/390]  eta: 0:00:11  lr: 0.000112  loss: 2.9369 (2.8274)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [22]  [360/390]  eta: 0:00:08  lr: 0.000112  loss: 2.9254 (2.8281)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [22]  [370/390]  eta: 0:00:05  lr: 0.000112  loss: 2.6575 (2.8242)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [22]  [380/390]  eta: 0:00:02  lr: 0.000112  loss: 2.6575 (2.8271)  time: 0.2746  data: 0.0002  max mem: 14473
Epoch: [22]  [389/390]  eta: 0:00:00  lr: 0.000112  loss: 3.1685 (2.8357)  time: 0.2762  data: 0.0001  max mem: 14473
Epoch: [22] Total time: 0:01:48 (0.2791 s / it)
Averaged stats: lr: 0.000112  loss: 3.1685 (2.8357)
Test:  [ 0/53]  eta: 0:01:15  loss: 0.3551 (0.3551)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.4274  data: 1.2752  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.3551 (0.3590)  acc1: 96.8750 (96.5909)  acc5: 100.0000 (99.7633)  acc1_10: 96.3542 (96.2121)  acc5_10: 100.0000 (99.8580)  time: 0.2492  data: 0.1162  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3622 (0.3672)  acc1: 96.8750 (96.4782)  acc5: 100.0000 (99.7272)  acc1_10: 96.3542 (96.1310)  acc5_10: 100.0000 (99.7024)  time: 0.1280  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3632 (0.3661)  acc1: 96.8750 (96.5390)  acc5: 100.0000 (99.7816)  acc1_10: 96.3542 (96.2030)  acc5_10: 100.0000 (99.7816)  time: 0.1236  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3669 (0.3669)  acc1: 96.3542 (96.5066)  acc5: 100.0000 (99.7586)  acc1_10: 96.3542 (96.0747)  acc5_10: 100.0000 (99.7840)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3669 (0.3660)  acc1: 96.3542 (96.5074)  acc5: 100.0000 (99.7958)  acc1_10: 96.3542 (96.1601)  acc5_10: 100.0000 (99.8060)  time: 0.1188  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3630 (0.3638)  acc1: 96.3542 (96.5100)  acc5: 100.0000 (99.8000)  acc1_10: 96.3542 (96.1400)  acc5_10: 100.0000 (99.8000)  time: 0.1144  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1483 s / it)
* Acc@1 96.510 Acc@5 99.800 loss 0.364
classifiers_10 : Acc@1 96.140 Acc@5 99.800
Accuracy of the network on the 10000 test images: 96.5%
## Using lr  0.0001106 for BACKBONE, cosine lr = 0.0021889 for PRUNER
Epoch: [23]  [  0/390]  eta: 0:11:45  lr: 0.000111  loss: 3.2941 (3.2941)  time: 1.8088  data: 1.4959  max mem: 14473
Epoch: [23]  [ 10/390]  eta: 0:02:37  lr: 0.000111  loss: 2.4376 (2.5541)  time: 0.4156  data: 0.1362  max mem: 14473
Epoch: [23]  [ 20/390]  eta: 0:02:08  lr: 0.000111  loss: 2.9370 (2.7779)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [23]  [ 30/390]  eta: 0:01:58  lr: 0.000111  loss: 2.8306 (2.6462)  time: 0.2835  data: 0.0003  max mem: 14473
Epoch: [23]  [ 40/390]  eta: 0:01:50  lr: 0.000111  loss: 2.3188 (2.6134)  time: 0.2833  data: 0.0003  max mem: 14473
Epoch: [23]  [ 50/390]  eta: 0:01:44  lr: 0.000111  loss: 2.8749 (2.6897)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [23]  [ 60/390]  eta: 0:01:39  lr: 0.000111  loss: 2.9580 (2.7063)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [23]  [ 70/390]  eta: 0:01:35  lr: 0.000111  loss: 2.8173 (2.7264)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [23]  [ 80/390]  eta: 0:01:31  lr: 0.000111  loss: 2.6017 (2.6978)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [23]  [ 90/390]  eta: 0:01:28  lr: 0.000111  loss: 2.6017 (2.7048)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [23]  [100/390]  eta: 0:01:24  lr: 0.000111  loss: 2.9268 (2.7071)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [23]  [110/390]  eta: 0:01:21  lr: 0.000111  loss: 2.9681 (2.7286)  time: 0.2782  data: 0.0003  max mem: 14473
Epoch: [23]  [120/390]  eta: 0:01:18  lr: 0.000111  loss: 2.9652 (2.7394)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [23]  [130/390]  eta: 0:01:14  lr: 0.000111  loss: 2.8285 (2.7322)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [23]  [140/390]  eta: 0:01:11  lr: 0.000111  loss: 2.8606 (2.7556)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [23]  [150/390]  eta: 0:01:08  lr: 0.000111  loss: 2.8606 (2.7414)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [23]  [160/390]  eta: 0:01:05  lr: 0.000111  loss: 2.6166 (2.7437)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [23]  [170/390]  eta: 0:01:02  lr: 0.000111  loss: 2.7613 (2.7455)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [23]  [180/390]  eta: 0:00:59  lr: 0.000111  loss: 2.7613 (2.7387)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [23]  [190/390]  eta: 0:00:56  lr: 0.000111  loss: 2.5550 (2.7346)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [23]  [200/390]  eta: 0:00:53  lr: 0.000111  loss: 2.9360 (2.7448)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [23]  [210/390]  eta: 0:00:50  lr: 0.000111  loss: 2.8530 (2.7387)  time: 0.2783  data: 0.0003  max mem: 14473
Epoch: [23]  [220/390]  eta: 0:00:48  lr: 0.000111  loss: 2.6565 (2.7382)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [23]  [230/390]  eta: 0:00:45  lr: 0.000111  loss: 2.6565 (2.7442)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [23]  [240/390]  eta: 0:00:42  lr: 0.000111  loss: 3.0214 (2.7474)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [23]  [250/390]  eta: 0:00:39  lr: 0.000111  loss: 3.0846 (2.7572)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [23]  [260/390]  eta: 0:00:36  lr: 0.000111  loss: 3.0846 (2.7580)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [23]  [270/390]  eta: 0:00:33  lr: 0.000111  loss: 2.6118 (2.7568)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [23]  [280/390]  eta: 0:00:30  lr: 0.000111  loss: 2.7125 (2.7579)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [23]  [290/390]  eta: 0:00:28  lr: 0.000111  loss: 2.9568 (2.7606)  time: 0.2785  data: 0.0003  max mem: 14473
Epoch: [23]  [300/390]  eta: 0:00:25  lr: 0.000111  loss: 2.8376 (2.7622)  time: 0.2790  data: 0.0003  max mem: 14473
Epoch: [23]  [310/390]  eta: 0:00:22  lr: 0.000111  loss: 3.0119 (2.7723)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [23]  [320/390]  eta: 0:00:19  lr: 0.000111  loss: 2.9003 (2.7700)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [23]  [330/390]  eta: 0:00:16  lr: 0.000111  loss: 2.7913 (2.7677)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [23]  [340/390]  eta: 0:00:14  lr: 0.000111  loss: 2.9878 (2.7695)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [23]  [350/390]  eta: 0:00:11  lr: 0.000111  loss: 2.8693 (2.7683)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [23]  [360/390]  eta: 0:00:08  lr: 0.000111  loss: 2.5419 (2.7607)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [23]  [370/390]  eta: 0:00:05  lr: 0.000111  loss: 2.7873 (2.7616)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [23]  [380/390]  eta: 0:00:02  lr: 0.000111  loss: 2.7873 (2.7579)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [23]  [389/390]  eta: 0:00:00  lr: 0.000111  loss: 2.8132 (2.7603)  time: 0.2719  data: 0.0001  max mem: 14473
Epoch: [23] Total time: 0:01:49 (0.2798 s / it)
Averaged stats: lr: 0.000111  loss: 2.8132 (2.7603)
Test:  [ 0/53]  eta: 0:01:25  loss: 0.3318 (0.3318)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.6053  data: 1.4542  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.3013 (0.3050)  acc1: 95.8333 (96.2595)  acc5: 100.0000 (99.8580)  acc1_10: 95.8333 (96.1174)  acc5_10: 100.0000 (99.9527)  time: 0.2603  data: 0.1325  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3013 (0.3078)  acc1: 95.8333 (96.1806)  acc5: 100.0000 (99.7520)  acc1_10: 95.8333 (95.8581)  acc5_10: 100.0000 (99.8016)  time: 0.1239  data: 0.0002  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3032 (0.3075)  acc1: 96.3542 (96.2198)  acc5: 100.0000 (99.7816)  acc1_10: 96.3542 (96.0518)  acc5_10: 100.0000 (99.8152)  time: 0.1220  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3060 (0.3095)  acc1: 95.8333 (96.1382)  acc5: 100.0000 (99.7840)  acc1_10: 96.3542 (95.9604)  acc5_10: 100.0000 (99.7967)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3141 (0.3094)  acc1: 95.8333 (96.1091)  acc5: 100.0000 (99.7958)  acc1_10: 95.8333 (95.9661)  acc5_10: 100.0000 (99.8264)  time: 0.1190  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3061 (0.3081)  acc1: 95.8333 (96.1100)  acc5: 100.0000 (99.8000)  acc1_10: 95.8333 (95.9700)  acc5_10: 100.0000 (99.8200)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1500 s / it)
* Acc@1 96.110 Acc@5 99.800 loss 0.308
classifiers_10 : Acc@1 95.970 Acc@5 99.820
Accuracy of the network on the 10000 test images: 96.1%
## Using lr  0.0001094 for BACKBONE, cosine lr = 0.0021626 for PRUNER
Epoch: [24]  [  0/390]  eta: 0:11:26  lr: 0.000109  loss: 3.3964 (3.3964)  time: 1.7594  data: 1.4355  max mem: 14473
Epoch: [24]  [ 10/390]  eta: 0:02:37  lr: 0.000109  loss: 2.9797 (2.9070)  time: 0.4135  data: 0.1308  max mem: 14473
Epoch: [24]  [ 20/390]  eta: 0:02:08  lr: 0.000109  loss: 2.8237 (2.8150)  time: 0.2769  data: 0.0003  max mem: 14473
Epoch: [24]  [ 30/390]  eta: 0:01:56  lr: 0.000109  loss: 2.7681 (2.8475)  time: 0.2744  data: 0.0002  max mem: 14473
Epoch: [24]  [ 40/390]  eta: 0:01:48  lr: 0.000109  loss: 3.0995 (2.8559)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [24]  [ 50/390]  eta: 0:01:43  lr: 0.000109  loss: 3.1096 (2.8710)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [24]  [ 60/390]  eta: 0:01:38  lr: 0.000109  loss: 3.0027 (2.8898)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [24]  [ 70/390]  eta: 0:01:34  lr: 0.000109  loss: 2.9726 (2.8953)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [24]  [ 80/390]  eta: 0:01:30  lr: 0.000109  loss: 2.9581 (2.8980)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [24]  [ 90/390]  eta: 0:01:27  lr: 0.000109  loss: 2.9716 (2.8904)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [24]  [100/390]  eta: 0:01:23  lr: 0.000109  loss: 2.6738 (2.8667)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [24]  [110/390]  eta: 0:01:20  lr: 0.000109  loss: 2.8682 (2.8731)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [24]  [120/390]  eta: 0:01:17  lr: 0.000109  loss: 3.0352 (2.8723)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [24]  [130/390]  eta: 0:01:14  lr: 0.000109  loss: 2.9402 (2.8707)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [24]  [140/390]  eta: 0:01:11  lr: 0.000109  loss: 2.7932 (2.8713)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [24]  [150/390]  eta: 0:01:08  lr: 0.000109  loss: 2.3909 (2.8349)  time: 0.2769  data: 0.0003  max mem: 14473
Epoch: [24]  [160/390]  eta: 0:01:05  lr: 0.000109  loss: 2.3800 (2.8233)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [24]  [170/390]  eta: 0:01:02  lr: 0.000109  loss: 2.7894 (2.8247)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [24]  [180/390]  eta: 0:00:59  lr: 0.000109  loss: 2.8993 (2.8331)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [24]  [190/390]  eta: 0:00:56  lr: 0.000109  loss: 2.8396 (2.8226)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [24]  [200/390]  eta: 0:00:53  lr: 0.000109  loss: 2.6913 (2.8213)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [24]  [210/390]  eta: 0:00:50  lr: 0.000109  loss: 3.0970 (2.8223)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [24]  [220/390]  eta: 0:00:47  lr: 0.000109  loss: 2.6530 (2.8184)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [24]  [230/390]  eta: 0:00:44  lr: 0.000109  loss: 2.8206 (2.8161)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [24]  [240/390]  eta: 0:00:42  lr: 0.000109  loss: 2.8828 (2.8092)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [24]  [250/390]  eta: 0:00:39  lr: 0.000109  loss: 2.8920 (2.8092)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [24]  [260/390]  eta: 0:00:36  lr: 0.000109  loss: 2.7665 (2.7999)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [24]  [270/390]  eta: 0:00:33  lr: 0.000109  loss: 2.9417 (2.8046)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [24]  [280/390]  eta: 0:00:30  lr: 0.000109  loss: 2.7661 (2.7926)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [24]  [290/390]  eta: 0:00:27  lr: 0.000109  loss: 2.5567 (2.7949)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [24]  [300/390]  eta: 0:00:25  lr: 0.000109  loss: 2.9669 (2.7979)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [24]  [310/390]  eta: 0:00:22  lr: 0.000109  loss: 3.0158 (2.8067)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [24]  [320/390]  eta: 0:00:19  lr: 0.000109  loss: 3.1157 (2.8123)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [24]  [330/390]  eta: 0:00:16  lr: 0.000109  loss: 3.0280 (2.8169)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [24]  [340/390]  eta: 0:00:13  lr: 0.000109  loss: 3.0176 (2.8179)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [24]  [350/390]  eta: 0:00:11  lr: 0.000109  loss: 3.0296 (2.8255)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [24]  [360/390]  eta: 0:00:08  lr: 0.000109  loss: 2.9853 (2.8215)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [24]  [370/390]  eta: 0:00:05  lr: 0.000109  loss: 2.8754 (2.8194)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [24]  [380/390]  eta: 0:00:02  lr: 0.000109  loss: 2.8951 (2.8203)  time: 0.2721  data: 0.0002  max mem: 14473
Epoch: [24]  [389/390]  eta: 0:00:00  lr: 0.000109  loss: 2.8951 (2.8202)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [24] Total time: 0:01:48 (0.2784 s / it)
Averaged stats: lr: 0.000109  loss: 2.8951 (2.8202)
Test:  [ 0/53]  eta: 0:01:02  loss: 0.2853 (0.2853)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 94.7917 (94.7917)  acc5_10: 100.0000 (100.0000)  time: 1.1728  data: 1.0256  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2849 (0.2823)  acc1: 96.8750 (96.6856)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.4962)  acc5_10: 100.0000 (99.9527)  time: 0.2446  data: 0.1049  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2896 (0.2925)  acc1: 96.3542 (96.5774)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.4782)  acc5_10: 100.0000 (99.7768)  time: 0.1378  data: 0.0065  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2962 (0.2915)  acc1: 96.3542 (96.5558)  acc5: 100.0000 (99.7984)  acc1_10: 96.3542 (96.4382)  acc5_10: 100.0000 (99.8320)  time: 0.1229  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2895 (0.2926)  acc1: 96.8750 (96.6336)  acc5: 100.0000 (99.7459)  acc1_10: 96.8750 (96.5828)  acc5_10: 100.0000 (99.7967)  time: 0.1207  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2895 (0.2929)  acc1: 96.8750 (96.6095)  acc5: 100.0000 (99.7855)  acc1_10: 96.8750 (96.5788)  acc5_10: 100.0000 (99.8366)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2895 (0.2926)  acc1: 96.8750 (96.6200)  acc5: 100.0000 (99.7900)  acc1_10: 96.8750 (96.6100)  acc5_10: 100.0000 (99.8400)  time: 0.1147  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1472 s / it)
* Acc@1 96.620 Acc@5 99.790 loss 0.293
classifiers_10 : Acc@1 96.610 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.6%
## Using lr  0.0001082 for BACKBONE, cosine lr = 0.0021353 for PRUNER
Epoch: [25]  [  0/390]  eta: 0:10:59  lr: 0.000108  loss: 2.3796 (2.3796)  time: 1.6921  data: 1.3574  max mem: 14473
Epoch: [25]  [ 10/390]  eta: 0:02:34  lr: 0.000108  loss: 2.3796 (2.5458)  time: 0.4063  data: 0.1236  max mem: 14473
Epoch: [25]  [ 20/390]  eta: 0:02:06  lr: 0.000108  loss: 2.6429 (2.5492)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [25]  [ 30/390]  eta: 0:01:55  lr: 0.000108  loss: 2.6429 (2.5900)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [25]  [ 40/390]  eta: 0:01:48  lr: 0.000108  loss: 2.8580 (2.6874)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [25]  [ 50/390]  eta: 0:01:42  lr: 0.000108  loss: 2.8906 (2.7147)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [25]  [ 60/390]  eta: 0:01:38  lr: 0.000108  loss: 2.7425 (2.6977)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [25]  [ 70/390]  eta: 0:01:34  lr: 0.000108  loss: 2.6945 (2.7177)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [25]  [ 80/390]  eta: 0:01:30  lr: 0.000108  loss: 3.0510 (2.7264)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [25]  [ 90/390]  eta: 0:01:27  lr: 0.000108  loss: 2.7323 (2.7163)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [25]  [100/390]  eta: 0:01:23  lr: 0.000108  loss: 2.5151 (2.7161)  time: 0.2776  data: 0.0003  max mem: 14473
Epoch: [25]  [110/390]  eta: 0:01:20  lr: 0.000108  loss: 2.6968 (2.7061)  time: 0.2780  data: 0.0003  max mem: 14473
Epoch: [25]  [120/390]  eta: 0:01:17  lr: 0.000108  loss: 2.6968 (2.7083)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [25]  [130/390]  eta: 0:01:14  lr: 0.000108  loss: 2.6303 (2.7115)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [25]  [140/390]  eta: 0:01:11  lr: 0.000108  loss: 2.9340 (2.7262)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [25]  [150/390]  eta: 0:01:08  lr: 0.000108  loss: 2.8347 (2.7161)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [25]  [160/390]  eta: 0:01:05  lr: 0.000108  loss: 2.4969 (2.7141)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [25]  [170/390]  eta: 0:01:02  lr: 0.000108  loss: 2.8566 (2.7223)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [25]  [180/390]  eta: 0:00:59  lr: 0.000108  loss: 2.9670 (2.7276)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [25]  [190/390]  eta: 0:00:56  lr: 0.000108  loss: 2.8236 (2.7292)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [25]  [200/390]  eta: 0:00:53  lr: 0.000108  loss: 2.8793 (2.7351)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [25]  [210/390]  eta: 0:00:50  lr: 0.000108  loss: 2.8028 (2.7238)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [25]  [220/390]  eta: 0:00:47  lr: 0.000108  loss: 2.7563 (2.7325)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [25]  [230/390]  eta: 0:00:44  lr: 0.000108  loss: 2.9666 (2.7357)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [25]  [240/390]  eta: 0:00:42  lr: 0.000108  loss: 2.9915 (2.7371)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [25]  [250/390]  eta: 0:00:39  lr: 0.000108  loss: 2.7908 (2.7339)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [25]  [260/390]  eta: 0:00:36  lr: 0.000108  loss: 2.7664 (2.7389)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [25]  [270/390]  eta: 0:00:33  lr: 0.000108  loss: 2.8640 (2.7477)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [25]  [280/390]  eta: 0:00:30  lr: 0.000108  loss: 2.9898 (2.7511)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [25]  [290/390]  eta: 0:00:27  lr: 0.000108  loss: 3.2124 (2.7669)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [25]  [300/390]  eta: 0:00:25  lr: 0.000108  loss: 2.9454 (2.7580)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [25]  [310/390]  eta: 0:00:22  lr: 0.000108  loss: 2.9454 (2.7731)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [25]  [320/390]  eta: 0:00:19  lr: 0.000108  loss: 3.1068 (2.7787)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [25]  [330/390]  eta: 0:00:16  lr: 0.000108  loss: 2.9167 (2.7819)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [25]  [340/390]  eta: 0:00:13  lr: 0.000108  loss: 2.7894 (2.7809)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [25]  [350/390]  eta: 0:00:11  lr: 0.000108  loss: 2.8908 (2.7828)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [25]  [360/390]  eta: 0:00:08  lr: 0.000108  loss: 2.8908 (2.7840)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [25]  [370/390]  eta: 0:00:05  lr: 0.000108  loss: 2.8773 (2.7882)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [25]  [380/390]  eta: 0:00:02  lr: 0.000108  loss: 2.8745 (2.7871)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [25]  [389/390]  eta: 0:00:00  lr: 0.000108  loss: 2.8745 (2.7870)  time: 0.2718  data: 0.0002  max mem: 14473
Epoch: [25] Total time: 0:01:48 (0.2783 s / it)
Averaged stats: lr: 0.000108  loss: 2.8745 (2.7870)
Test:  [ 0/53]  eta: 0:01:16  loss: 0.2957 (0.2957)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.4501  data: 1.2961  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2658 (0.2685)  acc1: 96.3542 (96.8277)  acc5: 100.0000 (99.9053)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (99.9527)  time: 0.2522  data: 0.1182  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2658 (0.2804)  acc1: 96.3542 (96.4038)  acc5: 100.0000 (99.7520)  acc1_10: 95.8333 (95.7341)  acc5_10: 100.0000 (99.8264)  time: 0.1270  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2793 (0.2821)  acc1: 95.8333 (96.2534)  acc5: 100.0000 (99.7480)  acc1_10: 95.3125 (95.7325)  acc5_10: 100.0000 (99.7984)  time: 0.1214  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2826 (0.2834)  acc1: 95.8333 (96.1890)  acc5: 99.4792 (99.7205)  acc1_10: 95.8333 (95.7571)  acc5_10: 100.0000 (99.7967)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2826 (0.2832)  acc1: 95.8333 (96.1499)  acc5: 100.0000 (99.7549)  acc1_10: 95.8333 (95.7823)  acc5_10: 100.0000 (99.8366)  time: 0.1192  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2790 (0.2814)  acc1: 95.8333 (96.1800)  acc5: 100.0000 (99.7600)  acc1_10: 95.8333 (95.7900)  acc5_10: 100.0000 (99.8400)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1482 s / it)
* Acc@1 96.180 Acc@5 99.760 loss 0.281
classifiers_10 : Acc@1 95.790 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.2%
## Using lr  0.0001069 for BACKBONE, cosine lr = 0.0021073 for PRUNER
Epoch: [26]  [  0/390]  eta: 0:11:35  lr: 0.000107  loss: 3.2341 (3.2341)  time: 1.7829  data: 1.4497  max mem: 14473
Epoch: [26]  [ 10/390]  eta: 0:02:36  lr: 0.000107  loss: 2.6182 (2.6512)  time: 0.4130  data: 0.1320  max mem: 14473
Epoch: [26]  [ 20/390]  eta: 0:02:08  lr: 0.000107  loss: 2.6008 (2.6155)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [26]  [ 30/390]  eta: 0:01:56  lr: 0.000107  loss: 2.7954 (2.7209)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [26]  [ 40/390]  eta: 0:01:48  lr: 0.000107  loss: 3.1330 (2.7970)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [26]  [ 50/390]  eta: 0:01:43  lr: 0.000107  loss: 3.0785 (2.7744)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [26]  [ 60/390]  eta: 0:01:38  lr: 0.000107  loss: 2.8847 (2.7963)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [26]  [ 70/390]  eta: 0:01:34  lr: 0.000107  loss: 2.9428 (2.8084)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [26]  [ 80/390]  eta: 0:01:30  lr: 0.000107  loss: 2.8861 (2.7871)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [26]  [ 90/390]  eta: 0:01:27  lr: 0.000107  loss: 2.7488 (2.7769)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [26]  [100/390]  eta: 0:01:23  lr: 0.000107  loss: 2.7488 (2.7657)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [26]  [110/390]  eta: 0:01:20  lr: 0.000107  loss: 3.0672 (2.8010)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [26]  [120/390]  eta: 0:01:17  lr: 0.000107  loss: 3.0821 (2.8179)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [26]  [130/390]  eta: 0:01:14  lr: 0.000107  loss: 2.9797 (2.8155)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [26]  [140/390]  eta: 0:01:11  lr: 0.000107  loss: 2.8937 (2.8075)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [26]  [150/390]  eta: 0:01:08  lr: 0.000107  loss: 2.8948 (2.8099)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [26]  [160/390]  eta: 0:01:05  lr: 0.000107  loss: 2.9000 (2.8119)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [26]  [170/390]  eta: 0:01:02  lr: 0.000107  loss: 2.8587 (2.8114)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [26]  [180/390]  eta: 0:00:59  lr: 0.000107  loss: 2.6720 (2.7947)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [26]  [190/390]  eta: 0:00:56  lr: 0.000107  loss: 2.6758 (2.7969)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [26]  [200/390]  eta: 0:00:53  lr: 0.000107  loss: 3.0327 (2.7999)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [26]  [210/390]  eta: 0:00:50  lr: 0.000107  loss: 2.9478 (2.7994)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [26]  [220/390]  eta: 0:00:47  lr: 0.000107  loss: 2.9750 (2.8116)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [26]  [230/390]  eta: 0:00:44  lr: 0.000107  loss: 2.9750 (2.8057)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [26]  [240/390]  eta: 0:00:42  lr: 0.000107  loss: 2.6968 (2.7948)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [26]  [250/390]  eta: 0:00:39  lr: 0.000107  loss: 2.6727 (2.7894)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [26]  [260/390]  eta: 0:00:36  lr: 0.000107  loss: 2.6727 (2.7810)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [26]  [270/390]  eta: 0:00:33  lr: 0.000107  loss: 2.7496 (2.7798)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [26]  [280/390]  eta: 0:00:30  lr: 0.000107  loss: 2.9947 (2.7826)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [26]  [290/390]  eta: 0:00:27  lr: 0.000107  loss: 2.5919 (2.7718)  time: 0.2770  data: 0.0003  max mem: 14473
Epoch: [26]  [300/390]  eta: 0:00:25  lr: 0.000107  loss: 2.5683 (2.7664)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [26]  [310/390]  eta: 0:00:22  lr: 0.000107  loss: 2.7431 (2.7714)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [26]  [320/390]  eta: 0:00:19  lr: 0.000107  loss: 2.7431 (2.7628)  time: 0.2754  data: 0.0002  max mem: 14473
Epoch: [26]  [330/390]  eta: 0:00:16  lr: 0.000107  loss: 2.9651 (2.7720)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [26]  [340/390]  eta: 0:00:13  lr: 0.000107  loss: 3.0508 (2.7750)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [26]  [350/390]  eta: 0:00:11  lr: 0.000107  loss: 2.9121 (2.7761)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [26]  [360/390]  eta: 0:00:08  lr: 0.000107  loss: 2.7836 (2.7730)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [26]  [370/390]  eta: 0:00:05  lr: 0.000107  loss: 2.8493 (2.7773)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [26]  [380/390]  eta: 0:00:02  lr: 0.000107  loss: 2.9464 (2.7753)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [26]  [389/390]  eta: 0:00:00  lr: 0.000107  loss: 2.6923 (2.7769)  time: 0.2724  data: 0.0001  max mem: 14473
Epoch: [26] Total time: 0:01:48 (0.2784 s / it)
Averaged stats: lr: 0.000107  loss: 2.6923 (2.7769)
Test:  [ 0/53]  eta: 0:01:23  loss: 0.2881 (0.2881)  acc1: 96.3542 (96.3542)  acc5: 99.4792 (99.4792)  acc1_10: 96.3542 (96.3542)  acc5_10: 98.9583 (98.9583)  time: 1.5836  data: 1.4318  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2650 (0.2731)  acc1: 96.8750 (96.4489)  acc5: 100.0000 (99.9053)  acc1_10: 96.3542 (96.2121)  acc5_10: 100.0000 (99.7633)  time: 0.2611  data: 0.1304  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2752 (0.2802)  acc1: 96.3542 (96.2798)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.0069)  acc5_10: 100.0000 (99.7024)  time: 0.1251  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2782 (0.2787)  acc1: 95.8333 (96.2366)  acc5: 100.0000 (99.7984)  acc1_10: 95.8333 (96.0518)  acc5_10: 100.0000 (99.7816)  time: 0.1212  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2767 (0.2802)  acc1: 95.8333 (96.2398)  acc5: 100.0000 (99.7840)  acc1_10: 95.8333 (96.0493)  acc5_10: 100.0000 (99.7840)  time: 0.1211  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2767 (0.2785)  acc1: 96.3542 (96.3337)  acc5: 100.0000 (99.8162)  acc1_10: 95.8333 (96.1193)  acc5_10: 100.0000 (99.8162)  time: 0.1204  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2721 (0.2760)  acc1: 96.3542 (96.3500)  acc5: 100.0000 (99.8200)  acc1_10: 96.3542 (96.1500)  acc5_10: 100.0000 (99.8200)  time: 0.1159  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1504 s / it)
* Acc@1 96.350 Acc@5 99.820 loss 0.276
classifiers_10 : Acc@1 96.150 Acc@5 99.820
Accuracy of the network on the 10000 test images: 96.4%
## Using lr  0.0001055 for BACKBONE, cosine lr = 0.0020783 for PRUNER
Epoch: [27]  [  0/390]  eta: 0:12:34  lr: 0.000106  loss: 2.4830 (2.4830)  time: 1.9337  data: 1.4151  max mem: 14473
Epoch: [27]  [ 10/390]  eta: 0:02:43  lr: 0.000106  loss: 2.4507 (2.5273)  time: 0.4311  data: 0.1289  max mem: 14473
Epoch: [27]  [ 20/390]  eta: 0:02:12  lr: 0.000106  loss: 2.4507 (2.6570)  time: 0.2796  data: 0.0003  max mem: 14473
Epoch: [27]  [ 30/390]  eta: 0:01:59  lr: 0.000106  loss: 2.9961 (2.6399)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [27]  [ 40/390]  eta: 0:01:50  lr: 0.000106  loss: 2.4093 (2.6187)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [27]  [ 50/390]  eta: 0:01:45  lr: 0.000106  loss: 2.4579 (2.6592)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [27]  [ 60/390]  eta: 0:01:40  lr: 0.000106  loss: 2.7480 (2.6557)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [27]  [ 70/390]  eta: 0:01:35  lr: 0.000106  loss: 2.6446 (2.6479)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [27]  [ 80/390]  eta: 0:01:31  lr: 0.000106  loss: 2.8656 (2.6717)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [27]  [ 90/390]  eta: 0:01:28  lr: 0.000106  loss: 2.6902 (2.6664)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [27]  [100/390]  eta: 0:01:24  lr: 0.000106  loss: 2.7320 (2.6876)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [27]  [110/390]  eta: 0:01:21  lr: 0.000106  loss: 3.0157 (2.7077)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [27]  [120/390]  eta: 0:01:18  lr: 0.000106  loss: 2.7003 (2.6928)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [27]  [130/390]  eta: 0:01:14  lr: 0.000106  loss: 2.5621 (2.6848)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [27]  [140/390]  eta: 0:01:11  lr: 0.000106  loss: 2.8361 (2.6998)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [27]  [150/390]  eta: 0:01:08  lr: 0.000106  loss: 2.9706 (2.7124)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [27]  [160/390]  eta: 0:01:05  lr: 0.000106  loss: 2.9048 (2.7233)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [27]  [170/390]  eta: 0:01:02  lr: 0.000106  loss: 2.8449 (2.7312)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [27]  [180/390]  eta: 0:00:59  lr: 0.000106  loss: 3.0044 (2.7381)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [27]  [190/390]  eta: 0:00:56  lr: 0.000106  loss: 2.9672 (2.7318)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [27]  [200/390]  eta: 0:00:53  lr: 0.000106  loss: 2.9270 (2.7285)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [27]  [210/390]  eta: 0:00:50  lr: 0.000106  loss: 3.0231 (2.7369)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [27]  [220/390]  eta: 0:00:47  lr: 0.000106  loss: 3.1127 (2.7420)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [27]  [230/390]  eta: 0:00:45  lr: 0.000106  loss: 2.7249 (2.7433)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [27]  [240/390]  eta: 0:00:42  lr: 0.000106  loss: 2.5754 (2.7385)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [27]  [250/390]  eta: 0:00:39  lr: 0.000106  loss: 2.5754 (2.7325)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [27]  [260/390]  eta: 0:00:36  lr: 0.000106  loss: 2.8305 (2.7366)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [27]  [270/390]  eta: 0:00:33  lr: 0.000106  loss: 2.8921 (2.7336)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [27]  [280/390]  eta: 0:00:30  lr: 0.000106  loss: 2.8082 (2.7350)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [27]  [290/390]  eta: 0:00:28  lr: 0.000106  loss: 2.8718 (2.7357)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [27]  [300/390]  eta: 0:00:25  lr: 0.000106  loss: 2.8030 (2.7288)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [27]  [310/390]  eta: 0:00:22  lr: 0.000106  loss: 2.9016 (2.7383)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [27]  [320/390]  eta: 0:00:19  lr: 0.000106  loss: 3.0538 (2.7456)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [27]  [330/390]  eta: 0:00:16  lr: 0.000106  loss: 3.0685 (2.7481)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [27]  [340/390]  eta: 0:00:13  lr: 0.000106  loss: 2.8914 (2.7481)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [27]  [350/390]  eta: 0:00:11  lr: 0.000106  loss: 2.8487 (2.7507)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [27]  [360/390]  eta: 0:00:08  lr: 0.000106  loss: 2.9611 (2.7533)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [27]  [370/390]  eta: 0:00:05  lr: 0.000106  loss: 2.5606 (2.7432)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [27]  [380/390]  eta: 0:00:02  lr: 0.000106  loss: 2.6606 (2.7478)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [27]  [389/390]  eta: 0:00:00  lr: 0.000106  loss: 2.9048 (2.7438)  time: 0.2716  data: 0.0001  max mem: 14473
Epoch: [27] Total time: 0:01:48 (0.2787 s / it)
Averaged stats: lr: 0.000106  loss: 2.9048 (2.7438)
Test:  [ 0/53]  eta: 0:01:16  loss: 0.2469 (0.2469)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.4516  data: 1.2984  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2482 (0.2553)  acc1: 96.3542 (96.4962)  acc5: 100.0000 (99.8580)  acc1_10: 95.8333 (96.1174)  acc5_10: 100.0000 (99.9053)  time: 0.2504  data: 0.1183  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2536 (0.2598)  acc1: 96.3542 (96.2798)  acc5: 100.0000 (99.7520)  acc1_10: 95.8333 (95.8829)  acc5_10: 100.0000 (99.8264)  time: 0.1261  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2670 (0.2619)  acc1: 95.8333 (96.1358)  acc5: 100.0000 (99.7144)  acc1_10: 95.8333 (95.8669)  acc5_10: 100.0000 (99.8152)  time: 0.1224  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2669 (0.2633)  acc1: 95.8333 (96.1382)  acc5: 99.4792 (99.7078)  acc1_10: 95.8333 (95.8969)  acc5_10: 100.0000 (99.7586)  time: 0.1209  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2588 (0.2614)  acc1: 96.3542 (96.2623)  acc5: 100.0000 (99.7447)  acc1_10: 96.3542 (95.9865)  acc5_10: 100.0000 (99.7958)  time: 0.1189  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2588 (0.2598)  acc1: 96.3542 (96.2600)  acc5: 100.0000 (99.7400)  acc1_10: 96.3542 (95.9700)  acc5_10: 100.0000 (99.7900)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1481 s / it)
* Acc@1 96.260 Acc@5 99.740 loss 0.260
classifiers_10 : Acc@1 95.970 Acc@5 99.790
Accuracy of the network on the 10000 test images: 96.3%
## Using lr  0.0001042 for BACKBONE, cosine lr = 0.0020486 for PRUNER
Epoch: [28]  [  0/390]  eta: 0:10:39  lr: 0.000104  loss: 2.4330 (2.4330)  time: 1.6389  data: 1.2984  max mem: 14473
Epoch: [28]  [ 10/390]  eta: 0:02:33  lr: 0.000104  loss: 2.4330 (2.5225)  time: 0.4051  data: 0.1183  max mem: 14473
Epoch: [28]  [ 20/390]  eta: 0:02:07  lr: 0.000104  loss: 2.5371 (2.5795)  time: 0.2786  data: 0.0003  max mem: 14473
Epoch: [28]  [ 30/390]  eta: 0:01:55  lr: 0.000104  loss: 2.6817 (2.7175)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [28]  [ 40/390]  eta: 0:01:48  lr: 0.000104  loss: 3.0494 (2.7378)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [28]  [ 50/390]  eta: 0:01:42  lr: 0.000104  loss: 2.9478 (2.7524)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [28]  [ 60/390]  eta: 0:01:38  lr: 0.000104  loss: 2.9747 (2.7714)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [28]  [ 70/390]  eta: 0:01:34  lr: 0.000104  loss: 2.8815 (2.7536)  time: 0.2759  data: 0.0002  max mem: 14473
Epoch: [28]  [ 80/390]  eta: 0:01:30  lr: 0.000104  loss: 2.9150 (2.7723)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [28]  [ 90/390]  eta: 0:01:27  lr: 0.000104  loss: 3.0191 (2.7952)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [28]  [100/390]  eta: 0:01:23  lr: 0.000104  loss: 3.0312 (2.8171)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [28]  [110/390]  eta: 0:01:20  lr: 0.000104  loss: 2.7569 (2.8107)  time: 0.2775  data: 0.0003  max mem: 14473
Epoch: [28]  [120/390]  eta: 0:01:17  lr: 0.000104  loss: 2.6845 (2.8012)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [28]  [130/390]  eta: 0:01:14  lr: 0.000104  loss: 2.7254 (2.8035)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [28]  [140/390]  eta: 0:01:11  lr: 0.000104  loss: 2.8693 (2.8014)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [28]  [150/390]  eta: 0:01:08  lr: 0.000104  loss: 2.9014 (2.8102)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [28]  [160/390]  eta: 0:01:05  lr: 0.000104  loss: 2.8560 (2.7936)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [28]  [170/390]  eta: 0:01:02  lr: 0.000104  loss: 2.5378 (2.7826)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [28]  [180/390]  eta: 0:00:59  lr: 0.000104  loss: 2.9239 (2.7915)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [28]  [190/390]  eta: 0:00:56  lr: 0.000104  loss: 2.8211 (2.7811)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [28]  [200/390]  eta: 0:00:53  lr: 0.000104  loss: 2.7077 (2.7737)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [28]  [210/390]  eta: 0:00:50  lr: 0.000104  loss: 2.9653 (2.7855)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [28]  [220/390]  eta: 0:00:47  lr: 0.000104  loss: 2.9653 (2.7802)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [28]  [230/390]  eta: 0:00:45  lr: 0.000104  loss: 2.8839 (2.7911)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [28]  [240/390]  eta: 0:00:42  lr: 0.000104  loss: 2.8623 (2.7835)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [28]  [250/390]  eta: 0:00:39  lr: 0.000104  loss: 2.7366 (2.7803)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [28]  [260/390]  eta: 0:00:36  lr: 0.000104  loss: 2.7580 (2.7757)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [28]  [270/390]  eta: 0:00:33  lr: 0.000104  loss: 2.7484 (2.7675)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [28]  [280/390]  eta: 0:00:30  lr: 0.000104  loss: 2.9794 (2.7709)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [28]  [290/390]  eta: 0:00:28  lr: 0.000104  loss: 3.0469 (2.7663)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [28]  [300/390]  eta: 0:00:25  lr: 0.000104  loss: 2.9122 (2.7677)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [28]  [310/390]  eta: 0:00:22  lr: 0.000104  loss: 2.9854 (2.7715)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [28]  [320/390]  eta: 0:00:19  lr: 0.000104  loss: 2.7922 (2.7681)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [28]  [330/390]  eta: 0:00:16  lr: 0.000104  loss: 2.7922 (2.7636)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [28]  [340/390]  eta: 0:00:13  lr: 0.000104  loss: 2.8768 (2.7642)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [28]  [350/390]  eta: 0:00:11  lr: 0.000104  loss: 2.8928 (2.7665)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [28]  [360/390]  eta: 0:00:08  lr: 0.000104  loss: 2.7597 (2.7575)  time: 0.2786  data: 0.0003  max mem: 14473
Epoch: [28]  [370/390]  eta: 0:00:05  lr: 0.000104  loss: 2.9062 (2.7625)  time: 0.2798  data: 0.0003  max mem: 14473
Epoch: [28]  [380/390]  eta: 0:00:02  lr: 0.000104  loss: 2.9456 (2.7635)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [28]  [389/390]  eta: 0:00:00  lr: 0.000104  loss: 2.9456 (2.7674)  time: 0.2715  data: 0.0001  max mem: 14473
Epoch: [28] Total time: 0:01:48 (0.2791 s / it)
Averaged stats: lr: 0.000104  loss: 2.9456 (2.7674)
Test:  [ 0/53]  eta: 0:01:21  loss: 0.3132 (0.3132)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.5366  data: 1.3763  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2898 (0.2899)  acc1: 96.3542 (96.4015)  acc5: 100.0000 (99.9527)  acc1_10: 96.3542 (95.9280)  acc5_10: 100.0000 (99.9527)  time: 0.2652  data: 0.1316  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2902 (0.2989)  acc1: 96.3542 (96.1558)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (95.7589)  acc5_10: 100.0000 (99.7768)  time: 0.1304  data: 0.0037  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2995 (0.2966)  acc1: 95.8333 (96.1694)  acc5: 100.0000 (99.7984)  acc1_10: 95.8333 (95.8501)  acc5_10: 100.0000 (99.8152)  time: 0.1227  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2929 (0.2960)  acc1: 96.3542 (96.1890)  acc5: 100.0000 (99.8095)  acc1_10: 95.8333 (95.8587)  acc5_10: 100.0000 (99.8222)  time: 0.1210  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2926 (0.2950)  acc1: 96.3542 (96.1601)  acc5: 100.0000 (99.8264)  acc1_10: 95.8333 (95.9457)  acc5_10: 100.0000 (99.8468)  time: 0.1188  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2926 (0.2959)  acc1: 95.8333 (96.1200)  acc5: 100.0000 (99.8300)  acc1_10: 95.8333 (95.8800)  acc5_10: 100.0000 (99.8500)  time: 0.1144  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1513 s / it)
* Acc@1 96.120 Acc@5 99.830 loss 0.296
classifiers_10 : Acc@1 95.880 Acc@5 99.850
Accuracy of the network on the 10000 test images: 96.1%
## Using lr  0.0001027 for BACKBONE, cosine lr = 0.0020181 for PRUNER
Epoch: [29]  [  0/390]  eta: 0:10:55  lr: 0.000103  loss: 2.5352 (2.5352)  time: 1.6802  data: 1.3500  max mem: 14473
Epoch: [29]  [ 10/390]  eta: 0:02:35  lr: 0.000103  loss: 2.5973 (2.6584)  time: 0.4097  data: 0.1230  max mem: 14473
Epoch: [29]  [ 20/390]  eta: 0:02:07  lr: 0.000103  loss: 2.7197 (2.7056)  time: 0.2779  data: 0.0003  max mem: 14473
Epoch: [29]  [ 30/390]  eta: 0:01:55  lr: 0.000103  loss: 2.8312 (2.7658)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [29]  [ 40/390]  eta: 0:01:48  lr: 0.000103  loss: 2.9194 (2.8273)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [29]  [ 50/390]  eta: 0:01:43  lr: 0.000103  loss: 2.9142 (2.8168)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [29]  [ 60/390]  eta: 0:01:38  lr: 0.000103  loss: 2.8451 (2.7938)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [29]  [ 70/390]  eta: 0:01:34  lr: 0.000103  loss: 3.0118 (2.8139)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [29]  [ 80/390]  eta: 0:01:31  lr: 0.000103  loss: 2.9191 (2.8079)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [29]  [ 90/390]  eta: 0:01:27  lr: 0.000103  loss: 2.8733 (2.8015)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [29]  [100/390]  eta: 0:01:23  lr: 0.000103  loss: 2.6041 (2.7692)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [29]  [110/390]  eta: 0:01:20  lr: 0.000103  loss: 2.8378 (2.8020)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [29]  [120/390]  eta: 0:01:17  lr: 0.000103  loss: 3.0526 (2.7939)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [29]  [130/390]  eta: 0:01:14  lr: 0.000103  loss: 2.5881 (2.7914)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [29]  [140/390]  eta: 0:01:11  lr: 0.000103  loss: 2.9132 (2.8019)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [29]  [150/390]  eta: 0:01:08  lr: 0.000103  loss: 2.9024 (2.7979)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [29]  [160/390]  eta: 0:01:05  lr: 0.000103  loss: 2.9018 (2.8011)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [29]  [170/390]  eta: 0:01:02  lr: 0.000103  loss: 2.9705 (2.7949)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [29]  [180/390]  eta: 0:00:59  lr: 0.000103  loss: 2.9657 (2.8064)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [29]  [190/390]  eta: 0:00:56  lr: 0.000103  loss: 3.0636 (2.8195)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [29]  [200/390]  eta: 0:00:53  lr: 0.000103  loss: 3.0636 (2.8294)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [29]  [210/390]  eta: 0:00:50  lr: 0.000103  loss: 2.9040 (2.8241)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [29]  [220/390]  eta: 0:00:47  lr: 0.000103  loss: 2.6634 (2.8094)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [29]  [230/390]  eta: 0:00:44  lr: 0.000103  loss: 2.7008 (2.8169)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [29]  [240/390]  eta: 0:00:42  lr: 0.000103  loss: 3.0377 (2.8209)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [29]  [250/390]  eta: 0:00:39  lr: 0.000103  loss: 2.6713 (2.8107)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [29]  [260/390]  eta: 0:00:36  lr: 0.000103  loss: 2.6011 (2.8102)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [29]  [270/390]  eta: 0:00:33  lr: 0.000103  loss: 2.6183 (2.7983)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [29]  [280/390]  eta: 0:00:30  lr: 0.000103  loss: 2.6183 (2.7911)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [29]  [290/390]  eta: 0:00:27  lr: 0.000103  loss: 2.7729 (2.7870)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [29]  [300/390]  eta: 0:00:25  lr: 0.000103  loss: 2.7729 (2.7903)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [29]  [310/390]  eta: 0:00:22  lr: 0.000103  loss: 2.7080 (2.7829)  time: 0.2792  data: 0.0003  max mem: 14473
Epoch: [29]  [320/390]  eta: 0:00:19  lr: 0.000103  loss: 2.6215 (2.7788)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [29]  [330/390]  eta: 0:00:16  lr: 0.000103  loss: 2.7094 (2.7811)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [29]  [340/390]  eta: 0:00:13  lr: 0.000103  loss: 2.8244 (2.7734)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [29]  [350/390]  eta: 0:00:11  lr: 0.000103  loss: 2.9110 (2.7782)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [29]  [360/390]  eta: 0:00:08  lr: 0.000103  loss: 2.9110 (2.7739)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [29]  [370/390]  eta: 0:00:05  lr: 0.000103  loss: 2.8563 (2.7760)  time: 0.2744  data: 0.0002  max mem: 14473
Epoch: [29]  [380/390]  eta: 0:00:02  lr: 0.000103  loss: 2.8563 (2.7731)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [29]  [389/390]  eta: 0:00:00  lr: 0.000103  loss: 2.8267 (2.7765)  time: 0.2740  data: 0.0001  max mem: 14473
Epoch: [29] Total time: 0:01:48 (0.2789 s / it)
Averaged stats: lr: 0.000103  loss: 2.8267 (2.7765)
Test:  [ 0/53]  eta: 0:00:58  loss: 0.4146 (0.4146)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.1047  data: 0.9554  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.3843 (0.3890)  acc1: 96.8750 (96.6856)  acc5: 100.0000 (99.8106)  acc1_10: 96.3542 (96.4962)  acc5_10: 100.0000 (99.7633)  time: 0.2620  data: 0.1335  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3964 (0.4007)  acc1: 96.3542 (96.2550)  acc5: 100.0000 (99.7520)  acc1_10: 95.3125 (96.0069)  acc5_10: 100.0000 (99.7768)  time: 0.1506  data: 0.0258  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.4043 (0.3996)  acc1: 95.8333 (96.1862)  acc5: 100.0000 (99.7816)  acc1_10: 95.3125 (95.6821)  acc5_10: 100.0000 (99.7648)  time: 0.1227  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3919 (0.4016)  acc1: 95.8333 (96.0493)  acc5: 100.0000 (99.7205)  acc1_10: 95.3125 (95.6301)  acc5_10: 99.4792 (99.7332)  time: 0.1206  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.4032 (0.4019)  acc1: 95.8333 (96.0172)  acc5: 100.0000 (99.7549)  acc1_10: 95.3125 (95.6495)  acc5_10: 100.0000 (99.7651)  time: 0.1194  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3998 (0.3998)  acc1: 95.8333 (96.0400)  acc5: 100.0000 (99.7600)  acc1_10: 95.3125 (95.6500)  acc5_10: 100.0000 (99.7700)  time: 0.1149  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1508 s / it)
* Acc@1 96.040 Acc@5 99.760 loss 0.400
classifiers_10 : Acc@1 95.650 Acc@5 99.770
Accuracy of the network on the 10000 test images: 96.0%
## Using lr  0.0001013 for BACKBONE, cosine lr = 0.0019868 for PRUNER
Epoch: [30]  [  0/390]  eta: 0:08:50  lr: 0.000101  loss: 3.1447 (3.1447)  time: 1.3606  data: 1.0399  max mem: 14473
Epoch: [30]  [ 10/390]  eta: 0:02:27  lr: 0.000101  loss: 2.9895 (2.8308)  time: 0.3871  data: 0.1012  max mem: 14473
Epoch: [30]  [ 20/390]  eta: 0:02:03  lr: 0.000101  loss: 2.5451 (2.5598)  time: 0.2813  data: 0.0038  max mem: 14473
Epoch: [30]  [ 30/390]  eta: 0:01:52  lr: 0.000101  loss: 2.3457 (2.5720)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [30]  [ 40/390]  eta: 0:01:46  lr: 0.000101  loss: 2.5806 (2.6052)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [30]  [ 50/390]  eta: 0:01:41  lr: 0.000101  loss: 2.7172 (2.6124)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [30]  [ 60/390]  eta: 0:01:36  lr: 0.000101  loss: 2.7018 (2.6328)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [30]  [ 70/390]  eta: 0:01:33  lr: 0.000101  loss: 2.8938 (2.6676)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [30]  [ 80/390]  eta: 0:01:29  lr: 0.000101  loss: 2.9802 (2.7013)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [30]  [ 90/390]  eta: 0:01:26  lr: 0.000101  loss: 2.8436 (2.7048)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [30]  [100/390]  eta: 0:01:22  lr: 0.000101  loss: 2.7049 (2.7005)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [30]  [110/390]  eta: 0:01:19  lr: 0.000101  loss: 2.7562 (2.7222)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [30]  [120/390]  eta: 0:01:16  lr: 0.000101  loss: 3.0148 (2.7228)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [30]  [130/390]  eta: 0:01:13  lr: 0.000101  loss: 2.7428 (2.7165)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [30]  [140/390]  eta: 0:01:10  lr: 0.000101  loss: 2.7428 (2.7194)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [30]  [150/390]  eta: 0:01:07  lr: 0.000101  loss: 2.9753 (2.7328)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [30]  [160/390]  eta: 0:01:04  lr: 0.000101  loss: 2.8174 (2.7178)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [30]  [170/390]  eta: 0:01:01  lr: 0.000101  loss: 2.6291 (2.7173)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [30]  [180/390]  eta: 0:00:58  lr: 0.000101  loss: 2.6515 (2.7204)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [30]  [190/390]  eta: 0:00:56  lr: 0.000101  loss: 2.4674 (2.7029)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [30]  [200/390]  eta: 0:00:53  lr: 0.000101  loss: 2.9493 (2.7212)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [30]  [210/390]  eta: 0:00:50  lr: 0.000101  loss: 2.9774 (2.7232)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [30]  [220/390]  eta: 0:00:47  lr: 0.000101  loss: 2.7089 (2.7239)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [30]  [230/390]  eta: 0:00:44  lr: 0.000101  loss: 2.7589 (2.7227)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [30]  [240/390]  eta: 0:00:41  lr: 0.000101  loss: 2.6835 (2.7201)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [30]  [250/390]  eta: 0:00:39  lr: 0.000101  loss: 2.6990 (2.7245)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [30]  [260/390]  eta: 0:00:36  lr: 0.000101  loss: 3.0199 (2.7238)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [30]  [270/390]  eta: 0:00:33  lr: 0.000101  loss: 2.6055 (2.7212)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [30]  [280/390]  eta: 0:00:30  lr: 0.000101  loss: 2.8715 (2.7281)  time: 0.2758  data: 0.0002  max mem: 14473
Epoch: [30]  [290/390]  eta: 0:00:27  lr: 0.000101  loss: 2.6532 (2.7185)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [30]  [300/390]  eta: 0:00:25  lr: 0.000101  loss: 2.6532 (2.7249)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [30]  [310/390]  eta: 0:00:22  lr: 0.000101  loss: 3.0378 (2.7296)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [30]  [320/390]  eta: 0:00:19  lr: 0.000101  loss: 2.8828 (2.7259)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [30]  [330/390]  eta: 0:00:16  lr: 0.000101  loss: 2.5719 (2.7276)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [30]  [340/390]  eta: 0:00:13  lr: 0.000101  loss: 2.9820 (2.7331)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [30]  [350/390]  eta: 0:00:11  lr: 0.000101  loss: 2.9985 (2.7350)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [30]  [360/390]  eta: 0:00:08  lr: 0.000101  loss: 2.7732 (2.7352)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [30]  [370/390]  eta: 0:00:05  lr: 0.000101  loss: 2.7514 (2.7378)  time: 0.2828  data: 0.0002  max mem: 14473
Epoch: [30]  [380/390]  eta: 0:00:02  lr: 0.000101  loss: 2.8523 (2.7389)  time: 0.2819  data: 0.0002  max mem: 14473
Epoch: [30]  [389/390]  eta: 0:00:00  lr: 0.000101  loss: 2.7130 (2.7368)  time: 0.2726  data: 0.0001  max mem: 14473
Epoch: [30] Total time: 0:01:48 (0.2784 s / it)
Averaged stats: lr: 0.000101  loss: 2.7130 (2.7368)
Test:  [ 0/53]  eta: 0:01:12  loss: 0.2977 (0.2977)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.3604  data: 1.2110  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2652 (0.2620)  acc1: 96.8750 (96.7330)  acc5: 100.0000 (99.8580)  acc1_10: 96.3542 (96.4489)  acc5_10: 100.0000 (99.9053)  time: 0.2474  data: 0.1136  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2665 (0.2729)  acc1: 96.3542 (96.4038)  acc5: 100.0000 (99.7768)  acc1_10: 96.3542 (96.1806)  acc5_10: 100.0000 (99.7768)  time: 0.1292  data: 0.0020  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2678 (0.2725)  acc1: 95.8333 (96.4214)  acc5: 100.0000 (99.8320)  acc1_10: 95.8333 (96.1694)  acc5_10: 100.0000 (99.8320)  time: 0.1215  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2678 (0.2753)  acc1: 96.3542 (96.3034)  acc5: 100.0000 (99.7967)  acc1_10: 95.8333 (96.0366)  acc5_10: 100.0000 (99.8222)  time: 0.1199  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2728 (0.2741)  acc1: 96.3542 (96.3950)  acc5: 100.0000 (99.8366)  acc1_10: 95.8333 (96.1295)  acc5_10: 100.0000 (99.8366)  time: 0.1189  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2693 (0.2726)  acc1: 96.3542 (96.4000)  acc5: 100.0000 (99.8400)  acc1_10: 96.3542 (96.1500)  acc5_10: 100.0000 (99.8400)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1472 s / it)
* Acc@1 96.400 Acc@5 99.840 loss 0.273
classifiers_10 : Acc@1 96.150 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.4%
## Using lr  0.0000998 for BACKBONE, cosine lr = 0.0019548 for PRUNER
Epoch: [31]  [  0/390]  eta: 0:09:50  lr: 0.000100  loss: 2.9181 (2.9181)  time: 1.5128  data: 1.1798  max mem: 14473
Epoch: [31]  [ 10/390]  eta: 0:02:28  lr: 0.000100  loss: 2.4375 (2.3315)  time: 0.3917  data: 0.1075  max mem: 14473
Epoch: [31]  [ 20/390]  eta: 0:02:04  lr: 0.000100  loss: 2.4506 (2.4787)  time: 0.2769  data: 0.0003  max mem: 14473
Epoch: [31]  [ 30/390]  eta: 0:01:53  lr: 0.000100  loss: 2.5965 (2.4899)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [31]  [ 40/390]  eta: 0:01:47  lr: 0.000100  loss: 2.5169 (2.5225)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [31]  [ 50/390]  eta: 0:01:41  lr: 0.000100  loss: 2.3898 (2.5264)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [31]  [ 60/390]  eta: 0:01:37  lr: 0.000100  loss: 2.6117 (2.5646)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [31]  [ 70/390]  eta: 0:01:33  lr: 0.000100  loss: 2.8342 (2.5839)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [31]  [ 80/390]  eta: 0:01:29  lr: 0.000100  loss: 2.8892 (2.6173)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [31]  [ 90/390]  eta: 0:01:26  lr: 0.000100  loss: 2.8102 (2.6063)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [31]  [100/390]  eta: 0:01:23  lr: 0.000100  loss: 2.3960 (2.5863)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [31]  [110/390]  eta: 0:01:20  lr: 0.000100  loss: 2.4172 (2.5775)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [31]  [120/390]  eta: 0:01:16  lr: 0.000100  loss: 2.5490 (2.5888)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [31]  [130/390]  eta: 0:01:13  lr: 0.000100  loss: 2.6223 (2.5943)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [31]  [140/390]  eta: 0:01:10  lr: 0.000100  loss: 2.6324 (2.6066)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [31]  [150/390]  eta: 0:01:07  lr: 0.000100  loss: 2.9867 (2.6194)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [31]  [160/390]  eta: 0:01:04  lr: 0.000100  loss: 2.9867 (2.6274)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [31]  [170/390]  eta: 0:01:02  lr: 0.000100  loss: 2.7296 (2.6371)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [31]  [180/390]  eta: 0:00:59  lr: 0.000100  loss: 2.7296 (2.6402)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [31]  [190/390]  eta: 0:00:56  lr: 0.000100  loss: 2.7117 (2.6443)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [31]  [200/390]  eta: 0:00:53  lr: 0.000100  loss: 2.8023 (2.6534)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [31]  [210/390]  eta: 0:00:50  lr: 0.000100  loss: 2.9140 (2.6638)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [31]  [220/390]  eta: 0:00:47  lr: 0.000100  loss: 2.9140 (2.6705)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [31]  [230/390]  eta: 0:00:44  lr: 0.000100  loss: 2.8606 (2.6748)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [31]  [240/390]  eta: 0:00:41  lr: 0.000100  loss: 2.8629 (2.6760)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [31]  [250/390]  eta: 0:00:39  lr: 0.000100  loss: 2.8973 (2.6819)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [31]  [260/390]  eta: 0:00:36  lr: 0.000100  loss: 2.8462 (2.6855)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [31]  [270/390]  eta: 0:00:33  lr: 0.000100  loss: 2.7834 (2.6811)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [31]  [280/390]  eta: 0:00:30  lr: 0.000100  loss: 2.2362 (2.6676)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [31]  [290/390]  eta: 0:00:27  lr: 0.000100  loss: 2.6908 (2.6749)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [31]  [300/390]  eta: 0:00:25  lr: 0.000100  loss: 2.7762 (2.6716)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [31]  [310/390]  eta: 0:00:22  lr: 0.000100  loss: 2.7926 (2.6747)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [31]  [320/390]  eta: 0:00:19  lr: 0.000100  loss: 2.9018 (2.6815)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [31]  [330/390]  eta: 0:00:16  lr: 0.000100  loss: 2.8565 (2.6793)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [31]  [340/390]  eta: 0:00:13  lr: 0.000100  loss: 2.6837 (2.6773)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [31]  [350/390]  eta: 0:00:11  lr: 0.000100  loss: 2.4959 (2.6691)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [31]  [360/390]  eta: 0:00:08  lr: 0.000100  loss: 2.5797 (2.6675)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [31]  [370/390]  eta: 0:00:05  lr: 0.000100  loss: 2.7280 (2.6673)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [31]  [380/390]  eta: 0:00:02  lr: 0.000100  loss: 2.7797 (2.6748)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [31]  [389/390]  eta: 0:00:00  lr: 0.000100  loss: 2.7478 (2.6747)  time: 0.2718  data: 0.0001  max mem: 14473
Epoch: [31] Total time: 0:01:48 (0.2777 s / it)
Averaged stats: lr: 0.000100  loss: 2.7478 (2.6747)
Test:  [ 0/53]  eta: 0:01:18  loss: 0.2683 (0.2683)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.4893  data: 1.3279  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2582 (0.2591)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (99.8580)  acc1_10: 96.3542 (96.5909)  acc5_10: 100.0000 (99.9053)  time: 0.2583  data: 0.1229  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2626 (0.2669)  acc1: 96.8750 (96.6518)  acc5: 100.0000 (99.8264)  acc1_10: 96.3542 (96.4286)  acc5_10: 100.0000 (99.7520)  time: 0.1279  data: 0.0013  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2763 (0.2684)  acc1: 96.3542 (96.5558)  acc5: 100.0000 (99.8488)  acc1_10: 96.3542 (96.4550)  acc5_10: 100.0000 (99.8320)  time: 0.1216  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2595 (0.2678)  acc1: 96.8750 (96.6845)  acc5: 100.0000 (99.8222)  acc1_10: 96.8750 (96.5955)  acc5_10: 100.0000 (99.8222)  time: 0.1209  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2615 (0.2660)  acc1: 96.8750 (96.7525)  acc5: 100.0000 (99.8468)  acc1_10: 96.8750 (96.6401)  acc5_10: 100.0000 (99.8366)  time: 0.1187  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2573 (0.2638)  acc1: 96.8750 (96.7700)  acc5: 100.0000 (99.8500)  acc1_10: 96.8750 (96.6500)  acc5_10: 100.0000 (99.8400)  time: 0.1144  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1494 s / it)
* Acc@1 96.770 Acc@5 99.850 loss 0.264
classifiers_10 : Acc@1 96.650 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.8%
## Using lr  0.0000983 for BACKBONE, cosine lr = 0.0019221 for PRUNER
Epoch: [32]  [  0/390]  eta: 0:11:39  lr: 0.000098  loss: 2.3278 (2.3278)  time: 1.7926  data: 1.4866  max mem: 14473
Epoch: [32]  [ 10/390]  eta: 0:02:36  lr: 0.000098  loss: 2.7724 (2.5636)  time: 0.4113  data: 0.1354  max mem: 14473
Epoch: [32]  [ 20/390]  eta: 0:02:08  lr: 0.000098  loss: 2.7724 (2.6777)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [32]  [ 30/390]  eta: 0:01:56  lr: 0.000098  loss: 2.9265 (2.7294)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [32]  [ 40/390]  eta: 0:01:48  lr: 0.000098  loss: 2.9617 (2.7904)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [32]  [ 50/390]  eta: 0:01:43  lr: 0.000098  loss: 3.0098 (2.7952)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [32]  [ 60/390]  eta: 0:01:38  lr: 0.000098  loss: 2.7782 (2.7637)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [32]  [ 70/390]  eta: 0:01:34  lr: 0.000098  loss: 2.6724 (2.7656)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [32]  [ 80/390]  eta: 0:01:30  lr: 0.000098  loss: 2.7704 (2.7573)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [32]  [ 90/390]  eta: 0:01:27  lr: 0.000098  loss: 2.7704 (2.7404)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [32]  [100/390]  eta: 0:01:23  lr: 0.000098  loss: 2.9033 (2.7637)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [32]  [110/390]  eta: 0:01:20  lr: 0.000098  loss: 3.0063 (2.7754)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [32]  [120/390]  eta: 0:01:17  lr: 0.000098  loss: 2.7440 (2.7679)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [32]  [130/390]  eta: 0:01:14  lr: 0.000098  loss: 2.4804 (2.7554)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [32]  [140/390]  eta: 0:01:11  lr: 0.000098  loss: 2.8341 (2.7602)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [32]  [150/390]  eta: 0:01:08  lr: 0.000098  loss: 2.9125 (2.7647)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [32]  [160/390]  eta: 0:01:05  lr: 0.000098  loss: 2.8756 (2.7585)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [32]  [170/390]  eta: 0:01:02  lr: 0.000098  loss: 2.7618 (2.7566)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [32]  [180/390]  eta: 0:00:59  lr: 0.000098  loss: 2.8599 (2.7614)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [32]  [190/390]  eta: 0:00:56  lr: 0.000098  loss: 2.9115 (2.7656)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [32]  [200/390]  eta: 0:00:53  lr: 0.000098  loss: 2.9029 (2.7684)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [32]  [210/390]  eta: 0:00:50  lr: 0.000098  loss: 2.9317 (2.7723)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [32]  [220/390]  eta: 0:00:47  lr: 0.000098  loss: 2.9917 (2.7773)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [32]  [230/390]  eta: 0:00:44  lr: 0.000098  loss: 2.9351 (2.7735)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [32]  [240/390]  eta: 0:00:42  lr: 0.000098  loss: 2.8918 (2.7769)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [32]  [250/390]  eta: 0:00:39  lr: 0.000098  loss: 3.0793 (2.7798)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [32]  [260/390]  eta: 0:00:36  lr: 0.000098  loss: 3.0512 (2.7795)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [32]  [270/390]  eta: 0:00:33  lr: 0.000098  loss: 2.3432 (2.7657)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [32]  [280/390]  eta: 0:00:30  lr: 0.000098  loss: 2.5109 (2.7675)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [32]  [290/390]  eta: 0:00:27  lr: 0.000098  loss: 3.0203 (2.7775)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [32]  [300/390]  eta: 0:00:25  lr: 0.000098  loss: 2.8619 (2.7713)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [32]  [310/390]  eta: 0:00:22  lr: 0.000098  loss: 2.5988 (2.7661)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [32]  [320/390]  eta: 0:00:19  lr: 0.000098  loss: 2.5988 (2.7633)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [32]  [330/390]  eta: 0:00:16  lr: 0.000098  loss: 2.6589 (2.7601)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [32]  [340/390]  eta: 0:00:13  lr: 0.000098  loss: 2.8418 (2.7625)  time: 0.2718  data: 0.0003  max mem: 14473
Epoch: [32]  [350/390]  eta: 0:00:11  lr: 0.000098  loss: 2.8978 (2.7641)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [32]  [360/390]  eta: 0:00:08  lr: 0.000098  loss: 2.7719 (2.7605)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [32]  [370/390]  eta: 0:00:05  lr: 0.000098  loss: 2.7719 (2.7640)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [32]  [380/390]  eta: 0:00:02  lr: 0.000098  loss: 2.7062 (2.7597)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [32]  [389/390]  eta: 0:00:00  lr: 0.000098  loss: 2.7062 (2.7635)  time: 0.2714  data: 0.0001  max mem: 14473
Epoch: [32] Total time: 0:01:48 (0.2779 s / it)
Averaged stats: lr: 0.000098  loss: 2.7062 (2.7635)
Test:  [ 0/53]  eta: 0:01:20  loss: 0.3743 (0.3743)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  acc1_10: 94.2708 (94.2708)  acc5_10: 100.0000 (100.0000)  time: 1.5106  data: 1.3530  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2997 (0.3110)  acc1: 96.8750 (96.8277)  acc5: 100.0000 (99.9053)  acc1_10: 96.3542 (96.6856)  acc5_10: 100.0000 (99.9527)  time: 0.2567  data: 0.1233  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3231 (0.3231)  acc1: 96.3542 (96.3046)  acc5: 100.0000 (99.6776)  acc1_10: 96.3542 (96.2798)  acc5_10: 100.0000 (99.7520)  time: 0.1265  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3287 (0.3227)  acc1: 95.8333 (96.1694)  acc5: 100.0000 (99.7144)  acc1_10: 95.8333 (96.1358)  acc5_10: 100.0000 (99.8152)  time: 0.1212  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3242 (0.3247)  acc1: 95.8333 (96.1255)  acc5: 100.0000 (99.6951)  acc1_10: 95.8333 (96.1001)  acc5_10: 100.0000 (99.8095)  time: 0.1198  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3246 (0.3225)  acc1: 95.8333 (96.1806)  acc5: 100.0000 (99.7243)  acc1_10: 96.3542 (96.1601)  acc5_10: 100.0000 (99.8468)  time: 0.1185  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3273 (0.3225)  acc1: 95.8333 (96.1700)  acc5: 100.0000 (99.7300)  acc1_10: 95.8333 (96.1400)  acc5_10: 100.0000 (99.8500)  time: 0.1140  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1489 s / it)
* Acc@1 96.170 Acc@5 99.730 loss 0.323
classifiers_10 : Acc@1 96.140 Acc@5 99.850
Accuracy of the network on the 10000 test images: 96.2%
## Using lr  0.0000968 for BACKBONE, cosine lr = 0.0018888 for PRUNER
Epoch: [33]  [  0/390]  eta: 0:10:14  lr: 0.000097  loss: 3.2537 (3.2537)  time: 1.5747  data: 1.2399  max mem: 14473
Epoch: [33]  [ 10/390]  eta: 0:02:30  lr: 0.000097  loss: 2.8507 (2.7884)  time: 0.3959  data: 0.1130  max mem: 14473
Epoch: [33]  [ 20/390]  eta: 0:02:05  lr: 0.000097  loss: 2.8507 (2.7156)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [33]  [ 30/390]  eta: 0:01:54  lr: 0.000097  loss: 2.9773 (2.7634)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [33]  [ 40/390]  eta: 0:01:47  lr: 0.000097  loss: 3.1500 (2.8063)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [33]  [ 50/390]  eta: 0:01:42  lr: 0.000097  loss: 3.0342 (2.8484)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [33]  [ 60/390]  eta: 0:01:37  lr: 0.000097  loss: 2.8514 (2.8048)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [33]  [ 70/390]  eta: 0:01:33  lr: 0.000097  loss: 2.7410 (2.8099)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [33]  [ 80/390]  eta: 0:01:30  lr: 0.000097  loss: 2.7917 (2.7954)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [33]  [ 90/390]  eta: 0:01:26  lr: 0.000097  loss: 2.7566 (2.7999)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [33]  [100/390]  eta: 0:01:23  lr: 0.000097  loss: 2.8633 (2.8046)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [33]  [110/390]  eta: 0:01:20  lr: 0.000097  loss: 2.8938 (2.7809)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [33]  [120/390]  eta: 0:01:17  lr: 0.000097  loss: 2.4868 (2.7499)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [33]  [130/390]  eta: 0:01:14  lr: 0.000097  loss: 2.4868 (2.7336)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [33]  [140/390]  eta: 0:01:11  lr: 0.000097  loss: 2.8586 (2.7491)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [33]  [150/390]  eta: 0:01:08  lr: 0.000097  loss: 3.1132 (2.7652)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [33]  [160/390]  eta: 0:01:05  lr: 0.000097  loss: 2.9906 (2.7651)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [33]  [170/390]  eta: 0:01:02  lr: 0.000097  loss: 2.9007 (2.7696)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [33]  [180/390]  eta: 0:00:59  lr: 0.000097  loss: 2.9799 (2.7726)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [33]  [190/390]  eta: 0:00:56  lr: 0.000097  loss: 2.8214 (2.7620)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [33]  [200/390]  eta: 0:00:53  lr: 0.000097  loss: 2.4848 (2.7525)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [33]  [210/390]  eta: 0:00:50  lr: 0.000097  loss: 2.4848 (2.7397)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [33]  [220/390]  eta: 0:00:47  lr: 0.000097  loss: 2.9476 (2.7463)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [33]  [230/390]  eta: 0:00:44  lr: 0.000097  loss: 2.9742 (2.7514)  time: 0.2721  data: 0.0003  max mem: 14473
Epoch: [33]  [240/390]  eta: 0:00:41  lr: 0.000097  loss: 2.8936 (2.7522)  time: 0.2718  data: 0.0003  max mem: 14473
Epoch: [33]  [250/390]  eta: 0:00:39  lr: 0.000097  loss: 2.6251 (2.7469)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [33]  [260/390]  eta: 0:00:36  lr: 0.000097  loss: 2.5280 (2.7483)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [33]  [270/390]  eta: 0:00:33  lr: 0.000097  loss: 2.8559 (2.7484)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [33]  [280/390]  eta: 0:00:30  lr: 0.000097  loss: 3.0776 (2.7589)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [33]  [290/390]  eta: 0:00:27  lr: 0.000097  loss: 2.9270 (2.7559)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [33]  [300/390]  eta: 0:00:25  lr: 0.000097  loss: 2.7102 (2.7481)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [33]  [310/390]  eta: 0:00:22  lr: 0.000097  loss: 2.8018 (2.7572)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [33]  [320/390]  eta: 0:00:19  lr: 0.000097  loss: 2.8810 (2.7536)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [33]  [330/390]  eta: 0:00:16  lr: 0.000097  loss: 2.7577 (2.7537)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [33]  [340/390]  eta: 0:00:13  lr: 0.000097  loss: 2.9341 (2.7577)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [33]  [350/390]  eta: 0:00:11  lr: 0.000097  loss: 3.0257 (2.7614)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [33]  [360/390]  eta: 0:00:08  lr: 0.000097  loss: 2.9987 (2.7623)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [33]  [370/390]  eta: 0:00:05  lr: 0.000097  loss: 2.6960 (2.7569)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [33]  [380/390]  eta: 0:00:02  lr: 0.000097  loss: 2.3781 (2.7493)  time: 0.2717  data: 0.0002  max mem: 14473
Epoch: [33]  [389/390]  eta: 0:00:00  lr: 0.000097  loss: 2.6480 (2.7477)  time: 0.2715  data: 0.0001  max mem: 14473
Epoch: [33] Total time: 0:01:48 (0.2777 s / it)
Averaged stats: lr: 0.000097  loss: 2.6480 (2.7477)
Test:  [ 0/53]  eta: 0:01:26  loss: 0.3055 (0.3055)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.6387  data: 1.5004  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2775 (0.2676)  acc1: 96.8750 (97.0644)  acc5: 100.0000 (99.9053)  acc1_10: 97.3958 (96.9697)  acc5_10: 100.0000 (99.9053)  time: 0.2627  data: 0.1366  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2773 (0.2760)  acc1: 96.3542 (96.8254)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.6022)  acc5_10: 100.0000 (99.7272)  time: 0.1232  data: 0.0002  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2796 (0.2808)  acc1: 96.3542 (96.5726)  acc5: 100.0000 (99.7648)  acc1_10: 95.8333 (96.3710)  acc5_10: 100.0000 (99.7312)  time: 0.1212  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2862 (0.2822)  acc1: 96.3542 (96.6082)  acc5: 100.0000 (99.7459)  acc1_10: 95.8333 (96.4431)  acc5_10: 100.0000 (99.7332)  time: 0.1200  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2862 (0.2817)  acc1: 96.3542 (96.5993)  acc5: 100.0000 (99.7651)  acc1_10: 96.8750 (96.4869)  acc5_10: 100.0000 (99.7651)  time: 0.1186  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2820 (0.2809)  acc1: 96.3542 (96.5900)  acc5: 100.0000 (99.7700)  acc1_10: 96.8750 (96.4900)  acc5_10: 100.0000 (99.7700)  time: 0.1142  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1501 s / it)
* Acc@1 96.590 Acc@5 99.770 loss 0.281
classifiers_10 : Acc@1 96.490 Acc@5 99.770
Accuracy of the network on the 10000 test images: 96.6%
## Using lr  0.0000952 for BACKBONE, cosine lr = 0.0018548 for PRUNER
Epoch: [34]  [  0/390]  eta: 0:09:56  lr: 0.000095  loss: 2.6536 (2.6536)  time: 1.5291  data: 1.2112  max mem: 14473
Epoch: [34]  [ 10/390]  eta: 0:02:28  lr: 0.000095  loss: 2.6355 (2.5602)  time: 0.3915  data: 0.1103  max mem: 14473
Epoch: [34]  [ 20/390]  eta: 0:02:03  lr: 0.000095  loss: 2.6355 (2.6249)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [34]  [ 30/390]  eta: 0:01:53  lr: 0.000095  loss: 2.8647 (2.6954)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [34]  [ 40/390]  eta: 0:01:46  lr: 0.000095  loss: 2.9831 (2.7128)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [34]  [ 50/390]  eta: 0:01:41  lr: 0.000095  loss: 2.5168 (2.6192)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [34]  [ 60/390]  eta: 0:01:37  lr: 0.000095  loss: 2.3225 (2.6203)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [34]  [ 70/390]  eta: 0:01:33  lr: 0.000095  loss: 2.7326 (2.6469)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [34]  [ 80/390]  eta: 0:01:29  lr: 0.000095  loss: 2.7426 (2.6516)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [34]  [ 90/390]  eta: 0:01:26  lr: 0.000095  loss: 2.9193 (2.6700)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [34]  [100/390]  eta: 0:01:23  lr: 0.000095  loss: 2.9193 (2.6831)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [34]  [110/390]  eta: 0:01:19  lr: 0.000095  loss: 2.8975 (2.7004)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [34]  [120/390]  eta: 0:01:17  lr: 0.000095  loss: 3.0285 (2.7269)  time: 0.2829  data: 0.0002  max mem: 14473
Epoch: [34]  [130/390]  eta: 0:01:14  lr: 0.000095  loss: 2.8289 (2.7212)  time: 0.2830  data: 0.0003  max mem: 14473
Epoch: [34]  [140/390]  eta: 0:01:11  lr: 0.000095  loss: 2.3012 (2.6936)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [34]  [150/390]  eta: 0:01:08  lr: 0.000095  loss: 2.1238 (2.6634)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [34]  [160/390]  eta: 0:01:05  lr: 0.000095  loss: 2.4989 (2.6662)  time: 0.2744  data: 0.0002  max mem: 14473
Epoch: [34]  [170/390]  eta: 0:01:02  lr: 0.000095  loss: 2.7977 (2.6782)  time: 0.2746  data: 0.0002  max mem: 14473
Epoch: [34]  [180/390]  eta: 0:00:59  lr: 0.000095  loss: 3.0599 (2.6938)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [34]  [190/390]  eta: 0:00:56  lr: 0.000095  loss: 3.0183 (2.6974)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [34]  [200/390]  eta: 0:00:53  lr: 0.000095  loss: 2.6476 (2.6936)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [34]  [210/390]  eta: 0:00:50  lr: 0.000095  loss: 2.8649 (2.7053)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [34]  [220/390]  eta: 0:00:47  lr: 0.000095  loss: 2.9388 (2.7034)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [34]  [230/390]  eta: 0:00:44  lr: 0.000095  loss: 2.7859 (2.7046)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [34]  [240/390]  eta: 0:00:42  lr: 0.000095  loss: 2.8806 (2.7048)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [34]  [250/390]  eta: 0:00:39  lr: 0.000095  loss: 2.8392 (2.7083)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [34]  [260/390]  eta: 0:00:36  lr: 0.000095  loss: 2.6694 (2.6946)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [34]  [270/390]  eta: 0:00:33  lr: 0.000095  loss: 2.4891 (2.6884)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [34]  [280/390]  eta: 0:00:30  lr: 0.000095  loss: 2.6941 (2.6888)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [34]  [290/390]  eta: 0:00:27  lr: 0.000095  loss: 2.8808 (2.6903)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [34]  [300/390]  eta: 0:00:25  lr: 0.000095  loss: 2.8262 (2.6932)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [34]  [310/390]  eta: 0:00:22  lr: 0.000095  loss: 2.6401 (2.6881)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [34]  [320/390]  eta: 0:00:19  lr: 0.000095  loss: 2.5505 (2.6891)  time: 0.2769  data: 0.0003  max mem: 14473
Epoch: [34]  [330/390]  eta: 0:00:16  lr: 0.000095  loss: 2.7561 (2.6902)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [34]  [340/390]  eta: 0:00:13  lr: 0.000095  loss: 2.4152 (2.6814)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [34]  [350/390]  eta: 0:00:11  lr: 0.000095  loss: 2.3533 (2.6836)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [34]  [360/390]  eta: 0:00:08  lr: 0.000095  loss: 2.9168 (2.6846)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [34]  [370/390]  eta: 0:00:05  lr: 0.000095  loss: 2.8796 (2.6906)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [34]  [380/390]  eta: 0:00:02  lr: 0.000095  loss: 2.6839 (2.6809)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [34]  [389/390]  eta: 0:00:00  lr: 0.000095  loss: 2.2116 (2.6728)  time: 0.2717  data: 0.0001  max mem: 14473
Epoch: [34] Total time: 0:01:48 (0.2784 s / it)
Averaged stats: lr: 0.000095  loss: 2.2116 (2.6728)
Test:  [ 0/53]  eta: 0:00:58  loss: 0.2553 (0.2553)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.0961  data: 0.9389  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2425 (0.2410)  acc1: 96.8750 (96.8277)  acc5: 100.0000 (99.8580)  acc1_10: 96.8750 (96.5436)  acc5_10: 100.0000 (99.9053)  time: 0.2402  data: 0.1034  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2440 (0.2512)  acc1: 96.8750 (96.4782)  acc5: 100.0000 (99.7024)  acc1_10: 96.3542 (96.4038)  acc5_10: 100.0000 (99.7768)  time: 0.1387  data: 0.0100  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2537 (0.2520)  acc1: 96.3542 (96.3206)  acc5: 100.0000 (99.7648)  acc1_10: 95.8333 (96.2870)  acc5_10: 100.0000 (99.8152)  time: 0.1222  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:01  loss: 0.2537 (0.2534)  acc1: 95.8333 (96.2907)  acc5: 100.0000 (99.7205)  acc1_10: 95.8333 (96.2525)  acc5_10: 100.0000 (99.7967)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2504 (0.2520)  acc1: 96.3542 (96.3031)  acc5: 100.0000 (99.7549)  acc1_10: 96.3542 (96.2214)  acc5_10: 100.0000 (99.8162)  time: 0.1188  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2504 (0.2497)  acc1: 96.8750 (96.3300)  acc5: 100.0000 (99.7600)  acc1_10: 96.3542 (96.2300)  acc5_10: 100.0000 (99.8100)  time: 0.1142  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1459 s / it)
* Acc@1 96.330 Acc@5 99.760 loss 0.250
classifiers_10 : Acc@1 96.230 Acc@5 99.810
Accuracy of the network on the 10000 test images: 96.3%
## Using lr  0.0000936 for BACKBONE, cosine lr = 0.0018202 for PRUNER
Epoch: [35]  [  0/390]  eta: 0:11:27  lr: 0.000094  loss: 2.7605 (2.7605)  time: 1.7620  data: 1.4451  max mem: 14473
Epoch: [35]  [ 10/390]  eta: 0:02:35  lr: 0.000094  loss: 2.7605 (2.4886)  time: 0.4104  data: 0.1316  max mem: 14473
Epoch: [35]  [ 20/390]  eta: 0:02:07  lr: 0.000094  loss: 2.7694 (2.6349)  time: 0.2744  data: 0.0002  max mem: 14473
Epoch: [35]  [ 30/390]  eta: 0:01:56  lr: 0.000094  loss: 3.0005 (2.7184)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [35]  [ 40/390]  eta: 0:01:48  lr: 0.000094  loss: 3.0005 (2.6948)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [35]  [ 50/390]  eta: 0:01:43  lr: 0.000094  loss: 2.5969 (2.6985)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [35]  [ 60/390]  eta: 0:01:38  lr: 0.000094  loss: 2.9414 (2.7104)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [35]  [ 70/390]  eta: 0:01:34  lr: 0.000094  loss: 2.8289 (2.7146)  time: 0.2723  data: 0.0002  max mem: 14473
Epoch: [35]  [ 80/390]  eta: 0:01:30  lr: 0.000094  loss: 2.7242 (2.7159)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [35]  [ 90/390]  eta: 0:01:26  lr: 0.000094  loss: 2.6168 (2.7120)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [35]  [100/390]  eta: 0:01:23  lr: 0.000094  loss: 2.7529 (2.7327)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [35]  [110/390]  eta: 0:01:20  lr: 0.000094  loss: 2.8757 (2.7323)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [35]  [120/390]  eta: 0:01:17  lr: 0.000094  loss: 2.6243 (2.7365)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [35]  [130/390]  eta: 0:01:14  lr: 0.000094  loss: 2.9214 (2.7560)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [35]  [140/390]  eta: 0:01:11  lr: 0.000094  loss: 2.9214 (2.7467)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [35]  [150/390]  eta: 0:01:08  lr: 0.000094  loss: 2.7818 (2.7419)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [35]  [160/390]  eta: 0:01:05  lr: 0.000094  loss: 2.5353 (2.7279)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [35]  [170/390]  eta: 0:01:02  lr: 0.000094  loss: 2.5353 (2.7153)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [35]  [180/390]  eta: 0:00:59  lr: 0.000094  loss: 2.6825 (2.7166)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [35]  [190/390]  eta: 0:00:56  lr: 0.000094  loss: 2.8314 (2.7231)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [35]  [200/390]  eta: 0:00:53  lr: 0.000094  loss: 2.9608 (2.7228)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [35]  [210/390]  eta: 0:00:50  lr: 0.000094  loss: 2.9102 (2.7289)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [35]  [220/390]  eta: 0:00:47  lr: 0.000094  loss: 2.8816 (2.7324)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [35]  [230/390]  eta: 0:00:44  lr: 0.000094  loss: 2.7314 (2.7218)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [35]  [240/390]  eta: 0:00:41  lr: 0.000094  loss: 2.7800 (2.7252)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [35]  [250/390]  eta: 0:00:39  lr: 0.000094  loss: 2.9956 (2.7284)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [35]  [260/390]  eta: 0:00:36  lr: 0.000094  loss: 2.8936 (2.7276)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [35]  [270/390]  eta: 0:00:33  lr: 0.000094  loss: 2.7744 (2.7214)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [35]  [280/390]  eta: 0:00:30  lr: 0.000094  loss: 2.7348 (2.7199)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [35]  [290/390]  eta: 0:00:27  lr: 0.000094  loss: 2.8407 (2.7219)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [35]  [300/390]  eta: 0:00:25  lr: 0.000094  loss: 2.7692 (2.7143)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [35]  [310/390]  eta: 0:00:22  lr: 0.000094  loss: 2.7692 (2.7153)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [35]  [320/390]  eta: 0:00:19  lr: 0.000094  loss: 2.8159 (2.7162)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [35]  [330/390]  eta: 0:00:16  lr: 0.000094  loss: 2.8200 (2.7135)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [35]  [340/390]  eta: 0:00:13  lr: 0.000094  loss: 2.9677 (2.7214)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [35]  [350/390]  eta: 0:00:11  lr: 0.000094  loss: 3.0331 (2.7288)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [35]  [360/390]  eta: 0:00:08  lr: 0.000094  loss: 3.0327 (2.7342)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [35]  [370/390]  eta: 0:00:05  lr: 0.000094  loss: 2.8148 (2.7322)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [35]  [380/390]  eta: 0:00:02  lr: 0.000094  loss: 2.7578 (2.7350)  time: 0.2719  data: 0.0002  max mem: 14473
Epoch: [35]  [389/390]  eta: 0:00:00  lr: 0.000094  loss: 2.7578 (2.7351)  time: 0.2716  data: 0.0001  max mem: 14473
Epoch: [35] Total time: 0:01:48 (0.2777 s / it)
Averaged stats: lr: 0.000094  loss: 2.7578 (2.7351)
Test:  [ 0/53]  eta: 0:01:24  loss: 0.2753 (0.2753)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.5886  data: 1.4192  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2696 (0.2781)  acc1: 97.3958 (97.2064)  acc5: 100.0000 (99.8106)  acc1_10: 96.3542 (96.5909)  acc5_10: 100.0000 (99.8106)  time: 0.2623  data: 0.1293  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2922 (0.2895)  acc1: 96.3542 (96.6766)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.1558)  acc5_10: 100.0000 (99.7768)  time: 0.1257  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2922 (0.2910)  acc1: 96.3542 (96.6062)  acc5: 100.0000 (99.7648)  acc1_10: 95.8333 (96.3374)  acc5_10: 100.0000 (99.8320)  time: 0.1216  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2979 (0.2931)  acc1: 96.8750 (96.6336)  acc5: 100.0000 (99.7332)  acc1_10: 96.3542 (96.2398)  acc5_10: 100.0000 (99.7967)  time: 0.1205  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2979 (0.2925)  acc1: 96.8750 (96.6401)  acc5: 100.0000 (99.7549)  acc1_10: 95.3125 (96.2316)  acc5_10: 100.0000 (99.8162)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2916 (0.2943)  acc1: 96.8750 (96.6400)  acc5: 100.0000 (99.7600)  acc1_10: 95.3125 (96.2200)  acc5_10: 100.0000 (99.8200)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1504 s / it)
* Acc@1 96.640 Acc@5 99.760 loss 0.294
classifiers_10 : Acc@1 96.220 Acc@5 99.820
Accuracy of the network on the 10000 test images: 96.6%
## Using lr  0.0000920 for BACKBONE, cosine lr = 0.0017851 for PRUNER
Epoch: [36]  [  0/390]  eta: 0:11:01  lr: 0.000092  loss: 1.7159 (1.7159)  time: 1.6953  data: 1.3885  max mem: 14473
Epoch: [36]  [ 10/390]  eta: 0:02:33  lr: 0.000092  loss: 2.6133 (2.6410)  time: 0.4041  data: 0.1265  max mem: 14473
Epoch: [36]  [ 20/390]  eta: 0:02:06  lr: 0.000092  loss: 2.5561 (2.5965)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [36]  [ 30/390]  eta: 0:01:55  lr: 0.000092  loss: 2.7835 (2.7311)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [36]  [ 40/390]  eta: 0:01:48  lr: 0.000092  loss: 2.9455 (2.7622)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [36]  [ 50/390]  eta: 0:01:42  lr: 0.000092  loss: 2.8741 (2.8042)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [36]  [ 60/390]  eta: 0:01:38  lr: 0.000092  loss: 2.8227 (2.7813)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [36]  [ 70/390]  eta: 0:01:34  lr: 0.000092  loss: 2.5685 (2.7578)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [36]  [ 80/390]  eta: 0:01:30  lr: 0.000092  loss: 2.6085 (2.7405)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [36]  [ 90/390]  eta: 0:01:27  lr: 0.000092  loss: 2.8248 (2.7491)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [36]  [100/390]  eta: 0:01:23  lr: 0.000092  loss: 2.8779 (2.7511)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [36]  [110/390]  eta: 0:01:20  lr: 0.000092  loss: 2.9443 (2.7637)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [36]  [120/390]  eta: 0:01:17  lr: 0.000092  loss: 2.9361 (2.7578)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [36]  [130/390]  eta: 0:01:14  lr: 0.000092  loss: 2.8315 (2.7432)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [36]  [140/390]  eta: 0:01:11  lr: 0.000092  loss: 2.5236 (2.7405)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [36]  [150/390]  eta: 0:01:08  lr: 0.000092  loss: 2.9681 (2.7568)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [36]  [160/390]  eta: 0:01:05  lr: 0.000092  loss: 2.9681 (2.7690)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [36]  [170/390]  eta: 0:01:02  lr: 0.000092  loss: 2.6345 (2.7388)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [36]  [180/390]  eta: 0:00:59  lr: 0.000092  loss: 2.1185 (2.7308)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [36]  [190/390]  eta: 0:00:56  lr: 0.000092  loss: 2.6937 (2.7205)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [36]  [200/390]  eta: 0:00:53  lr: 0.000092  loss: 2.8604 (2.7222)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [36]  [210/390]  eta: 0:00:50  lr: 0.000092  loss: 2.9243 (2.7298)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [36]  [220/390]  eta: 0:00:47  lr: 0.000092  loss: 2.7504 (2.7293)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [36]  [230/390]  eta: 0:00:44  lr: 0.000092  loss: 2.7286 (2.7252)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [36]  [240/390]  eta: 0:00:41  lr: 0.000092  loss: 2.3769 (2.7173)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [36]  [250/390]  eta: 0:00:39  lr: 0.000092  loss: 2.7256 (2.7240)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [36]  [260/390]  eta: 0:00:36  lr: 0.000092  loss: 2.7643 (2.7243)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [36]  [270/390]  eta: 0:00:33  lr: 0.000092  loss: 2.5561 (2.7136)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [36]  [280/390]  eta: 0:00:30  lr: 0.000092  loss: 2.6539 (2.7210)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [36]  [290/390]  eta: 0:00:27  lr: 0.000092  loss: 2.8531 (2.7229)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [36]  [300/390]  eta: 0:00:25  lr: 0.000092  loss: 2.7762 (2.7225)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [36]  [310/390]  eta: 0:00:22  lr: 0.000092  loss: 2.7725 (2.7260)  time: 0.2770  data: 0.0002  max mem: 14473
Epoch: [36]  [320/390]  eta: 0:00:19  lr: 0.000092  loss: 2.8011 (2.7229)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [36]  [330/390]  eta: 0:00:16  lr: 0.000092  loss: 2.9757 (2.7302)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [36]  [340/390]  eta: 0:00:13  lr: 0.000092  loss: 2.9410 (2.7319)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [36]  [350/390]  eta: 0:00:11  lr: 0.000092  loss: 2.6644 (2.7305)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [36]  [360/390]  eta: 0:00:08  lr: 0.000092  loss: 2.7622 (2.7365)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [36]  [370/390]  eta: 0:00:05  lr: 0.000092  loss: 3.0405 (2.7398)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [36]  [380/390]  eta: 0:00:02  lr: 0.000092  loss: 2.9350 (2.7372)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [36]  [389/390]  eta: 0:00:00  lr: 0.000092  loss: 2.8922 (2.7412)  time: 0.2728  data: 0.0001  max mem: 14473
Epoch: [36] Total time: 0:01:48 (0.2782 s / it)
Averaged stats: lr: 0.000092  loss: 2.8922 (2.7412)
Test:  [ 0/53]  eta: 0:01:14  loss: 0.2798 (0.2798)  acc1: 96.3542 (96.3542)  acc5: 99.4792 (99.4792)  acc1_10: 96.3542 (96.3542)  acc5_10: 99.4792 (99.4792)  time: 1.4058  data: 1.2486  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2657 (0.2729)  acc1: 96.8750 (96.6856)  acc5: 100.0000 (99.8106)  acc1_10: 96.8750 (96.6383)  acc5_10: 100.0000 (99.8580)  time: 0.2521  data: 0.1139  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2808 (0.2827)  acc1: 96.8750 (96.4286)  acc5: 100.0000 (99.7272)  acc1_10: 96.3542 (96.3790)  acc5_10: 100.0000 (99.7768)  time: 0.1292  data: 0.0004  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2924 (0.2853)  acc1: 95.8333 (96.4214)  acc5: 100.0000 (99.7648)  acc1_10: 96.3542 (96.3038)  acc5_10: 100.0000 (99.7984)  time: 0.1223  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2930 (0.2871)  acc1: 96.3542 (96.4431)  acc5: 100.0000 (99.7459)  acc1_10: 96.3542 (96.3669)  acc5_10: 100.0000 (99.7840)  time: 0.1216  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2920 (0.2843)  acc1: 96.8750 (96.5482)  acc5: 100.0000 (99.7855)  acc1_10: 96.8750 (96.4665)  acc5_10: 100.0000 (99.8060)  time: 0.1194  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2767 (0.2831)  acc1: 96.3542 (96.5500)  acc5: 100.0000 (99.7900)  acc1_10: 96.3542 (96.4600)  acc5_10: 100.0000 (99.8000)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1486 s / it)
* Acc@1 96.550 Acc@5 99.790 loss 0.283
classifiers_10 : Acc@1 96.460 Acc@5 99.800
Accuracy of the network on the 10000 test images: 96.6%
## Using lr  0.0000903 for BACKBONE, cosine lr = 0.0017494 for PRUNER
Epoch: [37]  [  0/390]  eta: 0:10:57  lr: 0.000090  loss: 3.2879 (3.2879)  time: 1.6871  data: 1.3606  max mem: 14473
Epoch: [37]  [ 10/390]  eta: 0:02:34  lr: 0.000090  loss: 2.7550 (2.7069)  time: 0.4064  data: 0.1240  max mem: 14473
Epoch: [37]  [ 20/390]  eta: 0:02:07  lr: 0.000090  loss: 2.7550 (2.7014)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [37]  [ 30/390]  eta: 0:01:55  lr: 0.000090  loss: 2.9608 (2.7484)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [37]  [ 40/390]  eta: 0:01:48  lr: 0.000090  loss: 3.0774 (2.8361)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [37]  [ 50/390]  eta: 0:01:42  lr: 0.000090  loss: 3.0162 (2.8072)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [37]  [ 60/390]  eta: 0:01:38  lr: 0.000090  loss: 2.8538 (2.8310)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [37]  [ 70/390]  eta: 0:01:34  lr: 0.000090  loss: 2.9351 (2.8207)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [37]  [ 80/390]  eta: 0:01:30  lr: 0.000090  loss: 2.7182 (2.8005)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [37]  [ 90/390]  eta: 0:01:27  lr: 0.000090  loss: 2.8140 (2.8187)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [37]  [100/390]  eta: 0:01:23  lr: 0.000090  loss: 3.0431 (2.8075)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [37]  [110/390]  eta: 0:01:20  lr: 0.000090  loss: 2.8440 (2.8025)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [37]  [120/390]  eta: 0:01:17  lr: 0.000090  loss: 2.6536 (2.7840)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [37]  [130/390]  eta: 0:01:14  lr: 0.000090  loss: 2.6536 (2.7872)  time: 0.2765  data: 0.0002  max mem: 14473
Epoch: [37]  [140/390]  eta: 0:01:11  lr: 0.000090  loss: 2.6920 (2.7709)  time: 0.2765  data: 0.0002  max mem: 14473
Epoch: [37]  [150/390]  eta: 0:01:08  lr: 0.000090  loss: 2.7195 (2.7623)  time: 0.2757  data: 0.0002  max mem: 14473
Epoch: [37]  [160/390]  eta: 0:01:05  lr: 0.000090  loss: 2.7195 (2.7580)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [37]  [170/390]  eta: 0:01:02  lr: 0.000090  loss: 2.8776 (2.7623)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [37]  [180/390]  eta: 0:00:59  lr: 0.000090  loss: 3.0408 (2.7792)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [37]  [190/390]  eta: 0:00:56  lr: 0.000090  loss: 3.0771 (2.7876)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [37]  [200/390]  eta: 0:00:53  lr: 0.000090  loss: 2.8441 (2.7824)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [37]  [210/390]  eta: 0:00:50  lr: 0.000090  loss: 2.6030 (2.7642)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [37]  [220/390]  eta: 0:00:47  lr: 0.000090  loss: 2.6030 (2.7627)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [37]  [230/390]  eta: 0:00:44  lr: 0.000090  loss: 2.9184 (2.7689)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [37]  [240/390]  eta: 0:00:42  lr: 0.000090  loss: 2.8532 (2.7587)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [37]  [250/390]  eta: 0:00:39  lr: 0.000090  loss: 2.4178 (2.7501)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [37]  [260/390]  eta: 0:00:36  lr: 0.000090  loss: 2.7842 (2.7486)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [37]  [270/390]  eta: 0:00:33  lr: 0.000090  loss: 2.5873 (2.7257)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [37]  [280/390]  eta: 0:00:30  lr: 0.000090  loss: 2.2742 (2.7266)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [37]  [290/390]  eta: 0:00:27  lr: 0.000090  loss: 2.8261 (2.7224)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [37]  [300/390]  eta: 0:00:25  lr: 0.000090  loss: 2.7849 (2.7220)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [37]  [310/390]  eta: 0:00:22  lr: 0.000090  loss: 2.9714 (2.7250)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [37]  [320/390]  eta: 0:00:19  lr: 0.000090  loss: 2.8692 (2.7251)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [37]  [330/390]  eta: 0:00:16  lr: 0.000090  loss: 2.7470 (2.7205)  time: 0.2735  data: 0.0002  max mem: 14473
Epoch: [37]  [340/390]  eta: 0:00:13  lr: 0.000090  loss: 2.3443 (2.7166)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [37]  [350/390]  eta: 0:00:11  lr: 0.000090  loss: 2.3605 (2.7102)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [37]  [360/390]  eta: 0:00:08  lr: 0.000090  loss: 2.7059 (2.7165)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [37]  [370/390]  eta: 0:00:05  lr: 0.000090  loss: 2.9106 (2.7206)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [37]  [380/390]  eta: 0:00:02  lr: 0.000090  loss: 2.8647 (2.7201)  time: 0.2721  data: 0.0002  max mem: 14473
Epoch: [37]  [389/390]  eta: 0:00:00  lr: 0.000090  loss: 2.7316 (2.7175)  time: 0.2717  data: 0.0001  max mem: 14473
Epoch: [37] Total time: 0:01:48 (0.2781 s / it)
Averaged stats: lr: 0.000090  loss: 2.7316 (2.7175)
Test:  [ 0/53]  eta: 0:01:17  loss: 0.2656 (0.2656)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.4690  data: 1.3170  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2583 (0.2510)  acc1: 96.8750 (96.7803)  acc5: 100.0000 (99.9053)  acc1_10: 96.3542 (96.3068)  acc5_10: 100.0000 (99.8580)  time: 0.2554  data: 0.1201  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2583 (0.2591)  acc1: 96.8750 (96.5774)  acc5: 100.0000 (99.7768)  acc1_10: 96.3542 (96.3046)  acc5_10: 100.0000 (99.7272)  time: 0.1287  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2586 (0.2611)  acc1: 96.3542 (96.5054)  acc5: 100.0000 (99.7984)  acc1_10: 96.3542 (96.3206)  acc5_10: 99.4792 (99.7312)  time: 0.1229  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2580 (0.2604)  acc1: 96.3542 (96.5574)  acc5: 100.0000 (99.7586)  acc1_10: 96.8750 (96.4558)  acc5_10: 99.4792 (99.7205)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2525 (0.2611)  acc1: 96.3542 (96.5278)  acc5: 99.4792 (99.7549)  acc1_10: 96.8750 (96.4052)  acc5_10: 100.0000 (99.7447)  time: 0.1189  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2525 (0.2638)  acc1: 96.3542 (96.5400)  acc5: 100.0000 (99.7600)  acc1_10: 96.3542 (96.4100)  acc5_10: 100.0000 (99.7500)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1494 s / it)
* Acc@1 96.540 Acc@5 99.760 loss 0.264
classifiers_10 : Acc@1 96.410 Acc@5 99.750
Accuracy of the network on the 10000 test images: 96.5%
## Using lr  0.0000887 for BACKBONE, cosine lr = 0.0017133 for PRUNER
Epoch: [38]  [  0/390]  eta: 0:10:21  lr: 0.000089  loss: 2.0114 (2.0114)  time: 1.5930  data: 1.2700  max mem: 14473
Epoch: [38]  [ 10/390]  eta: 0:02:31  lr: 0.000089  loss: 2.4237 (2.4795)  time: 0.3978  data: 0.1157  max mem: 14473
Epoch: [38]  [ 20/390]  eta: 0:02:05  lr: 0.000089  loss: 2.6887 (2.6025)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [38]  [ 30/390]  eta: 0:01:54  lr: 0.000089  loss: 2.7357 (2.6846)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [38]  [ 40/390]  eta: 0:01:47  lr: 0.000089  loss: 2.6666 (2.6608)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [38]  [ 50/390]  eta: 0:01:42  lr: 0.000089  loss: 2.8177 (2.6700)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [38]  [ 60/390]  eta: 0:01:38  lr: 0.000089  loss: 2.8660 (2.6782)  time: 0.2815  data: 0.0003  max mem: 14473
Epoch: [38]  [ 70/390]  eta: 0:01:34  lr: 0.000089  loss: 2.8678 (2.6878)  time: 0.2809  data: 0.0003  max mem: 14473
Epoch: [38]  [ 80/390]  eta: 0:01:30  lr: 0.000089  loss: 2.9840 (2.6931)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [38]  [ 90/390]  eta: 0:01:27  lr: 0.000089  loss: 2.8794 (2.6978)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [38]  [100/390]  eta: 0:01:23  lr: 0.000089  loss: 2.8794 (2.7108)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [38]  [110/390]  eta: 0:01:20  lr: 0.000089  loss: 2.7862 (2.6882)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [38]  [120/390]  eta: 0:01:17  lr: 0.000089  loss: 2.8067 (2.7017)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [38]  [130/390]  eta: 0:01:14  lr: 0.000089  loss: 2.8421 (2.6973)  time: 0.2719  data: 0.0002  max mem: 14473
Epoch: [38]  [140/390]  eta: 0:01:11  lr: 0.000089  loss: 2.7042 (2.7015)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [38]  [150/390]  eta: 0:01:08  lr: 0.000089  loss: 2.7042 (2.6943)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [38]  [160/390]  eta: 0:01:05  lr: 0.000089  loss: 2.5424 (2.6895)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [38]  [170/390]  eta: 0:01:02  lr: 0.000089  loss: 2.8458 (2.6901)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [38]  [180/390]  eta: 0:00:59  lr: 0.000089  loss: 2.9394 (2.7015)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [38]  [190/390]  eta: 0:00:56  lr: 0.000089  loss: 2.9144 (2.7020)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [38]  [200/390]  eta: 0:00:53  lr: 0.000089  loss: 2.7471 (2.7015)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [38]  [210/390]  eta: 0:00:50  lr: 0.000089  loss: 2.7471 (2.6967)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [38]  [220/390]  eta: 0:00:47  lr: 0.000089  loss: 2.7810 (2.6987)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [38]  [230/390]  eta: 0:00:44  lr: 0.000089  loss: 2.9228 (2.6951)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [38]  [240/390]  eta: 0:00:41  lr: 0.000089  loss: 2.5326 (2.6916)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [38]  [250/390]  eta: 0:00:39  lr: 0.000089  loss: 2.5326 (2.6817)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [38]  [260/390]  eta: 0:00:36  lr: 0.000089  loss: 2.8977 (2.6879)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [38]  [270/390]  eta: 0:00:33  lr: 0.000089  loss: 2.9514 (2.6908)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [38]  [280/390]  eta: 0:00:30  lr: 0.000089  loss: 2.7347 (2.6921)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [38]  [290/390]  eta: 0:00:27  lr: 0.000089  loss: 2.9959 (2.6945)  time: 0.2760  data: 0.0002  max mem: 14473
Epoch: [38]  [300/390]  eta: 0:00:25  lr: 0.000089  loss: 2.9003 (2.6947)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [38]  [310/390]  eta: 0:00:22  lr: 0.000089  loss: 2.6985 (2.6977)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [38]  [320/390]  eta: 0:00:19  lr: 0.000089  loss: 2.8577 (2.6965)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [38]  [330/390]  eta: 0:00:16  lr: 0.000089  loss: 3.0018 (2.7052)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [38]  [340/390]  eta: 0:00:13  lr: 0.000089  loss: 2.9403 (2.7034)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [38]  [350/390]  eta: 0:00:11  lr: 0.000089  loss: 2.6692 (2.7022)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [38]  [360/390]  eta: 0:00:08  lr: 0.000089  loss: 2.7567 (2.7073)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [38]  [370/390]  eta: 0:00:05  lr: 0.000089  loss: 2.8995 (2.7085)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [38]  [380/390]  eta: 0:00:02  lr: 0.000089  loss: 2.6909 (2.7036)  time: 0.2712  data: 0.0002  max mem: 14473
Epoch: [38]  [389/390]  eta: 0:00:00  lr: 0.000089  loss: 2.5744 (2.7030)  time: 0.2705  data: 0.0001  max mem: 14473
Epoch: [38] Total time: 0:01:48 (0.2775 s / it)
Averaged stats: lr: 0.000089  loss: 2.5744 (2.7030)
Test:  [ 0/53]  eta: 0:01:16  loss: 0.2242 (0.2242)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  acc1_10: 96.8750 (96.8750)  acc5_10: 100.0000 (100.0000)  time: 1.4451  data: 1.2874  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2242 (0.2365)  acc1: 97.3958 (96.8277)  acc5: 100.0000 (99.8580)  acc1_10: 96.8750 (96.5909)  acc5_10: 100.0000 (99.9527)  time: 0.2659  data: 0.1343  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2534 (0.2485)  acc1: 95.8333 (96.5526)  acc5: 100.0000 (99.7272)  acc1_10: 96.3542 (96.2798)  acc5_10: 100.0000 (99.8264)  time: 0.1353  data: 0.0096  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2563 (0.2491)  acc1: 95.8333 (96.4886)  acc5: 100.0000 (99.7480)  acc1_10: 95.8333 (96.2030)  acc5_10: 100.0000 (99.8320)  time: 0.1225  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2517 (0.2486)  acc1: 96.3542 (96.5320)  acc5: 100.0000 (99.7205)  acc1_10: 96.8750 (96.3542)  acc5_10: 100.0000 (99.7967)  time: 0.1207  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2476 (0.2470)  acc1: 96.8750 (96.6401)  acc5: 100.0000 (99.7549)  acc1_10: 96.8750 (96.4563)  acc5_10: 100.0000 (99.8162)  time: 0.1195  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2395 (0.2468)  acc1: 96.8750 (96.6600)  acc5: 100.0000 (99.7600)  acc1_10: 96.8750 (96.4700)  acc5_10: 100.0000 (99.8200)  time: 0.1150  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1516 s / it)
* Acc@1 96.660 Acc@5 99.760 loss 0.247
classifiers_10 : Acc@1 96.470 Acc@5 99.820
Accuracy of the network on the 10000 test images: 96.7%
## Using lr  0.0000870 for BACKBONE, cosine lr = 0.0016767 for PRUNER
Epoch: [39]  [  0/390]  eta: 0:11:16  lr: 0.000087  loss: 2.9311 (2.9311)  time: 1.7356  data: 1.4500  max mem: 14473
Epoch: [39]  [ 10/390]  eta: 0:02:34  lr: 0.000087  loss: 2.7573 (2.6855)  time: 0.4075  data: 0.1321  max mem: 14473
Epoch: [39]  [ 20/390]  eta: 0:02:07  lr: 0.000087  loss: 2.5519 (2.6430)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [39]  [ 30/390]  eta: 0:01:55  lr: 0.000087  loss: 2.7242 (2.6689)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [39]  [ 40/390]  eta: 0:01:48  lr: 0.000087  loss: 2.8957 (2.7309)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [39]  [ 50/390]  eta: 0:01:42  lr: 0.000087  loss: 2.8957 (2.7070)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [39]  [ 60/390]  eta: 0:01:38  lr: 0.000087  loss: 2.8414 (2.7211)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [39]  [ 70/390]  eta: 0:01:34  lr: 0.000087  loss: 2.9862 (2.7495)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [39]  [ 80/390]  eta: 0:01:30  lr: 0.000087  loss: 2.9862 (2.7512)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [39]  [ 90/390]  eta: 0:01:26  lr: 0.000087  loss: 2.8342 (2.7578)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [39]  [100/390]  eta: 0:01:23  lr: 0.000087  loss: 2.7617 (2.7402)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [39]  [110/390]  eta: 0:01:20  lr: 0.000087  loss: 2.7905 (2.7347)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [39]  [120/390]  eta: 0:01:17  lr: 0.000087  loss: 2.5280 (2.7008)  time: 0.2729  data: 0.0002  max mem: 14473
Epoch: [39]  [130/390]  eta: 0:01:14  lr: 0.000087  loss: 2.4829 (2.7011)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [39]  [140/390]  eta: 0:01:11  lr: 0.000087  loss: 2.5888 (2.6953)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [39]  [150/390]  eta: 0:01:08  lr: 0.000087  loss: 2.8681 (2.7073)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [39]  [160/390]  eta: 0:01:05  lr: 0.000087  loss: 2.8662 (2.7124)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [39]  [170/390]  eta: 0:01:02  lr: 0.000087  loss: 2.8626 (2.7159)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [39]  [180/390]  eta: 0:00:59  lr: 0.000087  loss: 2.8328 (2.7026)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [39]  [190/390]  eta: 0:00:56  lr: 0.000087  loss: 2.4036 (2.6907)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [39]  [200/390]  eta: 0:00:53  lr: 0.000087  loss: 2.5936 (2.6873)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [39]  [210/390]  eta: 0:00:50  lr: 0.000087  loss: 2.8365 (2.6976)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [39]  [220/390]  eta: 0:00:47  lr: 0.000087  loss: 2.7655 (2.6835)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [39]  [230/390]  eta: 0:00:44  lr: 0.000087  loss: 2.4524 (2.6878)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [39]  [240/390]  eta: 0:00:42  lr: 0.000087  loss: 2.8099 (2.6887)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [39]  [250/390]  eta: 0:00:39  lr: 0.000087  loss: 2.7872 (2.6818)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [39]  [260/390]  eta: 0:00:36  lr: 0.000087  loss: 2.4270 (2.6693)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [39]  [270/390]  eta: 0:00:33  lr: 0.000087  loss: 2.4986 (2.6667)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [39]  [280/390]  eta: 0:00:30  lr: 0.000087  loss: 3.0050 (2.6756)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [39]  [290/390]  eta: 0:00:27  lr: 0.000087  loss: 3.0050 (2.6762)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [39]  [300/390]  eta: 0:00:25  lr: 0.000087  loss: 2.9042 (2.6803)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [39]  [310/390]  eta: 0:00:22  lr: 0.000087  loss: 2.9439 (2.6875)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [39]  [320/390]  eta: 0:00:19  lr: 0.000087  loss: 2.8578 (2.6850)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [39]  [330/390]  eta: 0:00:16  lr: 0.000087  loss: 2.7735 (2.6863)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [39]  [340/390]  eta: 0:00:13  lr: 0.000087  loss: 2.8028 (2.6871)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [39]  [350/390]  eta: 0:00:11  lr: 0.000087  loss: 2.8028 (2.6908)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [39]  [360/390]  eta: 0:00:08  lr: 0.000087  loss: 2.8892 (2.6968)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [39]  [370/390]  eta: 0:00:05  lr: 0.000087  loss: 2.8892 (2.6933)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [39]  [380/390]  eta: 0:00:02  lr: 0.000087  loss: 2.6831 (2.6907)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [39]  [389/390]  eta: 0:00:00  lr: 0.000087  loss: 2.5709 (2.6872)  time: 0.2738  data: 0.0001  max mem: 14473
Epoch: [39] Total time: 0:01:48 (0.2783 s / it)
Averaged stats: lr: 0.000087  loss: 2.5709 (2.6872)
Test:  [ 0/53]  eta: 0:01:17  loss: 0.2546 (0.2546)  acc1: 96.3542 (96.3542)  acc5: 99.4792 (99.4792)  acc1_10: 97.9167 (97.9167)  acc5_10: 99.4792 (99.4792)  time: 1.4639  data: 1.3123  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2306 (0.2367)  acc1: 96.8750 (97.3958)  acc5: 100.0000 (99.9527)  acc1_10: 97.3958 (97.2538)  acc5_10: 100.0000 (99.9053)  time: 0.2506  data: 0.1196  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2454 (0.2502)  acc1: 96.8750 (96.9246)  acc5: 100.0000 (99.8512)  acc1_10: 96.8750 (96.7262)  acc5_10: 100.0000 (99.8016)  time: 0.1257  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2493 (0.2535)  acc1: 96.8750 (96.7910)  acc5: 100.0000 (99.8152)  acc1_10: 97.3958 (96.6734)  acc5_10: 100.0000 (99.7984)  time: 0.1216  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2557 (0.2537)  acc1: 96.8750 (96.7988)  acc5: 100.0000 (99.7713)  acc1_10: 96.8750 (96.6845)  acc5_10: 100.0000 (99.7459)  time: 0.1201  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2557 (0.2549)  acc1: 96.3542 (96.6708)  acc5: 100.0000 (99.7958)  acc1_10: 96.8750 (96.5993)  acc5_10: 100.0000 (99.7855)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2496 (0.2539)  acc1: 96.8750 (96.6800)  acc5: 100.0000 (99.8000)  acc1_10: 96.8750 (96.6100)  acc5_10: 100.0000 (99.7900)  time: 0.1146  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1479 s / it)
* Acc@1 96.680 Acc@5 99.800 loss 0.254
classifiers_10 : Acc@1 96.610 Acc@5 99.790
Accuracy of the network on the 10000 test images: 96.7%
## Using lr  0.0000853 for BACKBONE, cosine lr = 0.0016397 for PRUNER
Epoch: [40]  [  0/390]  eta: 0:11:00  lr: 0.000085  loss: 2.5886 (2.5886)  time: 1.6928  data: 1.3682  max mem: 14473
Epoch: [40]  [ 10/390]  eta: 0:02:33  lr: 0.000085  loss: 2.7364 (2.5731)  time: 0.4052  data: 0.1246  max mem: 14473
Epoch: [40]  [ 20/390]  eta: 0:02:06  lr: 0.000085  loss: 2.7709 (2.6765)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [40]  [ 30/390]  eta: 0:01:55  lr: 0.000085  loss: 2.8931 (2.7523)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [40]  [ 40/390]  eta: 0:01:48  lr: 0.000085  loss: 2.7881 (2.7291)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [40]  [ 50/390]  eta: 0:01:43  lr: 0.000085  loss: 2.4690 (2.6644)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [40]  [ 60/390]  eta: 0:01:38  lr: 0.000085  loss: 2.7073 (2.7019)  time: 0.2744  data: 0.0002  max mem: 14473
Epoch: [40]  [ 70/390]  eta: 0:01:34  lr: 0.000085  loss: 2.9173 (2.6989)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [40]  [ 80/390]  eta: 0:01:30  lr: 0.000085  loss: 2.8976 (2.7079)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [40]  [ 90/390]  eta: 0:01:27  lr: 0.000085  loss: 2.5062 (2.6840)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [40]  [100/390]  eta: 0:01:23  lr: 0.000085  loss: 2.7511 (2.6960)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [40]  [110/390]  eta: 0:01:20  lr: 0.000085  loss: 2.7980 (2.6986)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [40]  [120/390]  eta: 0:01:17  lr: 0.000085  loss: 2.7109 (2.7051)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [40]  [130/390]  eta: 0:01:14  lr: 0.000085  loss: 2.6858 (2.6864)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [40]  [140/390]  eta: 0:01:11  lr: 0.000085  loss: 2.6858 (2.6892)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [40]  [150/390]  eta: 0:01:08  lr: 0.000085  loss: 2.8523 (2.7010)  time: 0.2755  data: 0.0002  max mem: 14473
Epoch: [40]  [160/390]  eta: 0:01:05  lr: 0.000085  loss: 2.8353 (2.7088)  time: 0.2771  data: 0.0002  max mem: 14473
Epoch: [40]  [170/390]  eta: 0:01:02  lr: 0.000085  loss: 2.8229 (2.7029)  time: 0.2771  data: 0.0002  max mem: 14473
Epoch: [40]  [180/390]  eta: 0:00:59  lr: 0.000085  loss: 2.6253 (2.6948)  time: 0.2770  data: 0.0002  max mem: 14473
Epoch: [40]  [190/390]  eta: 0:00:56  lr: 0.000085  loss: 2.6076 (2.6880)  time: 0.2758  data: 0.0002  max mem: 14473
Epoch: [40]  [200/390]  eta: 0:00:53  lr: 0.000085  loss: 2.9220 (2.6935)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [40]  [210/390]  eta: 0:00:50  lr: 0.000085  loss: 2.8825 (2.6935)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [40]  [220/390]  eta: 0:00:47  lr: 0.000085  loss: 2.8552 (2.6989)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [40]  [230/390]  eta: 0:00:44  lr: 0.000085  loss: 2.8552 (2.7021)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [40]  [240/390]  eta: 0:00:42  lr: 0.000085  loss: 2.8267 (2.7063)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [40]  [250/390]  eta: 0:00:39  lr: 0.000085  loss: 2.8516 (2.7029)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [40]  [260/390]  eta: 0:00:36  lr: 0.000085  loss: 2.9362 (2.7095)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [40]  [270/390]  eta: 0:00:33  lr: 0.000085  loss: 2.8886 (2.7126)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [40]  [280/390]  eta: 0:00:30  lr: 0.000085  loss: 2.8978 (2.7210)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [40]  [290/390]  eta: 0:00:27  lr: 0.000085  loss: 2.9816 (2.7233)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [40]  [300/390]  eta: 0:00:25  lr: 0.000085  loss: 2.9056 (2.7224)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [40]  [310/390]  eta: 0:00:22  lr: 0.000085  loss: 2.9056 (2.7194)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [40]  [320/390]  eta: 0:00:19  lr: 0.000085  loss: 2.3985 (2.7121)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [40]  [330/390]  eta: 0:00:16  lr: 0.000085  loss: 2.3849 (2.7011)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [40]  [340/390]  eta: 0:00:13  lr: 0.000085  loss: 2.5496 (2.7002)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [40]  [350/390]  eta: 0:00:11  lr: 0.000085  loss: 2.6839 (2.6963)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [40]  [360/390]  eta: 0:00:08  lr: 0.000085  loss: 2.6527 (2.6926)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [40]  [370/390]  eta: 0:00:05  lr: 0.000085  loss: 2.8787 (2.6942)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [40]  [380/390]  eta: 0:00:02  lr: 0.000085  loss: 2.9335 (2.6925)  time: 0.2713  data: 0.0002  max mem: 14473
Epoch: [40]  [389/390]  eta: 0:00:00  lr: 0.000085  loss: 2.3976 (2.6840)  time: 0.2717  data: 0.0001  max mem: 14473
Epoch: [40] Total time: 0:01:48 (0.2780 s / it)
Averaged stats: lr: 0.000085  loss: 2.3976 (2.6840)
Test:  [ 0/53]  eta: 0:01:29  loss: 0.2638 (0.2638)  acc1: 95.8333 (95.8333)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.6862  data: 1.5350  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2396 (0.2397)  acc1: 96.8750 (96.9224)  acc5: 100.0000 (99.9053)  acc1_10: 96.8750 (96.9224)  acc5_10: 100.0000 (99.9527)  time: 0.2682  data: 0.1398  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2452 (0.2476)  acc1: 96.3542 (96.5526)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.6766)  acc5_10: 100.0000 (99.8016)  time: 0.1237  data: 0.0002  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2435 (0.2459)  acc1: 96.8750 (96.6734)  acc5: 100.0000 (99.8320)  acc1_10: 96.8750 (96.7406)  acc5_10: 100.0000 (99.8320)  time: 0.1209  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2395 (0.2441)  acc1: 96.8750 (96.7480)  acc5: 100.0000 (99.7967)  acc1_10: 96.8750 (96.7607)  acc5_10: 100.0000 (99.8095)  time: 0.1199  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2458 (0.2412)  acc1: 96.3542 (96.7831)  acc5: 100.0000 (99.8366)  acc1_10: 96.8750 (96.8035)  acc5_10: 100.0000 (99.8468)  time: 0.1189  data: 0.0002  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2384 (0.2404)  acc1: 96.8750 (96.8200)  acc5: 100.0000 (99.8400)  acc1_10: 96.8750 (96.7900)  acc5_10: 100.0000 (99.8500)  time: 0.1144  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1512 s / it)
* Acc@1 96.820 Acc@5 99.840 loss 0.240
classifiers_10 : Acc@1 96.790 Acc@5 99.850
Accuracy of the network on the 10000 test images: 96.8%
## Using lr  0.0000835 for BACKBONE, cosine lr = 0.0016023 for PRUNER
Epoch: [41]  [  0/390]  eta: 0:10:32  lr: 0.000084  loss: 2.4048 (2.4048)  time: 1.6226  data: 1.2782  max mem: 14473
Epoch: [41]  [ 10/390]  eta: 0:02:33  lr: 0.000084  loss: 2.7425 (2.6272)  time: 0.4036  data: 0.1164  max mem: 14473
Epoch: [41]  [ 20/390]  eta: 0:02:06  lr: 0.000084  loss: 2.6756 (2.5807)  time: 0.2783  data: 0.0002  max mem: 14473
Epoch: [41]  [ 30/390]  eta: 0:01:55  lr: 0.000084  loss: 2.5439 (2.5966)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [41]  [ 40/390]  eta: 0:01:47  lr: 0.000084  loss: 2.6650 (2.5946)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [41]  [ 50/390]  eta: 0:01:42  lr: 0.000084  loss: 2.8795 (2.6169)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [41]  [ 60/390]  eta: 0:01:37  lr: 0.000084  loss: 2.8795 (2.6457)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [41]  [ 70/390]  eta: 0:01:33  lr: 0.000084  loss: 2.5735 (2.6232)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [41]  [ 80/390]  eta: 0:01:30  lr: 0.000084  loss: 2.5049 (2.6222)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [41]  [ 90/390]  eta: 0:01:26  lr: 0.000084  loss: 2.8490 (2.6579)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [41]  [100/390]  eta: 0:01:23  lr: 0.000084  loss: 2.8490 (2.6596)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [41]  [110/390]  eta: 0:01:20  lr: 0.000084  loss: 2.4585 (2.6358)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [41]  [120/390]  eta: 0:01:17  lr: 0.000084  loss: 2.6354 (2.6488)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [41]  [130/390]  eta: 0:01:14  lr: 0.000084  loss: 2.8326 (2.6475)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [41]  [140/390]  eta: 0:01:11  lr: 0.000084  loss: 2.6722 (2.6530)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [41]  [150/390]  eta: 0:01:08  lr: 0.000084  loss: 2.9662 (2.6688)  time: 0.2777  data: 0.0003  max mem: 14473
Epoch: [41]  [160/390]  eta: 0:01:05  lr: 0.000084  loss: 2.9734 (2.6751)  time: 0.2774  data: 0.0003  max mem: 14473
Epoch: [41]  [170/390]  eta: 0:01:02  lr: 0.000084  loss: 2.7095 (2.6752)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [41]  [180/390]  eta: 0:00:59  lr: 0.000084  loss: 2.7471 (2.6695)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [41]  [190/390]  eta: 0:00:56  lr: 0.000084  loss: 2.5705 (2.6528)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [41]  [200/390]  eta: 0:00:53  lr: 0.000084  loss: 2.4387 (2.6515)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [41]  [210/390]  eta: 0:00:50  lr: 0.000084  loss: 2.7059 (2.6590)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [41]  [220/390]  eta: 0:00:47  lr: 0.000084  loss: 3.0759 (2.6758)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [41]  [230/390]  eta: 0:00:44  lr: 0.000084  loss: 2.9055 (2.6638)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [41]  [240/390]  eta: 0:00:42  lr: 0.000084  loss: 2.8992 (2.6728)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [41]  [250/390]  eta: 0:00:39  lr: 0.000084  loss: 2.7355 (2.6601)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [41]  [260/390]  eta: 0:00:36  lr: 0.000084  loss: 2.6970 (2.6610)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [41]  [270/390]  eta: 0:00:33  lr: 0.000084  loss: 2.7291 (2.6620)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [41]  [280/390]  eta: 0:00:30  lr: 0.000084  loss: 2.7291 (2.6616)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [41]  [290/390]  eta: 0:00:27  lr: 0.000084  loss: 2.6586 (2.6573)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [41]  [300/390]  eta: 0:00:25  lr: 0.000084  loss: 2.6853 (2.6603)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [41]  [310/390]  eta: 0:00:22  lr: 0.000084  loss: 2.6590 (2.6569)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [41]  [320/390]  eta: 0:00:19  lr: 0.000084  loss: 2.5962 (2.6544)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [41]  [330/390]  eta: 0:00:16  lr: 0.000084  loss: 2.7904 (2.6616)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [41]  [340/390]  eta: 0:00:13  lr: 0.000084  loss: 2.7137 (2.6617)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [41]  [350/390]  eta: 0:00:11  lr: 0.000084  loss: 2.6473 (2.6600)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [41]  [360/390]  eta: 0:00:08  lr: 0.000084  loss: 2.5932 (2.6540)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [41]  [370/390]  eta: 0:00:05  lr: 0.000084  loss: 2.5932 (2.6506)  time: 0.2830  data: 0.0003  max mem: 14473
Epoch: [41]  [380/390]  eta: 0:00:02  lr: 0.000084  loss: 2.7157 (2.6486)  time: 0.2810  data: 0.0002  max mem: 14473
Epoch: [41]  [389/390]  eta: 0:00:00  lr: 0.000084  loss: 2.8694 (2.6528)  time: 0.2710  data: 0.0001  max mem: 14473
Epoch: [41] Total time: 0:01:48 (0.2789 s / it)
Averaged stats: lr: 0.000084  loss: 2.8694 (2.6528)
Test:  [ 0/53]  eta: 0:01:14  loss: 0.3132 (0.3132)  acc1: 95.3125 (95.3125)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 99.4792 (99.4792)  time: 1.4072  data: 1.2439  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2807 (0.2753)  acc1: 96.3542 (96.4015)  acc5: 100.0000 (99.8106)  acc1_10: 95.8333 (96.0227)  acc5_10: 99.4792 (99.7159)  time: 0.2641  data: 0.1334  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2787 (0.2802)  acc1: 96.3542 (96.4534)  acc5: 100.0000 (99.7272)  acc1_10: 95.8333 (96.0565)  acc5_10: 100.0000 (99.7520)  time: 0.1353  data: 0.0113  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2787 (0.2812)  acc1: 96.3542 (96.5222)  acc5: 100.0000 (99.7816)  acc1_10: 96.3542 (96.2198)  acc5_10: 100.0000 (99.8152)  time: 0.1209  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2808 (0.2822)  acc1: 96.3542 (96.5193)  acc5: 100.0000 (99.7713)  acc1_10: 96.3542 (96.2525)  acc5_10: 100.0000 (99.8222)  time: 0.1201  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2827 (0.2813)  acc1: 96.3542 (96.5380)  acc5: 100.0000 (99.8060)  acc1_10: 96.3542 (96.2316)  acc5_10: 100.0000 (99.8468)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2768 (0.2795)  acc1: 96.3542 (96.5400)  acc5: 100.0000 (99.8100)  acc1_10: 96.3542 (96.2300)  acc5_10: 100.0000 (99.8400)  time: 0.1147  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1504 s / it)
* Acc@1 96.540 Acc@5 99.810 loss 0.279
classifiers_10 : Acc@1 96.230 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.5%
## Using lr  0.0000818 for BACKBONE, cosine lr = 0.0015646 for PRUNER
Epoch: [42]  [  0/390]  eta: 0:10:13  lr: 0.000082  loss: 1.6265 (1.6265)  time: 1.5730  data: 1.2469  max mem: 14473
Epoch: [42]  [ 10/390]  eta: 0:02:30  lr: 0.000082  loss: 2.7337 (2.4798)  time: 0.3969  data: 0.1136  max mem: 14473
Epoch: [42]  [ 20/390]  eta: 0:02:05  lr: 0.000082  loss: 2.7075 (2.4932)  time: 0.2781  data: 0.0003  max mem: 14473
Epoch: [42]  [ 30/390]  eta: 0:01:56  lr: 0.000082  loss: 2.7075 (2.5977)  time: 0.2812  data: 0.0003  max mem: 14473
Epoch: [42]  [ 40/390]  eta: 0:01:49  lr: 0.000082  loss: 2.6715 (2.5899)  time: 0.2833  data: 0.0003  max mem: 14473
Epoch: [42]  [ 50/390]  eta: 0:01:43  lr: 0.000082  loss: 2.4775 (2.6077)  time: 0.2788  data: 0.0002  max mem: 14473
Epoch: [42]  [ 60/390]  eta: 0:01:38  lr: 0.000082  loss: 2.8297 (2.6423)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [42]  [ 70/390]  eta: 0:01:34  lr: 0.000082  loss: 2.8802 (2.6487)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [42]  [ 80/390]  eta: 0:01:30  lr: 0.000082  loss: 2.6598 (2.6320)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [42]  [ 90/390]  eta: 0:01:27  lr: 0.000082  loss: 2.5612 (2.6274)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [42]  [100/390]  eta: 0:01:23  lr: 0.000082  loss: 2.6453 (2.6362)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [42]  [110/390]  eta: 0:01:20  lr: 0.000082  loss: 2.6927 (2.6338)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [42]  [120/390]  eta: 0:01:17  lr: 0.000082  loss: 2.8185 (2.6467)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [42]  [130/390]  eta: 0:01:14  lr: 0.000082  loss: 2.8185 (2.6580)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [42]  [140/390]  eta: 0:01:11  lr: 0.000082  loss: 2.8686 (2.6627)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [42]  [150/390]  eta: 0:01:08  lr: 0.000082  loss: 2.8347 (2.6592)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [42]  [160/390]  eta: 0:01:05  lr: 0.000082  loss: 2.5487 (2.6501)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [42]  [170/390]  eta: 0:01:02  lr: 0.000082  loss: 2.5487 (2.6427)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [42]  [180/390]  eta: 0:00:59  lr: 0.000082  loss: 2.4657 (2.6277)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [42]  [190/390]  eta: 0:00:56  lr: 0.000082  loss: 2.4657 (2.6295)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [42]  [200/390]  eta: 0:00:53  lr: 0.000082  loss: 2.7243 (2.6367)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [42]  [210/390]  eta: 0:00:50  lr: 0.000082  loss: 2.7243 (2.6400)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [42]  [220/390]  eta: 0:00:47  lr: 0.000082  loss: 2.5116 (2.6378)  time: 0.2723  data: 0.0002  max mem: 14473
Epoch: [42]  [230/390]  eta: 0:00:44  lr: 0.000082  loss: 2.4517 (2.6362)  time: 0.2721  data: 0.0003  max mem: 14473
Epoch: [42]  [240/390]  eta: 0:00:42  lr: 0.000082  loss: 2.7177 (2.6359)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [42]  [250/390]  eta: 0:00:39  lr: 0.000082  loss: 2.8349 (2.6384)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [42]  [260/390]  eta: 0:00:36  lr: 0.000082  loss: 2.8728 (2.6451)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [42]  [270/390]  eta: 0:00:33  lr: 0.000082  loss: 2.8985 (2.6437)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [42]  [280/390]  eta: 0:00:30  lr: 0.000082  loss: 2.7562 (2.6396)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [42]  [290/390]  eta: 0:00:27  lr: 0.000082  loss: 2.7053 (2.6404)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [42]  [300/390]  eta: 0:00:25  lr: 0.000082  loss: 2.6708 (2.6391)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [42]  [310/390]  eta: 0:00:22  lr: 0.000082  loss: 2.6708 (2.6426)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [42]  [320/390]  eta: 0:00:19  lr: 0.000082  loss: 3.0616 (2.6543)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [42]  [330/390]  eta: 0:00:16  lr: 0.000082  loss: 3.0143 (2.6607)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [42]  [340/390]  eta: 0:00:13  lr: 0.000082  loss: 2.7200 (2.6520)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [42]  [350/390]  eta: 0:00:11  lr: 0.000082  loss: 2.5163 (2.6495)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [42]  [360/390]  eta: 0:00:08  lr: 0.000082  loss: 2.6342 (2.6475)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [42]  [370/390]  eta: 0:00:05  lr: 0.000082  loss: 2.7514 (2.6508)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [42]  [380/390]  eta: 0:00:02  lr: 0.000082  loss: 2.9250 (2.6589)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [42]  [389/390]  eta: 0:00:00  lr: 0.000082  loss: 2.9816 (2.6650)  time: 0.2723  data: 0.0001  max mem: 14473
Epoch: [42] Total time: 0:01:48 (0.2785 s / it)
Averaged stats: lr: 0.000082  loss: 2.9816 (2.6650)
Test:  [ 0/53]  eta: 0:01:25  loss: 0.2964 (0.2964)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.6148  data: 1.4628  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2723 (0.2788)  acc1: 97.3958 (96.9224)  acc5: 100.0000 (99.9053)  acc1_10: 97.3958 (97.0170)  acc5_10: 100.0000 (99.9053)  time: 0.2623  data: 0.1332  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2923 (0.2952)  acc1: 96.3542 (96.4038)  acc5: 100.0000 (99.8264)  acc1_10: 96.8750 (96.3790)  acc5_10: 100.0000 (99.8264)  time: 0.1252  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2996 (0.2916)  acc1: 96.3542 (96.4214)  acc5: 100.0000 (99.8152)  acc1_10: 96.3542 (96.4550)  acc5_10: 100.0000 (99.8656)  time: 0.1225  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2917 (0.2920)  acc1: 96.3542 (96.4431)  acc5: 100.0000 (99.7967)  acc1_10: 95.8333 (96.3415)  acc5_10: 100.0000 (99.8603)  time: 0.1208  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2889 (0.2904)  acc1: 96.3542 (96.4767)  acc5: 100.0000 (99.8060)  acc1_10: 95.8333 (96.3746)  acc5_10: 100.0000 (99.8672)  time: 0.1193  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2889 (0.2882)  acc1: 96.3542 (96.4800)  acc5: 100.0000 (99.8100)  acc1_10: 95.8333 (96.3700)  acc5_10: 100.0000 (99.8700)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1508 s / it)
* Acc@1 96.480 Acc@5 99.810 loss 0.288
classifiers_10 : Acc@1 96.370 Acc@5 99.870
Accuracy of the network on the 10000 test images: 96.5%
## Using lr  0.0000800 for BACKBONE, cosine lr = 0.0015266 for PRUNER
Epoch: [43]  [  0/390]  eta: 0:10:39  lr: 0.000080  loss: 2.5899 (2.5899)  time: 1.6397  data: 1.3094  max mem: 14473
Epoch: [43]  [ 10/390]  eta: 0:02:33  lr: 0.000080  loss: 2.7936 (2.7464)  time: 0.4040  data: 0.1193  max mem: 14473
Epoch: [43]  [ 20/390]  eta: 0:02:06  lr: 0.000080  loss: 2.6583 (2.5271)  time: 0.2774  data: 0.0003  max mem: 14473
Epoch: [43]  [ 30/390]  eta: 0:01:55  lr: 0.000080  loss: 2.3235 (2.5463)  time: 0.2759  data: 0.0002  max mem: 14473
Epoch: [43]  [ 40/390]  eta: 0:01:48  lr: 0.000080  loss: 2.6898 (2.5703)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [43]  [ 50/390]  eta: 0:01:42  lr: 0.000080  loss: 2.6898 (2.5383)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [43]  [ 60/390]  eta: 0:01:38  lr: 0.000080  loss: 2.8233 (2.6023)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [43]  [ 70/390]  eta: 0:01:34  lr: 0.000080  loss: 2.8993 (2.6373)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [43]  [ 80/390]  eta: 0:01:30  lr: 0.000080  loss: 2.8993 (2.6683)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [43]  [ 90/390]  eta: 0:01:27  lr: 0.000080  loss: 2.7382 (2.6391)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [43]  [100/390]  eta: 0:01:23  lr: 0.000080  loss: 2.7382 (2.6481)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [43]  [110/390]  eta: 0:01:20  lr: 0.000080  loss: 2.7965 (2.6549)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [43]  [120/390]  eta: 0:01:17  lr: 0.000080  loss: 2.7033 (2.6417)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [43]  [130/390]  eta: 0:01:14  lr: 0.000080  loss: 2.6131 (2.6315)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [43]  [140/390]  eta: 0:01:11  lr: 0.000080  loss: 2.7019 (2.6301)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [43]  [150/390]  eta: 0:01:08  lr: 0.000080  loss: 2.8141 (2.6369)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [43]  [160/390]  eta: 0:01:05  lr: 0.000080  loss: 2.6355 (2.6281)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [43]  [170/390]  eta: 0:01:02  lr: 0.000080  loss: 2.4493 (2.6195)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [43]  [180/390]  eta: 0:00:59  lr: 0.000080  loss: 2.7558 (2.6346)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [43]  [190/390]  eta: 0:00:56  lr: 0.000080  loss: 2.8396 (2.6312)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [43]  [200/390]  eta: 0:00:53  lr: 0.000080  loss: 2.5269 (2.6262)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [43]  [210/390]  eta: 0:00:50  lr: 0.000080  loss: 2.5581 (2.6276)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [43]  [220/390]  eta: 0:00:47  lr: 0.000080  loss: 2.8282 (2.6334)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [43]  [230/390]  eta: 0:00:44  lr: 0.000080  loss: 2.8282 (2.6390)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [43]  [240/390]  eta: 0:00:42  lr: 0.000080  loss: 2.8544 (2.6386)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [43]  [250/390]  eta: 0:00:39  lr: 0.000080  loss: 2.4615 (2.6282)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [43]  [260/390]  eta: 0:00:36  lr: 0.000080  loss: 2.3683 (2.6221)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [43]  [270/390]  eta: 0:00:33  lr: 0.000080  loss: 2.5860 (2.6194)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [43]  [280/390]  eta: 0:00:30  lr: 0.000080  loss: 2.5860 (2.6170)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [43]  [290/390]  eta: 0:00:27  lr: 0.000080  loss: 2.7559 (2.6229)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [43]  [300/390]  eta: 0:00:25  lr: 0.000080  loss: 2.6298 (2.6171)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [43]  [310/390]  eta: 0:00:22  lr: 0.000080  loss: 2.6955 (2.6216)  time: 0.2716  data: 0.0002  max mem: 14473
Epoch: [43]  [320/390]  eta: 0:00:19  lr: 0.000080  loss: 2.8571 (2.6252)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [43]  [330/390]  eta: 0:00:16  lr: 0.000080  loss: 2.8821 (2.6319)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [43]  [340/390]  eta: 0:00:13  lr: 0.000080  loss: 2.7527 (2.6285)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [43]  [350/390]  eta: 0:00:11  lr: 0.000080  loss: 2.7527 (2.6378)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [43]  [360/390]  eta: 0:00:08  lr: 0.000080  loss: 2.7354 (2.6334)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [43]  [370/390]  eta: 0:00:05  lr: 0.000080  loss: 2.6606 (2.6363)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [43]  [380/390]  eta: 0:00:02  lr: 0.000080  loss: 2.7395 (2.6369)  time: 0.2735  data: 0.0002  max mem: 14473
Epoch: [43]  [389/390]  eta: 0:00:00  lr: 0.000080  loss: 2.9713 (2.6432)  time: 0.2723  data: 0.0001  max mem: 14473
Epoch: [43] Total time: 0:01:48 (0.2781 s / it)
Averaged stats: lr: 0.000080  loss: 2.9713 (2.6432)
Test:  [ 0/53]  eta: 0:01:25  loss: 0.2659 (0.2659)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 97.3958 (97.3958)  acc5_10: 100.0000 (100.0000)  time: 1.6181  data: 1.4660  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2678 (0.2698)  acc1: 96.3542 (96.4962)  acc5: 100.0000 (99.9527)  acc1_10: 96.8750 (96.6856)  acc5_10: 100.0000 (99.9527)  time: 0.2644  data: 0.1335  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2787 (0.2823)  acc1: 96.3542 (96.2550)  acc5: 100.0000 (99.8264)  acc1_10: 96.3542 (96.3294)  acc5_10: 100.0000 (99.8264)  time: 0.1251  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2796 (0.2810)  acc1: 96.3542 (96.3710)  acc5: 100.0000 (99.8488)  acc1_10: 96.3542 (96.3038)  acc5_10: 100.0000 (99.8320)  time: 0.1210  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2788 (0.2809)  acc1: 96.8750 (96.4685)  acc5: 100.0000 (99.8349)  acc1_10: 96.3542 (96.3923)  acc5_10: 100.0000 (99.8222)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2820 (0.2814)  acc1: 96.3542 (96.4052)  acc5: 100.0000 (99.8570)  acc1_10: 96.3542 (96.3644)  acc5_10: 100.0000 (99.8468)  time: 0.1194  data: 0.0002  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2820 (0.2798)  acc1: 96.3542 (96.4200)  acc5: 100.0000 (99.8600)  acc1_10: 96.3542 (96.3600)  acc5_10: 100.0000 (99.8400)  time: 0.1146  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1507 s / it)
* Acc@1 96.420 Acc@5 99.860 loss 0.280
classifiers_10 : Acc@1 96.360 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.4%
## Using lr  0.0000783 for BACKBONE, cosine lr = 0.0014883 for PRUNER
Epoch: [44]  [  0/390]  eta: 0:11:35  lr: 0.000078  loss: 3.1875 (3.1875)  time: 1.7845  data: 1.4555  max mem: 14473
Epoch: [44]  [ 10/390]  eta: 0:02:37  lr: 0.000078  loss: 2.7444 (2.6389)  time: 0.4134  data: 0.1325  max mem: 14473
Epoch: [44]  [ 20/390]  eta: 0:02:08  lr: 0.000078  loss: 2.5656 (2.5622)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [44]  [ 30/390]  eta: 0:01:56  lr: 0.000078  loss: 2.3191 (2.4722)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [44]  [ 40/390]  eta: 0:01:48  lr: 0.000078  loss: 2.5677 (2.5333)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [44]  [ 50/390]  eta: 0:01:43  lr: 0.000078  loss: 2.7825 (2.5680)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [44]  [ 60/390]  eta: 0:01:38  lr: 0.000078  loss: 2.7824 (2.5761)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [44]  [ 70/390]  eta: 0:01:34  lr: 0.000078  loss: 2.5177 (2.5620)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [44]  [ 80/390]  eta: 0:01:30  lr: 0.000078  loss: 2.4832 (2.5694)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [44]  [ 90/390]  eta: 0:01:27  lr: 0.000078  loss: 2.8500 (2.5992)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [44]  [100/390]  eta: 0:01:23  lr: 0.000078  loss: 2.8179 (2.6164)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [44]  [110/390]  eta: 0:01:20  lr: 0.000078  loss: 2.7421 (2.6054)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [44]  [120/390]  eta: 0:01:17  lr: 0.000078  loss: 2.7421 (2.5958)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [44]  [130/390]  eta: 0:01:14  lr: 0.000078  loss: 2.8000 (2.6114)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [44]  [140/390]  eta: 0:01:11  lr: 0.000078  loss: 2.6934 (2.6134)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [44]  [150/390]  eta: 0:01:08  lr: 0.000078  loss: 2.6934 (2.6217)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [44]  [160/390]  eta: 0:01:05  lr: 0.000078  loss: 2.8248 (2.6268)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [44]  [170/390]  eta: 0:01:02  lr: 0.000078  loss: 2.8311 (2.6375)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [44]  [180/390]  eta: 0:00:59  lr: 0.000078  loss: 2.8484 (2.6323)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [44]  [190/390]  eta: 0:00:56  lr: 0.000078  loss: 2.5697 (2.6283)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [44]  [200/390]  eta: 0:00:53  lr: 0.000078  loss: 2.5697 (2.6274)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [44]  [210/390]  eta: 0:00:50  lr: 0.000078  loss: 2.6839 (2.6280)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [44]  [220/390]  eta: 0:00:47  lr: 0.000078  loss: 2.6109 (2.6171)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [44]  [230/390]  eta: 0:00:44  lr: 0.000078  loss: 2.4686 (2.6196)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [44]  [240/390]  eta: 0:00:41  lr: 0.000078  loss: 2.8667 (2.6251)  time: 0.2721  data: 0.0002  max mem: 14473
Epoch: [44]  [250/390]  eta: 0:00:39  lr: 0.000078  loss: 2.8748 (2.6290)  time: 0.2727  data: 0.0002  max mem: 14473
Epoch: [44]  [260/390]  eta: 0:00:36  lr: 0.000078  loss: 2.8748 (2.6384)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [44]  [270/390]  eta: 0:00:33  lr: 0.000078  loss: 2.8509 (2.6388)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [44]  [280/390]  eta: 0:00:30  lr: 0.000078  loss: 2.6702 (2.6435)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [44]  [290/390]  eta: 0:00:27  lr: 0.000078  loss: 2.6101 (2.6365)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [44]  [300/390]  eta: 0:00:25  lr: 0.000078  loss: 2.3392 (2.6274)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [44]  [310/390]  eta: 0:00:22  lr: 0.000078  loss: 2.7409 (2.6343)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [44]  [320/390]  eta: 0:00:19  lr: 0.000078  loss: 2.8328 (2.6295)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [44]  [330/390]  eta: 0:00:16  lr: 0.000078  loss: 2.9062 (2.6360)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [44]  [340/390]  eta: 0:00:13  lr: 0.000078  loss: 2.6460 (2.6284)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [44]  [350/390]  eta: 0:00:11  lr: 0.000078  loss: 2.5918 (2.6324)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [44]  [360/390]  eta: 0:00:08  lr: 0.000078  loss: 2.9333 (2.6358)  time: 0.2718  data: 0.0003  max mem: 14473
Epoch: [44]  [370/390]  eta: 0:00:05  lr: 0.000078  loss: 2.8685 (2.6329)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [44]  [380/390]  eta: 0:00:02  lr: 0.000078  loss: 2.8582 (2.6351)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [44]  [389/390]  eta: 0:00:00  lr: 0.000078  loss: 2.8343 (2.6360)  time: 0.2718  data: 0.0001  max mem: 14473
Epoch: [44] Total time: 0:01:48 (0.2774 s / it)
Averaged stats: lr: 0.000078  loss: 2.8343 (2.6360)
Test:  [ 0/53]  eta: 0:01:18  loss: 0.2733 (0.2733)  acc1: 96.8750 (96.8750)  acc5: 99.4792 (99.4792)  acc1_10: 96.8750 (96.8750)  acc5_10: 100.0000 (100.0000)  time: 1.4848  data: 1.3323  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2654 (0.2598)  acc1: 97.3958 (97.4432)  acc5: 100.0000 (99.8580)  acc1_10: 97.3958 (97.1591)  acc5_10: 100.0000 (99.9527)  time: 0.2566  data: 0.1214  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2656 (0.2710)  acc1: 96.3542 (96.9990)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.5030)  acc5_10: 100.0000 (99.8264)  time: 0.1274  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2673 (0.2719)  acc1: 96.3542 (96.8078)  acc5: 100.0000 (99.8152)  acc1_10: 96.3542 (96.5054)  acc5_10: 100.0000 (99.8824)  time: 0.1214  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2700 (0.2743)  acc1: 96.3542 (96.6845)  acc5: 100.0000 (99.7586)  acc1_10: 96.8750 (96.3669)  acc5_10: 100.0000 (99.8476)  time: 0.1210  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2807 (0.2763)  acc1: 96.3542 (96.5686)  acc5: 100.0000 (99.7855)  acc1_10: 96.3542 (96.3440)  acc5_10: 100.0000 (99.8775)  time: 0.1194  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2743 (0.2759)  acc1: 95.8333 (96.5500)  acc5: 100.0000 (99.7900)  acc1_10: 95.8333 (96.3000)  acc5_10: 100.0000 (99.8800)  time: 0.1147  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1492 s / it)
* Acc@1 96.550 Acc@5 99.790 loss 0.276
classifiers_10 : Acc@1 96.300 Acc@5 99.880
Accuracy of the network on the 10000 test images: 96.6%
## Using lr  0.0000765 for BACKBONE, cosine lr = 0.0014498 for PRUNER
Epoch: [45]  [  0/390]  eta: 0:10:32  lr: 0.000076  loss: 1.5970 (1.5970)  time: 1.6208  data: 1.2899  max mem: 14473
Epoch: [45]  [ 10/390]  eta: 0:02:31  lr: 0.000076  loss: 2.2400 (2.4047)  time: 0.3993  data: 0.1175  max mem: 14473
Epoch: [45]  [ 20/390]  eta: 0:02:06  lr: 0.000076  loss: 2.7948 (2.5555)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [45]  [ 30/390]  eta: 0:01:54  lr: 0.000076  loss: 2.8474 (2.6363)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [45]  [ 40/390]  eta: 0:01:48  lr: 0.000076  loss: 2.8734 (2.6593)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [45]  [ 50/390]  eta: 0:01:42  lr: 0.000076  loss: 2.9014 (2.6735)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [45]  [ 60/390]  eta: 0:01:38  lr: 0.000076  loss: 2.7420 (2.6691)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [45]  [ 70/390]  eta: 0:01:34  lr: 0.000076  loss: 2.5337 (2.6528)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [45]  [ 80/390]  eta: 0:01:30  lr: 0.000076  loss: 2.5137 (2.6388)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [45]  [ 90/390]  eta: 0:01:26  lr: 0.000076  loss: 2.7926 (2.6574)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [45]  [100/390]  eta: 0:01:23  lr: 0.000076  loss: 2.7416 (2.6401)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [45]  [110/390]  eta: 0:01:20  lr: 0.000076  loss: 2.6949 (2.6475)  time: 0.2735  data: 0.0002  max mem: 14473
Epoch: [45]  [120/390]  eta: 0:01:17  lr: 0.000076  loss: 2.7553 (2.6459)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [45]  [130/390]  eta: 0:01:14  lr: 0.000076  loss: 2.7092 (2.6430)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [45]  [140/390]  eta: 0:01:11  lr: 0.000076  loss: 2.2652 (2.6185)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [45]  [150/390]  eta: 0:01:08  lr: 0.000076  loss: 2.2195 (2.6151)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [45]  [160/390]  eta: 0:01:05  lr: 0.000076  loss: 2.8773 (2.6201)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [45]  [170/390]  eta: 0:01:02  lr: 0.000076  loss: 2.8773 (2.6226)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [45]  [180/390]  eta: 0:00:59  lr: 0.000076  loss: 2.5987 (2.6174)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [45]  [190/390]  eta: 0:00:56  lr: 0.000076  loss: 2.4937 (2.6143)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [45]  [200/390]  eta: 0:00:53  lr: 0.000076  loss: 2.7348 (2.6207)  time: 0.2829  data: 0.0003  max mem: 14473
Epoch: [45]  [210/390]  eta: 0:00:50  lr: 0.000076  loss: 2.8302 (2.6333)  time: 0.2830  data: 0.0003  max mem: 14473
Epoch: [45]  [220/390]  eta: 0:00:47  lr: 0.000076  loss: 2.9225 (2.6355)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [45]  [230/390]  eta: 0:00:44  lr: 0.000076  loss: 2.6890 (2.6264)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [45]  [240/390]  eta: 0:00:42  lr: 0.000076  loss: 2.5458 (2.6200)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [45]  [250/390]  eta: 0:00:39  lr: 0.000076  loss: 2.6862 (2.6208)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [45]  [260/390]  eta: 0:00:36  lr: 0.000076  loss: 2.8082 (2.6288)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [45]  [270/390]  eta: 0:00:33  lr: 0.000076  loss: 2.7834 (2.6211)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [45]  [280/390]  eta: 0:00:30  lr: 0.000076  loss: 2.4700 (2.6181)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [45]  [290/390]  eta: 0:00:27  lr: 0.000076  loss: 2.4851 (2.6159)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [45]  [300/390]  eta: 0:00:25  lr: 0.000076  loss: 2.6731 (2.6166)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [45]  [310/390]  eta: 0:00:22  lr: 0.000076  loss: 2.6878 (2.6175)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [45]  [320/390]  eta: 0:00:19  lr: 0.000076  loss: 2.7057 (2.6217)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [45]  [330/390]  eta: 0:00:16  lr: 0.000076  loss: 2.8835 (2.6238)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [45]  [340/390]  eta: 0:00:13  lr: 0.000076  loss: 2.7387 (2.6186)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [45]  [350/390]  eta: 0:00:11  lr: 0.000076  loss: 2.8332 (2.6236)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [45]  [360/390]  eta: 0:00:08  lr: 0.000076  loss: 2.8470 (2.6262)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [45]  [370/390]  eta: 0:00:05  lr: 0.000076  loss: 2.7745 (2.6270)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [45]  [380/390]  eta: 0:00:02  lr: 0.000076  loss: 2.8464 (2.6318)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [45]  [389/390]  eta: 0:00:00  lr: 0.000076  loss: 2.7889 (2.6292)  time: 0.2725  data: 0.0001  max mem: 14473
Epoch: [45] Total time: 0:01:48 (0.2785 s / it)
Averaged stats: lr: 0.000076  loss: 2.7889 (2.6292)
Test:  [ 0/53]  eta: 0:01:15  loss: 0.2356 (0.2356)  acc1: 96.8750 (96.8750)  acc5: 99.4792 (99.4792)  acc1_10: 96.8750 (96.8750)  acc5_10: 100.0000 (100.0000)  time: 1.4292  data: 1.2659  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2200 (0.2221)  acc1: 96.8750 (97.0170)  acc5: 100.0000 (99.8106)  acc1_10: 97.3958 (97.1591)  acc5_10: 100.0000 (99.9053)  time: 0.2494  data: 0.1154  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2305 (0.2339)  acc1: 96.8750 (96.7262)  acc5: 100.0000 (99.7768)  acc1_10: 96.8750 (96.8254)  acc5_10: 100.0000 (99.8264)  time: 0.1267  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2452 (0.2358)  acc1: 96.8750 (96.7406)  acc5: 100.0000 (99.7648)  acc1_10: 96.8750 (96.8078)  acc5_10: 100.0000 (99.8152)  time: 0.1217  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2460 (0.2393)  acc1: 96.3542 (96.6590)  acc5: 99.4792 (99.7078)  acc1_10: 96.8750 (96.6972)  acc5_10: 100.0000 (99.7840)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2423 (0.2390)  acc1: 96.3542 (96.6503)  acc5: 100.0000 (99.7651)  acc1_10: 96.3542 (96.7320)  acc5_10: 100.0000 (99.8264)  time: 0.1192  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2303 (0.2370)  acc1: 96.3542 (96.6700)  acc5: 100.0000 (99.7700)  acc1_10: 96.8750 (96.7500)  acc5_10: 100.0000 (99.8200)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1478 s / it)
* Acc@1 96.670 Acc@5 99.770 loss 0.237
classifiers_10 : Acc@1 96.750 Acc@5 99.820
Accuracy of the network on the 10000 test images: 96.7%
## Using lr  0.0000747 for BACKBONE, cosine lr = 0.0014110 for PRUNER
Epoch: [46]  [  0/390]  eta: 0:10:07  lr: 0.000075  loss: 2.6900 (2.6900)  time: 1.5577  data: 1.2304  max mem: 14473
Epoch: [46]  [ 10/390]  eta: 0:02:30  lr: 0.000075  loss: 2.5063 (2.4841)  time: 0.3963  data: 0.1121  max mem: 14473
Epoch: [46]  [ 20/390]  eta: 0:02:04  lr: 0.000075  loss: 2.5063 (2.5065)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [46]  [ 30/390]  eta: 0:01:54  lr: 0.000075  loss: 2.7253 (2.5804)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [46]  [ 40/390]  eta: 0:01:47  lr: 0.000075  loss: 2.7253 (2.5669)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [46]  [ 50/390]  eta: 0:01:42  lr: 0.000075  loss: 2.5471 (2.5398)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [46]  [ 60/390]  eta: 0:01:37  lr: 0.000075  loss: 2.5471 (2.5705)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [46]  [ 70/390]  eta: 0:01:33  lr: 0.000075  loss: 2.7418 (2.5899)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [46]  [ 80/390]  eta: 0:01:30  lr: 0.000075  loss: 2.8821 (2.6167)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [46]  [ 90/390]  eta: 0:01:26  lr: 0.000075  loss: 2.7751 (2.6057)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [46]  [100/390]  eta: 0:01:23  lr: 0.000075  loss: 2.5956 (2.6209)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [46]  [110/390]  eta: 0:01:20  lr: 0.000075  loss: 2.7243 (2.6167)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [46]  [120/390]  eta: 0:01:16  lr: 0.000075  loss: 2.6894 (2.6076)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [46]  [130/390]  eta: 0:01:13  lr: 0.000075  loss: 2.6438 (2.5996)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [46]  [140/390]  eta: 0:01:10  lr: 0.000075  loss: 2.9239 (2.6172)  time: 0.2714  data: 0.0003  max mem: 14473
Epoch: [46]  [150/390]  eta: 0:01:07  lr: 0.000075  loss: 2.9239 (2.6166)  time: 0.2719  data: 0.0003  max mem: 14473
Epoch: [46]  [160/390]  eta: 0:01:04  lr: 0.000075  loss: 2.9567 (2.6407)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [46]  [170/390]  eta: 0:01:01  lr: 0.000075  loss: 2.9624 (2.6454)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [46]  [180/390]  eta: 0:00:59  lr: 0.000075  loss: 2.7426 (2.6420)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [46]  [190/390]  eta: 0:00:56  lr: 0.000075  loss: 2.6084 (2.6346)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [46]  [200/390]  eta: 0:00:53  lr: 0.000075  loss: 2.6405 (2.6338)  time: 0.2773  data: 0.0003  max mem: 14473
Epoch: [46]  [210/390]  eta: 0:00:50  lr: 0.000075  loss: 2.6726 (2.6397)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [46]  [220/390]  eta: 0:00:47  lr: 0.000075  loss: 2.6320 (2.6322)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [46]  [230/390]  eta: 0:00:44  lr: 0.000075  loss: 2.6540 (2.6365)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [46]  [240/390]  eta: 0:00:41  lr: 0.000075  loss: 2.7994 (2.6345)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [46]  [250/390]  eta: 0:00:39  lr: 0.000075  loss: 2.6040 (2.6361)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [46]  [260/390]  eta: 0:00:36  lr: 0.000075  loss: 2.7628 (2.6379)  time: 0.2778  data: 0.0003  max mem: 14473
Epoch: [46]  [270/390]  eta: 0:00:33  lr: 0.000075  loss: 2.7376 (2.6398)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [46]  [280/390]  eta: 0:00:30  lr: 0.000075  loss: 2.7668 (2.6439)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [46]  [290/390]  eta: 0:00:27  lr: 0.000075  loss: 2.8231 (2.6458)  time: 0.2785  data: 0.0002  max mem: 14473
Epoch: [46]  [300/390]  eta: 0:00:25  lr: 0.000075  loss: 2.9667 (2.6577)  time: 0.2776  data: 0.0003  max mem: 14473
Epoch: [46]  [310/390]  eta: 0:00:22  lr: 0.000075  loss: 2.9667 (2.6570)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [46]  [320/390]  eta: 0:00:19  lr: 0.000075  loss: 2.9656 (2.6675)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [46]  [330/390]  eta: 0:00:16  lr: 0.000075  loss: 2.8044 (2.6699)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [46]  [340/390]  eta: 0:00:13  lr: 0.000075  loss: 2.7433 (2.6732)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [46]  [350/390]  eta: 0:00:11  lr: 0.000075  loss: 2.8453 (2.6735)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [46]  [360/390]  eta: 0:00:08  lr: 0.000075  loss: 2.7544 (2.6746)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [46]  [370/390]  eta: 0:00:05  lr: 0.000075  loss: 2.6453 (2.6724)  time: 0.2795  data: 0.0003  max mem: 14473
Epoch: [46]  [380/390]  eta: 0:00:02  lr: 0.000075  loss: 2.6453 (2.6694)  time: 0.2762  data: 0.0002  max mem: 14473
Epoch: [46]  [389/390]  eta: 0:00:00  lr: 0.000075  loss: 2.8554 (2.6743)  time: 0.2738  data: 0.0001  max mem: 14473
Epoch: [46] Total time: 0:01:48 (0.2786 s / it)
Averaged stats: lr: 0.000075  loss: 2.8554 (2.6743)
Test:  [ 0/53]  eta: 0:01:15  loss: 0.3093 (0.3093)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.4319  data: 1.2798  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.3094 (0.3075)  acc1: 96.3542 (96.4962)  acc5: 100.0000 (99.9527)  acc1_10: 96.8750 (96.6856)  acc5_10: 100.0000 (99.9053)  time: 0.2531  data: 0.1168  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.3214 (0.3203)  acc1: 95.8333 (96.1806)  acc5: 100.0000 (99.8264)  acc1_10: 95.8333 (96.1062)  acc5_10: 100.0000 (99.8264)  time: 0.1290  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.3214 (0.3179)  acc1: 96.3542 (96.4886)  acc5: 100.0000 (99.8152)  acc1_10: 95.8333 (96.3206)  acc5_10: 100.0000 (99.8152)  time: 0.1231  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.3063 (0.3169)  acc1: 96.8750 (96.5828)  acc5: 100.0000 (99.7840)  acc1_10: 96.8750 (96.4177)  acc5_10: 100.0000 (99.7713)  time: 0.1213  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.3063 (0.3144)  acc1: 96.8750 (96.6197)  acc5: 100.0000 (99.8162)  acc1_10: 96.8750 (96.4461)  acc5_10: 100.0000 (99.8060)  time: 0.1189  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.3024 (0.3118)  acc1: 96.8750 (96.6500)  acc5: 100.0000 (99.8200)  acc1_10: 96.8750 (96.4600)  acc5_10: 100.0000 (99.8100)  time: 0.1144  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1489 s / it)
* Acc@1 96.650 Acc@5 99.820 loss 0.312
classifiers_10 : Acc@1 96.460 Acc@5 99.810
Accuracy of the network on the 10000 test images: 96.7%
## Using lr  0.0000729 for BACKBONE, cosine lr = 0.0013722 for PRUNER
Epoch: [47]  [  0/390]  eta: 0:09:04  lr: 0.000073  loss: 1.9852 (1.9852)  time: 1.3962  data: 1.0641  max mem: 14473
Epoch: [47]  [ 10/390]  eta: 0:02:25  lr: 0.000073  loss: 2.4421 (2.4213)  time: 0.3819  data: 0.0970  max mem: 14473
Epoch: [47]  [ 20/390]  eta: 0:02:02  lr: 0.000073  loss: 2.4421 (2.4346)  time: 0.2780  data: 0.0003  max mem: 14473
Epoch: [47]  [ 30/390]  eta: 0:01:52  lr: 0.000073  loss: 2.5663 (2.4856)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [47]  [ 40/390]  eta: 0:01:46  lr: 0.000073  loss: 2.5663 (2.4886)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [47]  [ 50/390]  eta: 0:01:41  lr: 0.000073  loss: 2.6148 (2.5486)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [47]  [ 60/390]  eta: 0:01:37  lr: 0.000073  loss: 2.9541 (2.6006)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [47]  [ 70/390]  eta: 0:01:33  lr: 0.000073  loss: 2.8808 (2.5829)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [47]  [ 80/390]  eta: 0:01:29  lr: 0.000073  loss: 2.8808 (2.6174)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [47]  [ 90/390]  eta: 0:01:26  lr: 0.000073  loss: 2.9137 (2.6203)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [47]  [100/390]  eta: 0:01:23  lr: 0.000073  loss: 2.4954 (2.6081)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [47]  [110/390]  eta: 0:01:19  lr: 0.000073  loss: 2.4913 (2.5974)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [47]  [120/390]  eta: 0:01:16  lr: 0.000073  loss: 2.4280 (2.5839)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [47]  [130/390]  eta: 0:01:13  lr: 0.000073  loss: 2.7790 (2.5861)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [47]  [140/390]  eta: 0:01:10  lr: 0.000073  loss: 2.7460 (2.5834)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [47]  [150/390]  eta: 0:01:07  lr: 0.000073  loss: 2.8378 (2.6041)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [47]  [160/390]  eta: 0:01:04  lr: 0.000073  loss: 2.8624 (2.6037)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [47]  [170/390]  eta: 0:01:01  lr: 0.000073  loss: 2.7706 (2.6144)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [47]  [180/390]  eta: 0:00:59  lr: 0.000073  loss: 2.8307 (2.6114)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [47]  [190/390]  eta: 0:00:56  lr: 0.000073  loss: 2.7387 (2.6167)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [47]  [200/390]  eta: 0:00:53  lr: 0.000073  loss: 2.6562 (2.6172)  time: 0.2769  data: 0.0003  max mem: 14473
Epoch: [47]  [210/390]  eta: 0:00:50  lr: 0.000073  loss: 2.4776 (2.6036)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [47]  [220/390]  eta: 0:00:47  lr: 0.000073  loss: 2.4279 (2.6034)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [47]  [230/390]  eta: 0:00:44  lr: 0.000073  loss: 2.8578 (2.6118)  time: 0.2794  data: 0.0002  max mem: 14473
Epoch: [47]  [240/390]  eta: 0:00:42  lr: 0.000073  loss: 2.8164 (2.6086)  time: 0.2783  data: 0.0003  max mem: 14473
Epoch: [47]  [250/390]  eta: 0:00:39  lr: 0.000073  loss: 2.5775 (2.6071)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [47]  [260/390]  eta: 0:00:36  lr: 0.000073  loss: 2.5775 (2.6050)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [47]  [270/390]  eta: 0:00:33  lr: 0.000073  loss: 2.6389 (2.6089)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [47]  [280/390]  eta: 0:00:30  lr: 0.000073  loss: 2.8301 (2.6132)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [47]  [290/390]  eta: 0:00:27  lr: 0.000073  loss: 2.7531 (2.6112)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [47]  [300/390]  eta: 0:00:25  lr: 0.000073  loss: 2.4642 (2.5966)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [47]  [310/390]  eta: 0:00:22  lr: 0.000073  loss: 2.4666 (2.6034)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [47]  [320/390]  eta: 0:00:19  lr: 0.000073  loss: 2.7044 (2.6054)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [47]  [330/390]  eta: 0:00:16  lr: 0.000073  loss: 2.7044 (2.6109)  time: 0.2723  data: 0.0003  max mem: 14473
Epoch: [47]  [340/390]  eta: 0:00:13  lr: 0.000073  loss: 2.7157 (2.6096)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [47]  [350/390]  eta: 0:00:11  lr: 0.000073  loss: 2.6067 (2.6063)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [47]  [360/390]  eta: 0:00:08  lr: 0.000073  loss: 2.7531 (2.6100)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [47]  [370/390]  eta: 0:00:05  lr: 0.000073  loss: 2.8823 (2.6133)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [47]  [380/390]  eta: 0:00:02  lr: 0.000073  loss: 2.6234 (2.6085)  time: 0.2754  data: 0.0002  max mem: 14473
Epoch: [47]  [389/390]  eta: 0:00:00  lr: 0.000073  loss: 2.3667 (2.6041)  time: 0.2746  data: 0.0001  max mem: 14473
Epoch: [47] Total time: 0:01:48 (0.2781 s / it)
Averaged stats: lr: 0.000073  loss: 2.3667 (2.6041)
Test:  [ 0/53]  eta: 0:01:29  loss: 0.2328 (0.2328)  acc1: 97.3958 (97.3958)  acc5: 100.0000 (100.0000)  acc1_10: 97.3958 (97.3958)  acc5_10: 100.0000 (100.0000)  time: 1.6868  data: 1.5510  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2380 (0.2365)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (99.9053)  acc1_10: 96.8750 (96.7803)  acc5_10: 100.0000 (99.9527)  time: 0.2660  data: 0.1412  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2472 (0.2481)  acc1: 96.8750 (96.6022)  acc5: 100.0000 (99.8760)  acc1_10: 96.3542 (96.4286)  acc5_10: 100.0000 (99.9504)  time: 0.1233  data: 0.0002  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2525 (0.2504)  acc1: 96.8750 (96.6398)  acc5: 100.0000 (99.8320)  acc1_10: 96.3542 (96.5390)  acc5_10: 100.0000 (99.9328)  time: 0.1216  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2526 (0.2523)  acc1: 96.8750 (96.6209)  acc5: 100.0000 (99.7586)  acc1_10: 96.3542 (96.5574)  acc5_10: 100.0000 (99.8730)  time: 0.1198  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2458 (0.2509)  acc1: 96.8750 (96.6605)  acc5: 100.0000 (99.7753)  acc1_10: 96.3542 (96.6299)  acc5_10: 100.0000 (99.8775)  time: 0.1186  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2430 (0.2487)  acc1: 96.8750 (96.6800)  acc5: 100.0000 (99.7800)  acc1_10: 96.3542 (96.6300)  acc5_10: 100.0000 (99.8800)  time: 0.1142  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1511 s / it)
* Acc@1 96.680 Acc@5 99.780 loss 0.249
classifiers_10 : Acc@1 96.630 Acc@5 99.880
Accuracy of the network on the 10000 test images: 96.7%
## Using lr  0.0000711 for BACKBONE, cosine lr = 0.0013332 for PRUNER
Epoch: [48]  [  0/390]  eta: 0:10:36  lr: 0.000071  loss: 2.4851 (2.4851)  time: 1.6327  data: 1.3075  max mem: 14473
Epoch: [48]  [ 10/390]  eta: 0:02:33  lr: 0.000071  loss: 2.6583 (2.5635)  time: 0.4045  data: 0.1191  max mem: 14473
Epoch: [48]  [ 20/390]  eta: 0:02:06  lr: 0.000071  loss: 2.6290 (2.4884)  time: 0.2783  data: 0.0003  max mem: 14473
Epoch: [48]  [ 30/390]  eta: 0:01:55  lr: 0.000071  loss: 2.6474 (2.5352)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [48]  [ 40/390]  eta: 0:01:48  lr: 0.000071  loss: 2.5435 (2.5297)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [48]  [ 50/390]  eta: 0:01:43  lr: 0.000071  loss: 2.5435 (2.5713)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [48]  [ 60/390]  eta: 0:01:38  lr: 0.000071  loss: 2.7750 (2.5900)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [48]  [ 70/390]  eta: 0:01:34  lr: 0.000071  loss: 2.6556 (2.6104)  time: 0.2798  data: 0.0003  max mem: 14473
Epoch: [48]  [ 80/390]  eta: 0:01:31  lr: 0.000071  loss: 2.8151 (2.6444)  time: 0.2796  data: 0.0002  max mem: 14473
Epoch: [48]  [ 90/390]  eta: 0:01:27  lr: 0.000071  loss: 2.7790 (2.6427)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [48]  [100/390]  eta: 0:01:24  lr: 0.000071  loss: 2.5492 (2.6329)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [48]  [110/390]  eta: 0:01:20  lr: 0.000071  loss: 2.5492 (2.6207)  time: 0.2733  data: 0.0002  max mem: 14473
Epoch: [48]  [120/390]  eta: 0:01:17  lr: 0.000071  loss: 2.6984 (2.6148)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [48]  [130/390]  eta: 0:01:14  lr: 0.000071  loss: 2.3348 (2.5843)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [48]  [140/390]  eta: 0:01:11  lr: 0.000071  loss: 2.3348 (2.5898)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [48]  [150/390]  eta: 0:01:08  lr: 0.000071  loss: 2.7719 (2.5967)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [48]  [160/390]  eta: 0:01:05  lr: 0.000071  loss: 2.8992 (2.6003)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [48]  [170/390]  eta: 0:01:02  lr: 0.000071  loss: 2.8878 (2.6159)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [48]  [180/390]  eta: 0:00:59  lr: 0.000071  loss: 2.7850 (2.6198)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [48]  [190/390]  eta: 0:00:56  lr: 0.000071  loss: 2.5869 (2.6108)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [48]  [200/390]  eta: 0:00:53  lr: 0.000071  loss: 2.5387 (2.6066)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [48]  [210/390]  eta: 0:00:50  lr: 0.000071  loss: 2.6170 (2.6143)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [48]  [220/390]  eta: 0:00:47  lr: 0.000071  loss: 2.5545 (2.6047)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [48]  [230/390]  eta: 0:00:44  lr: 0.000071  loss: 2.5545 (2.6075)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [48]  [240/390]  eta: 0:00:42  lr: 0.000071  loss: 2.3745 (2.5945)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [48]  [250/390]  eta: 0:00:39  lr: 0.000071  loss: 2.5676 (2.6028)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [48]  [260/390]  eta: 0:00:36  lr: 0.000071  loss: 2.8298 (2.6043)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [48]  [270/390]  eta: 0:00:33  lr: 0.000071  loss: 2.8298 (2.5988)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [48]  [280/390]  eta: 0:00:30  lr: 0.000071  loss: 2.7624 (2.5976)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [48]  [290/390]  eta: 0:00:27  lr: 0.000071  loss: 2.8073 (2.6033)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [48]  [300/390]  eta: 0:00:25  lr: 0.000071  loss: 2.7826 (2.6036)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [48]  [310/390]  eta: 0:00:22  lr: 0.000071  loss: 2.6563 (2.6016)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [48]  [320/390]  eta: 0:00:19  lr: 0.000071  loss: 2.3878 (2.5994)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [48]  [330/390]  eta: 0:00:16  lr: 0.000071  loss: 2.3673 (2.5953)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [48]  [340/390]  eta: 0:00:13  lr: 0.000071  loss: 2.6844 (2.6021)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [48]  [350/390]  eta: 0:00:11  lr: 0.000071  loss: 2.8581 (2.6112)  time: 0.2720  data: 0.0003  max mem: 14473
Epoch: [48]  [360/390]  eta: 0:00:08  lr: 0.000071  loss: 2.8581 (2.6136)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [48]  [370/390]  eta: 0:00:05  lr: 0.000071  loss: 2.5710 (2.6068)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [48]  [380/390]  eta: 0:00:02  lr: 0.000071  loss: 2.7377 (2.6156)  time: 0.2780  data: 0.0002  max mem: 14473
Epoch: [48]  [389/390]  eta: 0:00:00  lr: 0.000071  loss: 3.0189 (2.6230)  time: 0.2751  data: 0.0001  max mem: 14473
Epoch: [48] Total time: 0:01:48 (0.2786 s / it)
Averaged stats: lr: 0.000071  loss: 3.0189 (2.6230)
Test:  [ 0/53]  eta: 0:01:28  loss: 0.3175 (0.3175)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  acc1_10: 94.7917 (94.7917)  acc5_10: 100.0000 (100.0000)  time: 1.6663  data: 1.5240  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2813 (0.2886)  acc1: 97.3958 (96.8277)  acc5: 100.0000 (99.8106)  acc1_10: 96.8750 (96.4489)  acc5_10: 100.0000 (99.9527)  time: 0.2659  data: 0.1388  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2915 (0.2971)  acc1: 96.8750 (96.5774)  acc5: 99.4792 (99.6776)  acc1_10: 96.3542 (96.5278)  acc5_10: 100.0000 (99.8016)  time: 0.1236  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2951 (0.2969)  acc1: 96.3542 (96.6902)  acc5: 100.0000 (99.7648)  acc1_10: 96.3542 (96.6398)  acc5_10: 100.0000 (99.8320)  time: 0.1216  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2926 (0.2957)  acc1: 96.8750 (96.7734)  acc5: 100.0000 (99.7332)  acc1_10: 97.3958 (96.7353)  acc5_10: 100.0000 (99.8095)  time: 0.1204  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2895 (0.2944)  acc1: 97.3958 (96.8648)  acc5: 100.0000 (99.7549)  acc1_10: 97.3958 (96.8342)  acc5_10: 100.0000 (99.8366)  time: 0.1191  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2865 (0.2918)  acc1: 97.3958 (96.9100)  acc5: 100.0000 (99.7600)  acc1_10: 97.3958 (96.8500)  acc5_10: 100.0000 (99.8400)  time: 0.1151  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1513 s / it)
* Acc@1 96.910 Acc@5 99.760 loss 0.292
classifiers_10 : Acc@1 96.850 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.9%
## Using lr  0.0000693 for BACKBONE, cosine lr = 0.0012941 for PRUNER
Epoch: [49]  [  0/390]  eta: 0:10:26  lr: 0.000069  loss: 3.0448 (3.0448)  time: 1.6060  data: 1.2807  max mem: 14473
Epoch: [49]  [ 10/390]  eta: 0:02:32  lr: 0.000069  loss: 2.8091 (2.5369)  time: 0.4011  data: 0.1167  max mem: 14473
Epoch: [49]  [ 20/390]  eta: 0:02:06  lr: 0.000069  loss: 2.5916 (2.4583)  time: 0.2778  data: 0.0003  max mem: 14473
Epoch: [49]  [ 30/390]  eta: 0:01:55  lr: 0.000069  loss: 2.2193 (2.4424)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [49]  [ 40/390]  eta: 0:01:47  lr: 0.000069  loss: 2.7264 (2.5102)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [49]  [ 50/390]  eta: 0:01:42  lr: 0.000069  loss: 2.8404 (2.5101)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [49]  [ 60/390]  eta: 0:01:38  lr: 0.000069  loss: 2.8816 (2.5783)  time: 0.2767  data: 0.0002  max mem: 14473
Epoch: [49]  [ 70/390]  eta: 0:01:34  lr: 0.000069  loss: 2.9656 (2.6039)  time: 0.2815  data: 0.0003  max mem: 14473
Epoch: [49]  [ 80/390]  eta: 0:01:31  lr: 0.000069  loss: 2.8443 (2.6104)  time: 0.2854  data: 0.0003  max mem: 14473
Epoch: [49]  [ 90/390]  eta: 0:01:27  lr: 0.000069  loss: 2.6704 (2.6035)  time: 0.2817  data: 0.0003  max mem: 14473
Epoch: [49]  [100/390]  eta: 0:01:24  lr: 0.000069  loss: 2.8625 (2.6268)  time: 0.2768  data: 0.0002  max mem: 14473
Epoch: [49]  [110/390]  eta: 0:01:21  lr: 0.000069  loss: 2.8717 (2.6391)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [49]  [120/390]  eta: 0:01:17  lr: 0.000069  loss: 2.7912 (2.6595)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [49]  [130/390]  eta: 0:01:14  lr: 0.000069  loss: 2.7912 (2.6579)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [49]  [140/390]  eta: 0:01:11  lr: 0.000069  loss: 2.7842 (2.6515)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [49]  [150/390]  eta: 0:01:08  lr: 0.000069  loss: 2.4477 (2.6276)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [49]  [160/390]  eta: 0:01:05  lr: 0.000069  loss: 2.4477 (2.6206)  time: 0.2822  data: 0.0002  max mem: 14473
Epoch: [49]  [170/390]  eta: 0:01:02  lr: 0.000069  loss: 2.3662 (2.6076)  time: 0.2822  data: 0.0003  max mem: 14473
Epoch: [49]  [180/390]  eta: 0:00:59  lr: 0.000069  loss: 2.7457 (2.6112)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [49]  [190/390]  eta: 0:00:56  lr: 0.000069  loss: 2.7303 (2.6054)  time: 0.2768  data: 0.0002  max mem: 14473
Epoch: [49]  [200/390]  eta: 0:00:53  lr: 0.000069  loss: 2.5184 (2.6051)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [49]  [210/390]  eta: 0:00:50  lr: 0.000069  loss: 2.5620 (2.6060)  time: 0.2737  data: 0.0003  max mem: 14473
Epoch: [49]  [220/390]  eta: 0:00:48  lr: 0.000069  loss: 2.5620 (2.6022)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [49]  [230/390]  eta: 0:00:45  lr: 0.000069  loss: 2.6388 (2.6056)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [49]  [240/390]  eta: 0:00:42  lr: 0.000069  loss: 2.7441 (2.6125)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [49]  [250/390]  eta: 0:00:39  lr: 0.000069  loss: 2.8154 (2.6129)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [49]  [260/390]  eta: 0:00:36  lr: 0.000069  loss: 2.6841 (2.6118)  time: 0.2777  data: 0.0002  max mem: 14473
Epoch: [49]  [270/390]  eta: 0:00:33  lr: 0.000069  loss: 2.4722 (2.5983)  time: 0.2770  data: 0.0003  max mem: 14473
Epoch: [49]  [280/390]  eta: 0:00:30  lr: 0.000069  loss: 2.3806 (2.5970)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [49]  [290/390]  eta: 0:00:28  lr: 0.000069  loss: 2.5536 (2.5929)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [49]  [300/390]  eta: 0:00:25  lr: 0.000069  loss: 2.7618 (2.6029)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [49]  [310/390]  eta: 0:00:22  lr: 0.000069  loss: 2.9104 (2.6081)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [49]  [320/390]  eta: 0:00:19  lr: 0.000069  loss: 2.9698 (2.6150)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [49]  [330/390]  eta: 0:00:16  lr: 0.000069  loss: 2.9938 (2.6193)  time: 0.2780  data: 0.0003  max mem: 14473
Epoch: [49]  [340/390]  eta: 0:00:14  lr: 0.000069  loss: 2.7313 (2.6187)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [49]  [350/390]  eta: 0:00:11  lr: 0.000069  loss: 2.7312 (2.6250)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [49]  [360/390]  eta: 0:00:08  lr: 0.000069  loss: 2.8596 (2.6218)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [49]  [370/390]  eta: 0:00:05  lr: 0.000069  loss: 2.7323 (2.6260)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [49]  [380/390]  eta: 0:00:02  lr: 0.000069  loss: 2.7598 (2.6291)  time: 0.2736  data: 0.0002  max mem: 14473
Epoch: [49]  [389/390]  eta: 0:00:00  lr: 0.000069  loss: 2.7702 (2.6286)  time: 0.2723  data: 0.0001  max mem: 14473
Epoch: [49] Total time: 0:01:49 (0.2797 s / it)
Averaged stats: lr: 0.000069  loss: 2.7702 (2.6286)
Test:  [ 0/53]  eta: 0:01:17  loss: 0.2605 (0.2605)  acc1: 97.3958 (97.3958)  acc5: 100.0000 (100.0000)  acc1_10: 96.8750 (96.8750)  acc5_10: 100.0000 (100.0000)  time: 1.4538  data: 1.3000  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2564 (0.2560)  acc1: 97.3958 (97.2064)  acc5: 100.0000 (99.7633)  acc1_10: 96.8750 (97.0644)  acc5_10: 100.0000 (99.9053)  time: 0.2561  data: 0.1185  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2668 (0.2680)  acc1: 96.8750 (96.8006)  acc5: 100.0000 (99.7024)  acc1_10: 96.8750 (96.7510)  acc5_10: 100.0000 (99.8016)  time: 0.1288  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2693 (0.2677)  acc1: 96.8750 (96.8582)  acc5: 100.0000 (99.7480)  acc1_10: 96.8750 (96.8750)  acc5_10: 100.0000 (99.8152)  time: 0.1226  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2696 (0.2701)  acc1: 96.8750 (96.7353)  acc5: 100.0000 (99.7332)  acc1_10: 96.3542 (96.7226)  acc5_10: 100.0000 (99.8349)  time: 0.1213  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2716 (0.2692)  acc1: 96.8750 (96.7729)  acc5: 100.0000 (99.7651)  acc1_10: 96.3542 (96.7320)  acc5_10: 100.0000 (99.8366)  time: 0.1188  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2683 (0.2678)  acc1: 96.8750 (96.7900)  acc5: 100.0000 (99.7700)  acc1_10: 96.3542 (96.7300)  acc5_10: 100.0000 (99.8400)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1497 s / it)
* Acc@1 96.790 Acc@5 99.770 loss 0.268
classifiers_10 : Acc@1 96.730 Acc@5 99.840
Accuracy of the network on the 10000 test images: 96.8%
## Using lr  0.0000675 for BACKBONE, cosine lr = 0.0012550 for PRUNER
Epoch: [50]  [  0/390]  eta: 0:11:01  lr: 0.000068  loss: 2.3256 (2.3256)  time: 1.6965  data: 1.3695  max mem: 14473
Epoch: [50]  [ 10/390]  eta: 0:02:34  lr: 0.000068  loss: 2.3256 (2.3853)  time: 0.4069  data: 0.1247  max mem: 14473
Epoch: [50]  [ 20/390]  eta: 0:02:07  lr: 0.000068  loss: 2.8017 (2.5127)  time: 0.2778  data: 0.0003  max mem: 14473
Epoch: [50]  [ 30/390]  eta: 0:01:56  lr: 0.000068  loss: 2.5931 (2.5384)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [50]  [ 40/390]  eta: 0:01:48  lr: 0.000068  loss: 2.7774 (2.5816)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [50]  [ 50/390]  eta: 0:01:43  lr: 0.000068  loss: 2.7774 (2.5882)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [50]  [ 60/390]  eta: 0:01:38  lr: 0.000068  loss: 2.6303 (2.5860)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [50]  [ 70/390]  eta: 0:01:34  lr: 0.000068  loss: 2.7515 (2.6481)  time: 0.2724  data: 0.0002  max mem: 14473
Epoch: [50]  [ 80/390]  eta: 0:01:30  lr: 0.000068  loss: 2.8837 (2.6661)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [50]  [ 90/390]  eta: 0:01:27  lr: 0.000068  loss: 2.7078 (2.6436)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [50]  [100/390]  eta: 0:01:23  lr: 0.000068  loss: 2.4981 (2.6345)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [50]  [110/390]  eta: 0:01:20  lr: 0.000068  loss: 2.7071 (2.6416)  time: 0.2768  data: 0.0003  max mem: 14473
Epoch: [50]  [120/390]  eta: 0:01:17  lr: 0.000068  loss: 2.7856 (2.6409)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [50]  [130/390]  eta: 0:01:14  lr: 0.000068  loss: 2.7739 (2.6424)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [50]  [140/390]  eta: 0:01:11  lr: 0.000068  loss: 2.7144 (2.6392)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [50]  [150/390]  eta: 0:01:08  lr: 0.000068  loss: 2.4976 (2.6186)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [50]  [160/390]  eta: 0:01:05  lr: 0.000068  loss: 2.4422 (2.6127)  time: 0.2820  data: 0.0003  max mem: 14473
Epoch: [50]  [170/390]  eta: 0:01:02  lr: 0.000068  loss: 2.3673 (2.5958)  time: 0.2801  data: 0.0003  max mem: 14473
Epoch: [50]  [180/390]  eta: 0:00:59  lr: 0.000068  loss: 2.3812 (2.5857)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [50]  [190/390]  eta: 0:00:56  lr: 0.000068  loss: 2.6492 (2.5917)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [50]  [200/390]  eta: 0:00:53  lr: 0.000068  loss: 2.9105 (2.5976)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [50]  [210/390]  eta: 0:00:50  lr: 0.000068  loss: 2.8598 (2.5997)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [50]  [220/390]  eta: 0:00:47  lr: 0.000068  loss: 2.6790 (2.5993)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [50]  [230/390]  eta: 0:00:45  lr: 0.000068  loss: 2.7067 (2.6130)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [50]  [240/390]  eta: 0:00:42  lr: 0.000068  loss: 2.8574 (2.6130)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [50]  [250/390]  eta: 0:00:39  lr: 0.000068  loss: 2.7356 (2.6099)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [50]  [260/390]  eta: 0:00:36  lr: 0.000068  loss: 2.7670 (2.6110)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [50]  [270/390]  eta: 0:00:33  lr: 0.000068  loss: 2.8946 (2.6138)  time: 0.2721  data: 0.0003  max mem: 14473
Epoch: [50]  [280/390]  eta: 0:00:30  lr: 0.000068  loss: 2.4974 (2.6074)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [50]  [290/390]  eta: 0:00:28  lr: 0.000068  loss: 2.4549 (2.6086)  time: 0.2772  data: 0.0003  max mem: 14473
Epoch: [50]  [300/390]  eta: 0:00:25  lr: 0.000068  loss: 2.7883 (2.6082)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [50]  [310/390]  eta: 0:00:22  lr: 0.000068  loss: 2.6345 (2.6025)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [50]  [320/390]  eta: 0:00:19  lr: 0.000068  loss: 2.5956 (2.6010)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [50]  [330/390]  eta: 0:00:16  lr: 0.000068  loss: 2.6589 (2.5976)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [50]  [340/390]  eta: 0:00:13  lr: 0.000068  loss: 2.7261 (2.6000)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [50]  [350/390]  eta: 0:00:11  lr: 0.000068  loss: 2.5907 (2.5955)  time: 0.2779  data: 0.0003  max mem: 14473
Epoch: [50]  [360/390]  eta: 0:00:08  lr: 0.000068  loss: 2.5841 (2.5990)  time: 0.2774  data: 0.0003  max mem: 14473
Epoch: [50]  [370/390]  eta: 0:00:05  lr: 0.000068  loss: 2.6506 (2.5991)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [50]  [380/390]  eta: 0:00:02  lr: 0.000068  loss: 2.6856 (2.6023)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [50]  [389/390]  eta: 0:00:00  lr: 0.000068  loss: 2.8486 (2.6071)  time: 0.2733  data: 0.0001  max mem: 14473
Epoch: [50] Total time: 0:01:48 (0.2792 s / it)
Averaged stats: lr: 0.000068  loss: 2.8486 (2.6071)
Test:  [ 0/53]  eta: 0:00:58  loss: 0.2641 (0.2641)  acc1: 95.8333 (95.8333)  acc5: 99.4792 (99.4792)  acc1_10: 95.8333 (95.8333)  acc5_10: 99.4792 (99.4792)  time: 1.1123  data: 0.9611  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2368 (0.2365)  acc1: 97.3958 (97.3011)  acc5: 100.0000 (99.8106)  acc1_10: 97.3958 (97.0170)  acc5_10: 100.0000 (99.8580)  time: 0.2522  data: 0.1189  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2440 (0.2468)  acc1: 96.8750 (96.9494)  acc5: 100.0000 (99.8016)  acc1_10: 96.8750 (96.8750)  acc5_10: 100.0000 (99.8264)  time: 0.1442  data: 0.0175  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2524 (0.2500)  acc1: 96.8750 (96.9254)  acc5: 99.4792 (99.7144)  acc1_10: 96.8750 (96.7238)  acc5_10: 100.0000 (99.7984)  time: 0.1215  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2412 (0.2522)  acc1: 96.8750 (96.8623)  acc5: 99.4792 (99.6570)  acc1_10: 96.8750 (96.7734)  acc5_10: 100.0000 (99.7840)  time: 0.1198  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2469 (0.2518)  acc1: 96.8750 (96.8342)  acc5: 99.4792 (99.6936)  acc1_10: 96.3542 (96.7116)  acc5_10: 100.0000 (99.8060)  time: 0.1187  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2469 (0.2496)  acc1: 96.3542 (96.8300)  acc5: 100.0000 (99.7000)  acc1_10: 96.3542 (96.7100)  acc5_10: 100.0000 (99.8100)  time: 0.1143  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1481 s / it)
* Acc@1 96.830 Acc@5 99.700 loss 0.250
classifiers_10 : Acc@1 96.710 Acc@5 99.810
Accuracy of the network on the 10000 test images: 96.8%
## Using lr  0.0000657 for BACKBONE, cosine lr = 0.0012159 for PRUNER
Epoch: [51]  [  0/390]  eta: 0:11:31  lr: 0.000066  loss: 2.3917 (2.3917)  time: 1.7727  data: 1.4875  max mem: 14473
Epoch: [51]  [ 10/390]  eta: 0:02:41  lr: 0.000066  loss: 2.6402 (2.6434)  time: 0.4239  data: 0.1355  max mem: 14473
Epoch: [51]  [ 20/390]  eta: 0:02:10  lr: 0.000066  loss: 2.5691 (2.5099)  time: 0.2826  data: 0.0003  max mem: 14473
Epoch: [51]  [ 30/390]  eta: 0:01:57  lr: 0.000066  loss: 2.5787 (2.5909)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [51]  [ 40/390]  eta: 0:01:50  lr: 0.000066  loss: 2.7855 (2.6188)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [51]  [ 50/390]  eta: 0:01:44  lr: 0.000066  loss: 2.7895 (2.6748)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [51]  [ 60/390]  eta: 0:01:39  lr: 0.000066  loss: 2.7019 (2.6476)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [51]  [ 70/390]  eta: 0:01:35  lr: 0.000066  loss: 2.5606 (2.6311)  time: 0.2735  data: 0.0002  max mem: 14473
Epoch: [51]  [ 80/390]  eta: 0:01:31  lr: 0.000066  loss: 2.6540 (2.6421)  time: 0.2754  data: 0.0002  max mem: 14473
Epoch: [51]  [ 90/390]  eta: 0:01:27  lr: 0.000066  loss: 2.5548 (2.6283)  time: 0.2746  data: 0.0002  max mem: 14473
Epoch: [51]  [100/390]  eta: 0:01:24  lr: 0.000066  loss: 2.6211 (2.6234)  time: 0.2749  data: 0.0002  max mem: 14473
Epoch: [51]  [110/390]  eta: 0:01:21  lr: 0.000066  loss: 2.4963 (2.6135)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [51]  [120/390]  eta: 0:01:17  lr: 0.000066  loss: 2.4916 (2.6001)  time: 0.2730  data: 0.0002  max mem: 14473
Epoch: [51]  [130/390]  eta: 0:01:14  lr: 0.000066  loss: 2.7145 (2.6156)  time: 0.2735  data: 0.0002  max mem: 14473
Epoch: [51]  [140/390]  eta: 0:01:11  lr: 0.000066  loss: 2.8081 (2.6180)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [51]  [150/390]  eta: 0:01:08  lr: 0.000066  loss: 2.9210 (2.6357)  time: 0.2803  data: 0.0003  max mem: 14473
Epoch: [51]  [160/390]  eta: 0:01:05  lr: 0.000066  loss: 2.9210 (2.6439)  time: 0.2791  data: 0.0003  max mem: 14473
Epoch: [51]  [170/390]  eta: 0:01:02  lr: 0.000066  loss: 2.7737 (2.6341)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [51]  [180/390]  eta: 0:00:59  lr: 0.000066  loss: 2.7655 (2.6434)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [51]  [190/390]  eta: 0:00:56  lr: 0.000066  loss: 2.8356 (2.6501)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [51]  [200/390]  eta: 0:00:53  lr: 0.000066  loss: 2.6111 (2.6454)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [51]  [210/390]  eta: 0:00:50  lr: 0.000066  loss: 2.8191 (2.6591)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [51]  [220/390]  eta: 0:00:48  lr: 0.000066  loss: 2.8048 (2.6515)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [51]  [230/390]  eta: 0:00:45  lr: 0.000066  loss: 2.3626 (2.6364)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [51]  [240/390]  eta: 0:00:42  lr: 0.000066  loss: 2.6587 (2.6347)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [51]  [250/390]  eta: 0:00:39  lr: 0.000066  loss: 2.6879 (2.6335)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [51]  [260/390]  eta: 0:00:36  lr: 0.000066  loss: 2.5012 (2.6283)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [51]  [270/390]  eta: 0:00:33  lr: 0.000066  loss: 2.5720 (2.6310)  time: 0.2753  data: 0.0002  max mem: 14473
Epoch: [51]  [280/390]  eta: 0:00:30  lr: 0.000066  loss: 2.7564 (2.6274)  time: 0.2756  data: 0.0002  max mem: 14473
Epoch: [51]  [290/390]  eta: 0:00:28  lr: 0.000066  loss: 2.3951 (2.6194)  time: 0.2772  data: 0.0003  max mem: 14473
Epoch: [51]  [300/390]  eta: 0:00:25  lr: 0.000066  loss: 2.3577 (2.6127)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [51]  [310/390]  eta: 0:00:22  lr: 0.000066  loss: 2.4737 (2.6149)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [51]  [320/390]  eta: 0:00:19  lr: 0.000066  loss: 2.5644 (2.6103)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [51]  [330/390]  eta: 0:00:16  lr: 0.000066  loss: 2.7020 (2.6140)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [51]  [340/390]  eta: 0:00:13  lr: 0.000066  loss: 2.7944 (2.6130)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [51]  [350/390]  eta: 0:00:11  lr: 0.000066  loss: 2.7944 (2.6154)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [51]  [360/390]  eta: 0:00:08  lr: 0.000066  loss: 2.7685 (2.6145)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [51]  [370/390]  eta: 0:00:05  lr: 0.000066  loss: 2.5895 (2.6076)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [51]  [380/390]  eta: 0:00:02  lr: 0.000066  loss: 2.3735 (2.6082)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [51]  [389/390]  eta: 0:00:00  lr: 0.000066  loss: 2.7844 (2.6113)  time: 0.2749  data: 0.0001  max mem: 14473
Epoch: [51] Total time: 0:01:49 (0.2796 s / it)
Averaged stats: lr: 0.000066  loss: 2.7844 (2.6113)
Test:  [ 0/53]  eta: 0:00:59  loss: 0.2452 (0.2452)  acc1: 97.3958 (97.3958)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.1296  data: 0.9738  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2452 (0.2513)  acc1: 97.3958 (97.3958)  acc5: 100.0000 (99.8106)  acc1_10: 97.3958 (97.1591)  acc5_10: 100.0000 (99.8106)  time: 0.2492  data: 0.1160  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2688 (0.2630)  acc1: 96.8750 (97.1478)  acc5: 100.0000 (99.7768)  acc1_10: 96.8750 (96.9246)  acc5_10: 100.0000 (99.7768)  time: 0.1432  data: 0.0152  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2617 (0.2634)  acc1: 96.8750 (97.0934)  acc5: 100.0000 (99.7648)  acc1_10: 96.3542 (96.8750)  acc5_10: 100.0000 (99.7984)  time: 0.1235  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2570 (0.2663)  acc1: 96.8750 (96.9893)  acc5: 100.0000 (99.7332)  acc1_10: 96.8750 (96.8115)  acc5_10: 100.0000 (99.7967)  time: 0.1209  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2621 (0.2645)  acc1: 96.8750 (97.0078)  acc5: 100.0000 (99.7549)  acc1_10: 96.8750 (96.8444)  acc5_10: 100.0000 (99.8162)  time: 0.1193  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2577 (0.2625)  acc1: 97.3958 (97.0200)  acc5: 100.0000 (99.7600)  acc1_10: 96.8750 (96.8400)  acc5_10: 100.0000 (99.8200)  time: 0.1148  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1485 s / it)
* Acc@1 97.020 Acc@5 99.760 loss 0.262
classifiers_10 : Acc@1 96.840 Acc@5 99.820
Accuracy of the network on the 10000 test images: 97.0%
## Using lr  0.0000639 for BACKBONE, cosine lr = 0.0011768 for PRUNER
Epoch: [52]  [  0/390]  eta: 0:09:08  lr: 0.000064  loss: 2.9940 (2.9940)  time: 1.4068  data: 1.0758  max mem: 14473
Epoch: [52]  [ 10/390]  eta: 0:02:25  lr: 0.000064  loss: 2.8313 (2.6533)  time: 0.3836  data: 0.0981  max mem: 14473
Epoch: [52]  [ 20/390]  eta: 0:02:02  lr: 0.000064  loss: 2.8203 (2.6485)  time: 0.2766  data: 0.0003  max mem: 14473
Epoch: [52]  [ 30/390]  eta: 0:01:52  lr: 0.000064  loss: 2.7673 (2.6213)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [52]  [ 40/390]  eta: 0:01:45  lr: 0.000064  loss: 2.7834 (2.6453)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [52]  [ 50/390]  eta: 0:01:40  lr: 0.000064  loss: 2.7752 (2.6369)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [52]  [ 60/390]  eta: 0:01:36  lr: 0.000064  loss: 2.7071 (2.6722)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [52]  [ 70/390]  eta: 0:01:32  lr: 0.000064  loss: 2.4388 (2.6266)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [52]  [ 80/390]  eta: 0:01:29  lr: 0.000064  loss: 2.2601 (2.5904)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [52]  [ 90/390]  eta: 0:01:25  lr: 0.000064  loss: 2.5476 (2.6149)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [52]  [100/390]  eta: 0:01:22  lr: 0.000064  loss: 2.8001 (2.6157)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [52]  [110/390]  eta: 0:01:19  lr: 0.000064  loss: 2.7799 (2.6181)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [52]  [120/390]  eta: 0:01:16  lr: 0.000064  loss: 2.3644 (2.6122)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [52]  [130/390]  eta: 0:01:13  lr: 0.000064  loss: 2.3602 (2.5958)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [52]  [140/390]  eta: 0:01:10  lr: 0.000064  loss: 2.7049 (2.6050)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [52]  [150/390]  eta: 0:01:07  lr: 0.000064  loss: 2.8581 (2.6177)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [52]  [160/390]  eta: 0:01:04  lr: 0.000064  loss: 2.6772 (2.6058)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [52]  [170/390]  eta: 0:01:01  lr: 0.000064  loss: 2.5035 (2.6000)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [52]  [180/390]  eta: 0:00:58  lr: 0.000064  loss: 2.6772 (2.6079)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [52]  [190/390]  eta: 0:00:56  lr: 0.000064  loss: 2.7133 (2.6082)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [52]  [200/390]  eta: 0:00:53  lr: 0.000064  loss: 2.7644 (2.6138)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [52]  [210/390]  eta: 0:00:50  lr: 0.000064  loss: 2.8335 (2.6165)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [52]  [220/390]  eta: 0:00:47  lr: 0.000064  loss: 2.3675 (2.6081)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [52]  [230/390]  eta: 0:00:44  lr: 0.000064  loss: 2.7133 (2.6136)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [52]  [240/390]  eta: 0:00:41  lr: 0.000064  loss: 2.7679 (2.6156)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [52]  [250/390]  eta: 0:00:38  lr: 0.000064  loss: 2.7163 (2.6128)  time: 0.2721  data: 0.0003  max mem: 14473
Epoch: [52]  [260/390]  eta: 0:00:36  lr: 0.000064  loss: 2.7250 (2.6210)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [52]  [270/390]  eta: 0:00:33  lr: 0.000064  loss: 2.6754 (2.6182)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [52]  [280/390]  eta: 0:00:30  lr: 0.000064  loss: 2.4607 (2.6122)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [52]  [290/390]  eta: 0:00:27  lr: 0.000064  loss: 2.8057 (2.6213)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [52]  [300/390]  eta: 0:00:24  lr: 0.000064  loss: 2.8083 (2.6195)  time: 0.2721  data: 0.0003  max mem: 14473
Epoch: [52]  [310/390]  eta: 0:00:22  lr: 0.000064  loss: 2.8083 (2.6261)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [52]  [320/390]  eta: 0:00:19  lr: 0.000064  loss: 2.9382 (2.6297)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [52]  [330/390]  eta: 0:00:16  lr: 0.000064  loss: 2.8392 (2.6307)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [52]  [340/390]  eta: 0:00:13  lr: 0.000064  loss: 2.7758 (2.6364)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [52]  [350/390]  eta: 0:00:11  lr: 0.000064  loss: 2.8320 (2.6350)  time: 0.2776  data: 0.0003  max mem: 14473
Epoch: [52]  [360/390]  eta: 0:00:08  lr: 0.000064  loss: 2.6060 (2.6294)  time: 0.2761  data: 0.0002  max mem: 14473
Epoch: [52]  [370/390]  eta: 0:00:05  lr: 0.000064  loss: 2.6887 (2.6338)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [52]  [380/390]  eta: 0:00:02  lr: 0.000064  loss: 2.7970 (2.6340)  time: 0.2717  data: 0.0002  max mem: 14473
Epoch: [52]  [389/390]  eta: 0:00:00  lr: 0.000064  loss: 2.6887 (2.6345)  time: 0.2757  data: 0.0001  max mem: 14473
Epoch: [52] Total time: 0:01:48 (0.2774 s / it)
Averaged stats: lr: 0.000064  loss: 2.6887 (2.6345)
Test:  [ 0/53]  eta: 0:01:00  loss: 0.2711 (0.2711)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.1370  data: 1.0023  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2684 (0.2675)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (99.9527)  acc1_10: 96.3542 (96.6383)  acc5_10: 100.0000 (99.9527)  time: 0.2342  data: 0.1010  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2747 (0.2749)  acc1: 96.8750 (96.8006)  acc5: 100.0000 (99.7768)  acc1_10: 96.3542 (96.4534)  acc5_10: 100.0000 (99.8016)  time: 0.1354  data: 0.0056  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2723 (0.2771)  acc1: 96.3542 (96.5894)  acc5: 100.0000 (99.7648)  acc1_10: 95.8333 (96.4550)  acc5_10: 100.0000 (99.8152)  time: 0.1240  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:01  loss: 0.2693 (0.2765)  acc1: 96.3542 (96.6082)  acc5: 100.0000 (99.7332)  acc1_10: 96.8750 (96.5066)  acc5_10: 100.0000 (99.7967)  time: 0.1205  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2745 (0.2781)  acc1: 96.3542 (96.5993)  acc5: 100.0000 (99.7549)  acc1_10: 96.3542 (96.5074)  acc5_10: 100.0000 (99.8162)  time: 0.1190  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2705 (0.2762)  acc1: 96.3542 (96.6200)  acc5: 100.0000 (99.7600)  acc1_10: 96.3542 (96.5200)  acc5_10: 100.0000 (99.8100)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1454 s / it)
* Acc@1 96.620 Acc@5 99.760 loss 0.276
classifiers_10 : Acc@1 96.520 Acc@5 99.810
Accuracy of the network on the 10000 test images: 96.6%
## Using lr  0.0000621 for BACKBONE, cosine lr = 0.0011378 for PRUNER
Epoch: [53]  [  0/390]  eta: 0:11:33  lr: 0.000062  loss: 2.8519 (2.8519)  time: 1.7790  data: 1.4509  max mem: 14473
Epoch: [53]  [ 10/390]  eta: 0:02:38  lr: 0.000062  loss: 2.6324 (2.5205)  time: 0.4165  data: 0.1321  max mem: 14473
Epoch: [53]  [ 20/390]  eta: 0:02:08  lr: 0.000062  loss: 2.4626 (2.5126)  time: 0.2760  data: 0.0002  max mem: 14473
Epoch: [53]  [ 30/390]  eta: 0:01:56  lr: 0.000062  loss: 2.7178 (2.6129)  time: 0.2719  data: 0.0002  max mem: 14473
Epoch: [53]  [ 40/390]  eta: 0:01:48  lr: 0.000062  loss: 2.8851 (2.6259)  time: 0.2734  data: 0.0002  max mem: 14473
Epoch: [53]  [ 50/390]  eta: 0:01:43  lr: 0.000062  loss: 2.7125 (2.6235)  time: 0.2745  data: 0.0002  max mem: 14473
Epoch: [53]  [ 60/390]  eta: 0:01:38  lr: 0.000062  loss: 2.5242 (2.5972)  time: 0.2751  data: 0.0002  max mem: 14473
Epoch: [53]  [ 70/390]  eta: 0:01:34  lr: 0.000062  loss: 2.4974 (2.5771)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [53]  [ 80/390]  eta: 0:01:30  lr: 0.000062  loss: 2.8043 (2.6029)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [53]  [ 90/390]  eta: 0:01:27  lr: 0.000062  loss: 2.8426 (2.6019)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [53]  [100/390]  eta: 0:01:23  lr: 0.000062  loss: 2.7750 (2.6068)  time: 0.2744  data: 0.0002  max mem: 14473
Epoch: [53]  [110/390]  eta: 0:01:21  lr: 0.000062  loss: 2.8180 (2.6100)  time: 0.2841  data: 0.0002  max mem: 14473
Epoch: [53]  [120/390]  eta: 0:01:17  lr: 0.000062  loss: 2.7996 (2.6108)  time: 0.2826  data: 0.0003  max mem: 14473
Epoch: [53]  [130/390]  eta: 0:01:14  lr: 0.000062  loss: 2.7201 (2.5953)  time: 0.2738  data: 0.0003  max mem: 14473
Epoch: [53]  [140/390]  eta: 0:01:11  lr: 0.000062  loss: 2.7452 (2.5964)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [53]  [150/390]  eta: 0:01:08  lr: 0.000062  loss: 2.8500 (2.6095)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [53]  [160/390]  eta: 0:01:05  lr: 0.000062  loss: 2.7985 (2.6072)  time: 0.2772  data: 0.0002  max mem: 14473
Epoch: [53]  [170/390]  eta: 0:01:02  lr: 0.000062  loss: 2.8620 (2.6190)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [53]  [180/390]  eta: 0:00:59  lr: 0.000062  loss: 2.7851 (2.6110)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [53]  [190/390]  eta: 0:00:56  lr: 0.000062  loss: 2.5571 (2.6032)  time: 0.2773  data: 0.0002  max mem: 14473
Epoch: [53]  [200/390]  eta: 0:00:53  lr: 0.000062  loss: 2.5571 (2.5949)  time: 0.2790  data: 0.0002  max mem: 14473
Epoch: [53]  [210/390]  eta: 0:00:50  lr: 0.000062  loss: 2.8340 (2.5978)  time: 0.2759  data: 0.0002  max mem: 14473
Epoch: [53]  [220/390]  eta: 0:00:48  lr: 0.000062  loss: 2.7100 (2.5933)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [53]  [230/390]  eta: 0:00:45  lr: 0.000062  loss: 2.4849 (2.5969)  time: 0.2773  data: 0.0003  max mem: 14473
Epoch: [53]  [240/390]  eta: 0:00:42  lr: 0.000062  loss: 2.4235 (2.5906)  time: 0.2773  data: 0.0003  max mem: 14473
Epoch: [53]  [250/390]  eta: 0:00:39  lr: 0.000062  loss: 2.5693 (2.5931)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [53]  [260/390]  eta: 0:00:36  lr: 0.000062  loss: 2.8008 (2.5933)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [53]  [270/390]  eta: 0:00:33  lr: 0.000062  loss: 2.6400 (2.5865)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [53]  [280/390]  eta: 0:00:30  lr: 0.000062  loss: 2.5502 (2.5865)  time: 0.2746  data: 0.0002  max mem: 14473
Epoch: [53]  [290/390]  eta: 0:00:28  lr: 0.000062  loss: 2.7885 (2.5885)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [53]  [300/390]  eta: 0:00:25  lr: 0.000062  loss: 2.7484 (2.5881)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [53]  [310/390]  eta: 0:00:22  lr: 0.000062  loss: 2.6991 (2.5813)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [53]  [320/390]  eta: 0:00:19  lr: 0.000062  loss: 2.4638 (2.5809)  time: 0.2725  data: 0.0002  max mem: 14473
Epoch: [53]  [330/390]  eta: 0:00:16  lr: 0.000062  loss: 2.6634 (2.5851)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [53]  [340/390]  eta: 0:00:13  lr: 0.000062  loss: 2.7682 (2.5912)  time: 0.2728  data: 0.0002  max mem: 14473
Epoch: [53]  [350/390]  eta: 0:00:11  lr: 0.000062  loss: 2.5543 (2.5805)  time: 0.2723  data: 0.0002  max mem: 14473
Epoch: [53]  [360/390]  eta: 0:00:08  lr: 0.000062  loss: 2.2999 (2.5809)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [53]  [370/390]  eta: 0:00:05  lr: 0.000062  loss: 2.6933 (2.5798)  time: 0.2741  data: 0.0003  max mem: 14473
Epoch: [53]  [380/390]  eta: 0:00:02  lr: 0.000062  loss: 2.5809 (2.5785)  time: 0.2742  data: 0.0002  max mem: 14473
Epoch: [53]  [389/390]  eta: 0:00:00  lr: 0.000062  loss: 2.6189 (2.5799)  time: 0.2729  data: 0.0001  max mem: 14473
Epoch: [53] Total time: 0:01:48 (0.2794 s / it)
Averaged stats: lr: 0.000062  loss: 2.6189 (2.5799)
Test:  [ 0/53]  eta: 0:01:33  loss: 0.2540 (0.2540)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.7664  data: 1.6083  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2417 (0.2476)  acc1: 97.3958 (97.2538)  acc5: 100.0000 (99.9527)  acc1_10: 96.8750 (96.9224)  acc5_10: 100.0000 (99.9053)  time: 0.2733  data: 0.1464  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2481 (0.2534)  acc1: 97.3958 (97.3214)  acc5: 100.0000 (99.8264)  acc1_10: 96.8750 (96.8502)  acc5_10: 100.0000 (99.8512)  time: 0.1226  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:04  loss: 0.2479 (0.2523)  acc1: 97.3958 (97.3622)  acc5: 100.0000 (99.8488)  acc1_10: 97.3958 (97.0430)  acc5_10: 100.0000 (99.8488)  time: 0.1211  data: 0.0002  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2497 (0.2551)  acc1: 96.8750 (97.2053)  acc5: 100.0000 (99.7967)  acc1_10: 96.8750 (97.0020)  acc5_10: 100.0000 (99.8222)  time: 0.1199  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2587 (0.2559)  acc1: 96.8750 (97.0895)  acc5: 100.0000 (99.8162)  acc1_10: 96.8750 (96.9363)  acc5_10: 100.0000 (99.8468)  time: 0.1192  data: 0.0002  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2587 (0.2541)  acc1: 96.8750 (97.0700)  acc5: 100.0000 (99.8200)  acc1_10: 96.3542 (96.9200)  acc5_10: 100.0000 (99.8500)  time: 0.1147  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1525 s / it)
* Acc@1 97.070 Acc@5 99.820 loss 0.254
classifiers_10 : Acc@1 96.920 Acc@5 99.850
Accuracy of the network on the 10000 test images: 97.1%
## Using lr  0.0000603 for BACKBONE, cosine lr = 0.0010990 for PRUNER
Epoch: [54]  [  0/390]  eta: 0:10:36  lr: 0.000060  loss: 2.8702 (2.8702)  time: 1.6311  data: 1.3074  max mem: 14473
Epoch: [54]  [ 10/390]  eta: 0:02:32  lr: 0.000060  loss: 2.7608 (2.4995)  time: 0.4009  data: 0.1191  max mem: 14473
Epoch: [54]  [ 20/390]  eta: 0:02:05  lr: 0.000060  loss: 2.4185 (2.4227)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [54]  [ 30/390]  eta: 0:01:54  lr: 0.000060  loss: 2.5957 (2.5177)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [54]  [ 40/390]  eta: 0:01:47  lr: 0.000060  loss: 2.7514 (2.5222)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [54]  [ 50/390]  eta: 0:01:42  lr: 0.000060  loss: 2.4803 (2.4901)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [54]  [ 60/390]  eta: 0:01:38  lr: 0.000060  loss: 2.3818 (2.4955)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [54]  [ 70/390]  eta: 0:01:34  lr: 0.000060  loss: 2.5223 (2.5054)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [54]  [ 80/390]  eta: 0:01:30  lr: 0.000060  loss: 2.5200 (2.4992)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [54]  [ 90/390]  eta: 0:01:26  lr: 0.000060  loss: 2.7816 (2.5376)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [54]  [100/390]  eta: 0:01:23  lr: 0.000060  loss: 2.8396 (2.5500)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [54]  [110/390]  eta: 0:01:20  lr: 0.000060  loss: 2.6203 (2.5397)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [54]  [120/390]  eta: 0:01:17  lr: 0.000060  loss: 2.3714 (2.5349)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [54]  [130/390]  eta: 0:01:13  lr: 0.000060  loss: 2.7219 (2.5486)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [54]  [140/390]  eta: 0:01:10  lr: 0.000060  loss: 2.8519 (2.5587)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [54]  [150/390]  eta: 0:01:07  lr: 0.000060  loss: 2.8519 (2.5770)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [54]  [160/390]  eta: 0:01:05  lr: 0.000060  loss: 2.7338 (2.5757)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [54]  [170/390]  eta: 0:01:02  lr: 0.000060  loss: 2.7160 (2.5801)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [54]  [180/390]  eta: 0:00:59  lr: 0.000060  loss: 2.6374 (2.5726)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [54]  [190/390]  eta: 0:00:56  lr: 0.000060  loss: 2.6300 (2.5775)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [54]  [200/390]  eta: 0:00:53  lr: 0.000060  loss: 2.7502 (2.5856)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [54]  [210/390]  eta: 0:00:50  lr: 0.000060  loss: 2.7423 (2.5836)  time: 0.2766  data: 0.0002  max mem: 14473
Epoch: [54]  [220/390]  eta: 0:00:47  lr: 0.000060  loss: 2.7726 (2.5928)  time: 0.2788  data: 0.0002  max mem: 14473
Epoch: [54]  [230/390]  eta: 0:00:44  lr: 0.000060  loss: 2.7852 (2.5853)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [54]  [240/390]  eta: 0:00:42  lr: 0.000060  loss: 2.4738 (2.5811)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [54]  [250/390]  eta: 0:00:39  lr: 0.000060  loss: 2.3151 (2.5612)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [54]  [260/390]  eta: 0:00:36  lr: 0.000060  loss: 2.1112 (2.5523)  time: 0.2719  data: 0.0002  max mem: 14473
Epoch: [54]  [270/390]  eta: 0:00:33  lr: 0.000060  loss: 2.3693 (2.5521)  time: 0.2739  data: 0.0002  max mem: 14473
Epoch: [54]  [280/390]  eta: 0:00:30  lr: 0.000060  loss: 2.7411 (2.5596)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [54]  [290/390]  eta: 0:00:27  lr: 0.000060  loss: 2.7688 (2.5658)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [54]  [300/390]  eta: 0:00:25  lr: 0.000060  loss: 2.7337 (2.5734)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [54]  [310/390]  eta: 0:00:22  lr: 0.000060  loss: 2.7662 (2.5772)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [54]  [320/390]  eta: 0:00:19  lr: 0.000060  loss: 2.7450 (2.5742)  time: 0.2741  data: 0.0002  max mem: 14473
Epoch: [54]  [330/390]  eta: 0:00:16  lr: 0.000060  loss: 2.3986 (2.5728)  time: 0.2726  data: 0.0003  max mem: 14473
Epoch: [54]  [340/390]  eta: 0:00:13  lr: 0.000060  loss: 2.8050 (2.5779)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [54]  [350/390]  eta: 0:00:11  lr: 0.000060  loss: 2.5082 (2.5741)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [54]  [360/390]  eta: 0:00:08  lr: 0.000060  loss: 2.4937 (2.5731)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [54]  [370/390]  eta: 0:00:05  lr: 0.000060  loss: 2.6305 (2.5691)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [54]  [380/390]  eta: 0:00:02  lr: 0.000060  loss: 2.6305 (2.5693)  time: 0.2723  data: 0.0002  max mem: 14473
Epoch: [54]  [389/390]  eta: 0:00:00  lr: 0.000060  loss: 2.5625 (2.5697)  time: 0.2744  data: 0.0001  max mem: 14473
Epoch: [54] Total time: 0:01:48 (0.2780 s / it)
Averaged stats: lr: 0.000060  loss: 2.5625 (2.5697)
Test:  [ 0/53]  eta: 0:01:24  loss: 0.2280 (0.2280)  acc1: 98.4375 (98.4375)  acc5: 100.0000 (100.0000)  acc1_10: 97.9167 (97.9167)  acc5_10: 100.0000 (100.0000)  time: 1.5974  data: 1.4471  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2447 (0.2506)  acc1: 96.8750 (97.3485)  acc5: 100.0000 (99.7159)  acc1_10: 97.9167 (97.4905)  acc5_10: 100.0000 (99.7633)  time: 0.2615  data: 0.1319  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2603 (0.2656)  acc1: 96.8750 (96.9246)  acc5: 99.4792 (99.6528)  acc1_10: 96.3542 (96.8254)  acc5_10: 99.4792 (99.7272)  time: 0.1255  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2603 (0.2650)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (99.7312)  acc1_10: 96.3542 (96.7742)  acc5_10: 100.0000 (99.7816)  time: 0.1220  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2678 (0.2695)  acc1: 96.8750 (96.7353)  acc5: 100.0000 (99.7078)  acc1_10: 96.8750 (96.6336)  acc5_10: 100.0000 (99.7586)  time: 0.1200  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2686 (0.2683)  acc1: 96.8750 (96.7422)  acc5: 100.0000 (99.7651)  acc1_10: 96.8750 (96.7014)  acc5_10: 100.0000 (99.7958)  time: 0.1194  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2554 (0.2660)  acc1: 97.3958 (96.7700)  acc5: 100.0000 (99.7700)  acc1_10: 97.3958 (96.7300)  acc5_10: 100.0000 (99.8000)  time: 0.1149  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1504 s / it)
* Acc@1 96.770 Acc@5 99.770 loss 0.266
classifiers_10 : Acc@1 96.730 Acc@5 99.800
Accuracy of the network on the 10000 test images: 96.8%
## Using lr  0.0000585 for BACKBONE, cosine lr = 0.0010602 for PRUNER
Epoch: [55]  [  0/390]  eta: 0:10:41  lr: 0.000059  loss: 2.9922 (2.9922)  time: 1.6451  data: 1.3205  max mem: 14473
Epoch: [55]  [ 10/390]  eta: 0:02:33  lr: 0.000059  loss: 2.4984 (2.3453)  time: 0.4039  data: 0.1203  max mem: 14473
Epoch: [55]  [ 20/390]  eta: 0:02:06  lr: 0.000059  loss: 2.6168 (2.3642)  time: 0.2768  data: 0.0002  max mem: 14473
Epoch: [55]  [ 30/390]  eta: 0:01:55  lr: 0.000059  loss: 2.6441 (2.4602)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [55]  [ 40/390]  eta: 0:01:48  lr: 0.000059  loss: 2.6226 (2.5039)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [55]  [ 50/390]  eta: 0:01:42  lr: 0.000059  loss: 2.5572 (2.4916)  time: 0.2737  data: 0.0002  max mem: 14473
Epoch: [55]  [ 60/390]  eta: 0:01:38  lr: 0.000059  loss: 2.2751 (2.4637)  time: 0.2729  data: 0.0003  max mem: 14473
Epoch: [55]  [ 70/390]  eta: 0:01:34  lr: 0.000059  loss: 2.5838 (2.4805)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [55]  [ 80/390]  eta: 0:01:30  lr: 0.000059  loss: 2.6794 (2.4943)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [55]  [ 90/390]  eta: 0:01:26  lr: 0.000059  loss: 2.4761 (2.4770)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [55]  [100/390]  eta: 0:01:23  lr: 0.000059  loss: 2.1427 (2.4636)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [55]  [110/390]  eta: 0:01:20  lr: 0.000059  loss: 2.4937 (2.4614)  time: 0.2770  data: 0.0003  max mem: 14473
Epoch: [55]  [120/390]  eta: 0:01:17  lr: 0.000059  loss: 2.6913 (2.4884)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [55]  [130/390]  eta: 0:01:14  lr: 0.000059  loss: 2.7465 (2.5054)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [55]  [140/390]  eta: 0:01:11  lr: 0.000059  loss: 2.7465 (2.5106)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [55]  [150/390]  eta: 0:01:08  lr: 0.000059  loss: 2.4331 (2.4837)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [55]  [160/390]  eta: 0:01:05  lr: 0.000059  loss: 2.0243 (2.4799)  time: 0.2748  data: 0.0002  max mem: 14473
Epoch: [55]  [170/390]  eta: 0:01:02  lr: 0.000059  loss: 2.6799 (2.4850)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [55]  [180/390]  eta: 0:00:59  lr: 0.000059  loss: 2.7075 (2.4918)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [55]  [190/390]  eta: 0:00:56  lr: 0.000059  loss: 2.7582 (2.5027)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [55]  [200/390]  eta: 0:00:53  lr: 0.000059  loss: 2.7327 (2.5067)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [55]  [210/390]  eta: 0:00:50  lr: 0.000059  loss: 2.4182 (2.5045)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [55]  [220/390]  eta: 0:00:47  lr: 0.000059  loss: 2.3548 (2.5097)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [55]  [230/390]  eta: 0:00:44  lr: 0.000059  loss: 2.6169 (2.5189)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [55]  [240/390]  eta: 0:00:42  lr: 0.000059  loss: 2.6402 (2.5220)  time: 0.2738  data: 0.0002  max mem: 14473
Epoch: [55]  [250/390]  eta: 0:00:39  lr: 0.000059  loss: 2.6896 (2.5262)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [55]  [260/390]  eta: 0:00:36  lr: 0.000059  loss: 2.7939 (2.5300)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [55]  [270/390]  eta: 0:00:33  lr: 0.000059  loss: 2.6987 (2.5349)  time: 0.2746  data: 0.0002  max mem: 14473
Epoch: [55]  [280/390]  eta: 0:00:30  lr: 0.000059  loss: 2.7400 (2.5373)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [55]  [290/390]  eta: 0:00:27  lr: 0.000059  loss: 2.8202 (2.5376)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [55]  [300/390]  eta: 0:00:25  lr: 0.000059  loss: 2.6185 (2.5369)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [55]  [310/390]  eta: 0:00:22  lr: 0.000059  loss: 2.8037 (2.5457)  time: 0.2728  data: 0.0003  max mem: 14473
Epoch: [55]  [320/390]  eta: 0:00:19  lr: 0.000059  loss: 2.8700 (2.5491)  time: 0.2725  data: 0.0003  max mem: 14473
Epoch: [55]  [330/390]  eta: 0:00:16  lr: 0.000059  loss: 2.7694 (2.5464)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [55]  [340/390]  eta: 0:00:13  lr: 0.000059  loss: 2.5840 (2.5456)  time: 0.2762  data: 0.0003  max mem: 14473
Epoch: [55]  [350/390]  eta: 0:00:11  lr: 0.000059  loss: 2.7108 (2.5461)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [55]  [360/390]  eta: 0:00:08  lr: 0.000059  loss: 2.7878 (2.5513)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [55]  [370/390]  eta: 0:00:05  lr: 0.000059  loss: 2.8328 (2.5603)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [55]  [380/390]  eta: 0:00:02  lr: 0.000059  loss: 2.8851 (2.5636)  time: 0.2771  data: 0.0002  max mem: 14473
Epoch: [55]  [389/390]  eta: 0:00:00  lr: 0.000059  loss: 2.6909 (2.5589)  time: 0.2750  data: 0.0001  max mem: 14473
Epoch: [55] Total time: 0:01:48 (0.2786 s / it)
Averaged stats: lr: 0.000059  loss: 2.6909 (2.5589)
Test:  [ 0/53]  eta: 0:01:28  loss: 0.2383 (0.2383)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 96.3542 (96.3542)  acc5_10: 100.0000 (100.0000)  time: 1.6668  data: 1.5182  max mem: 14473
Test:  [10/53]  eta: 0:00:11  loss: 0.2292 (0.2328)  acc1: 97.3958 (97.1117)  acc5: 100.0000 (99.8580)  acc1_10: 96.3542 (96.7803)  acc5_10: 100.0000 (99.8580)  time: 0.2677  data: 0.1383  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2316 (0.2412)  acc1: 96.8750 (96.9742)  acc5: 100.0000 (99.8264)  acc1_10: 96.3542 (96.6022)  acc5_10: 100.0000 (99.8016)  time: 0.1247  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2380 (0.2418)  acc1: 96.8750 (96.9590)  acc5: 100.0000 (99.8320)  acc1_10: 96.8750 (96.5894)  acc5_10: 100.0000 (99.8488)  time: 0.1221  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2380 (0.2444)  acc1: 96.8750 (96.9004)  acc5: 100.0000 (99.7840)  acc1_10: 96.8750 (96.6590)  acc5_10: 100.0000 (99.8222)  time: 0.1212  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2434 (0.2432)  acc1: 96.3542 (96.8852)  acc5: 100.0000 (99.8060)  acc1_10: 96.8750 (96.6708)  acc5_10: 100.0000 (99.8570)  time: 0.1192  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2367 (0.2407)  acc1: 97.3958 (96.9000)  acc5: 100.0000 (99.8100)  acc1_10: 96.8750 (96.6900)  acc5_10: 100.0000 (99.8600)  time: 0.1143  data: 0.0001  max mem: 14473
Test: Total time: 0:00:08 (0.1517 s / it)
* Acc@1 96.900 Acc@5 99.810 loss 0.241
classifiers_10 : Acc@1 96.690 Acc@5 99.860
Accuracy of the network on the 10000 test images: 96.9%
## Using lr  0.0000567 for BACKBONE, cosine lr = 0.0010217 for PRUNER
Epoch: [56]  [  0/390]  eta: 0:09:12  lr: 0.000057  loss: 3.1320 (3.1320)  time: 1.4169  data: 1.0885  max mem: 14473
Epoch: [56]  [ 10/390]  eta: 0:02:27  lr: 0.000057  loss: 2.8030 (2.4613)  time: 0.3880  data: 0.0992  max mem: 14473
Epoch: [56]  [ 20/390]  eta: 0:02:03  lr: 0.000057  loss: 2.3675 (2.4403)  time: 0.2796  data: 0.0003  max mem: 14473
Epoch: [56]  [ 30/390]  eta: 0:01:53  lr: 0.000057  loss: 2.6633 (2.5577)  time: 0.2740  data: 0.0002  max mem: 14473
Epoch: [56]  [ 40/390]  eta: 0:01:46  lr: 0.000057  loss: 2.7410 (2.5842)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [56]  [ 50/390]  eta: 0:01:41  lr: 0.000057  loss: 2.5711 (2.5599)  time: 0.2735  data: 0.0003  max mem: 14473
Epoch: [56]  [ 60/390]  eta: 0:01:37  lr: 0.000057  loss: 2.7281 (2.6086)  time: 0.2731  data: 0.0002  max mem: 14473
Epoch: [56]  [ 70/390]  eta: 0:01:33  lr: 0.000057  loss: 2.7281 (2.5679)  time: 0.2755  data: 0.0002  max mem: 14473
Epoch: [56]  [ 80/390]  eta: 0:01:29  lr: 0.000057  loss: 2.6698 (2.5965)  time: 0.2759  data: 0.0002  max mem: 14473
Epoch: [56]  [ 90/390]  eta: 0:01:26  lr: 0.000057  loss: 2.8050 (2.6058)  time: 0.2731  data: 0.0003  max mem: 14473
Epoch: [56]  [100/390]  eta: 0:01:23  lr: 0.000057  loss: 2.6700 (2.6051)  time: 0.2724  data: 0.0003  max mem: 14473
Epoch: [56]  [110/390]  eta: 0:01:19  lr: 0.000057  loss: 2.6291 (2.5916)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [56]  [120/390]  eta: 0:01:16  lr: 0.000057  loss: 2.4063 (2.5899)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [56]  [130/390]  eta: 0:01:13  lr: 0.000057  loss: 2.3777 (2.5778)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [56]  [140/390]  eta: 0:01:10  lr: 0.000057  loss: 2.5134 (2.5932)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [56]  [150/390]  eta: 0:01:07  lr: 0.000057  loss: 2.8807 (2.6022)  time: 0.2777  data: 0.0003  max mem: 14473
Epoch: [56]  [160/390]  eta: 0:01:04  lr: 0.000057  loss: 2.6671 (2.5973)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [56]  [170/390]  eta: 0:01:01  lr: 0.000057  loss: 2.7347 (2.6119)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [56]  [180/390]  eta: 0:00:59  lr: 0.000057  loss: 2.8846 (2.6128)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [56]  [190/390]  eta: 0:00:56  lr: 0.000057  loss: 2.3939 (2.5982)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [56]  [200/390]  eta: 0:00:53  lr: 0.000057  loss: 2.3265 (2.5875)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [56]  [210/390]  eta: 0:00:50  lr: 0.000057  loss: 2.6677 (2.5900)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [56]  [220/390]  eta: 0:00:47  lr: 0.000057  loss: 2.7714 (2.5929)  time: 0.2749  data: 0.0003  max mem: 14473
Epoch: [56]  [230/390]  eta: 0:00:44  lr: 0.000057  loss: 2.7741 (2.6053)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [56]  [240/390]  eta: 0:00:41  lr: 0.000057  loss: 2.7741 (2.5986)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [56]  [250/390]  eta: 0:00:39  lr: 0.000057  loss: 2.2830 (2.5923)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [56]  [260/390]  eta: 0:00:36  lr: 0.000057  loss: 2.3405 (2.5890)  time: 0.2726  data: 0.0002  max mem: 14473
Epoch: [56]  [270/390]  eta: 0:00:33  lr: 0.000057  loss: 2.6545 (2.5918)  time: 0.2752  data: 0.0002  max mem: 14473
Epoch: [56]  [280/390]  eta: 0:00:30  lr: 0.000057  loss: 2.6545 (2.5863)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [56]  [290/390]  eta: 0:00:27  lr: 0.000057  loss: 2.4409 (2.5827)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [56]  [300/390]  eta: 0:00:25  lr: 0.000057  loss: 2.4855 (2.5793)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [56]  [310/390]  eta: 0:00:22  lr: 0.000057  loss: 2.5534 (2.5822)  time: 0.2722  data: 0.0003  max mem: 14473
Epoch: [56]  [320/390]  eta: 0:00:19  lr: 0.000057  loss: 2.7574 (2.5770)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [56]  [330/390]  eta: 0:00:16  lr: 0.000057  loss: 2.8439 (2.5816)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [56]  [340/390]  eta: 0:00:13  lr: 0.000057  loss: 2.9217 (2.5847)  time: 0.2750  data: 0.0002  max mem: 14473
Epoch: [56]  [350/390]  eta: 0:00:11  lr: 0.000057  loss: 2.7243 (2.5817)  time: 0.2743  data: 0.0002  max mem: 14473
Epoch: [56]  [360/390]  eta: 0:00:08  lr: 0.000057  loss: 2.6267 (2.5771)  time: 0.2733  data: 0.0003  max mem: 14473
Epoch: [56]  [370/390]  eta: 0:00:05  lr: 0.000057  loss: 2.8204 (2.5788)  time: 0.2763  data: 0.0003  max mem: 14473
Epoch: [56]  [380/390]  eta: 0:00:02  lr: 0.000057  loss: 2.8204 (2.5787)  time: 0.2764  data: 0.0002  max mem: 14473
Epoch: [56]  [389/390]  eta: 0:00:00  lr: 0.000057  loss: 2.7185 (2.5804)  time: 0.2729  data: 0.0001  max mem: 14473
Epoch: [56] Total time: 0:01:48 (0.2779 s / it)
Averaged stats: lr: 0.000057  loss: 2.7185 (2.5804)
Test:  [ 0/53]  eta: 0:01:00  loss: 0.2694 (0.2694)  acc1: 96.3542 (96.3542)  acc5: 100.0000 (100.0000)  acc1_10: 95.8333 (95.8333)  acc5_10: 100.0000 (100.0000)  time: 1.1502  data: 1.0135  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2648 (0.2619)  acc1: 96.8750 (96.9224)  acc5: 100.0000 (99.8580)  acc1_10: 96.3542 (96.7803)  acc5_10: 100.0000 (99.9053)  time: 0.2369  data: 0.1021  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2736 (0.2746)  acc1: 96.3542 (96.5774)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.5278)  acc5_10: 100.0000 (99.8512)  time: 0.1366  data: 0.0056  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2777 (0.2729)  acc1: 96.3542 (96.6230)  acc5: 100.0000 (99.7984)  acc1_10: 95.8333 (96.4886)  acc5_10: 100.0000 (99.8488)  time: 0.1254  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2736 (0.2758)  acc1: 96.3542 (96.4812)  acc5: 100.0000 (99.7840)  acc1_10: 96.8750 (96.4558)  acc5_10: 100.0000 (99.8349)  time: 0.1214  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2743 (0.2753)  acc1: 96.3542 (96.4767)  acc5: 100.0000 (99.8264)  acc1_10: 96.8750 (96.4767)  acc5_10: 100.0000 (99.8570)  time: 0.1193  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2736 (0.2731)  acc1: 96.3542 (96.5200)  acc5: 100.0000 (99.8300)  acc1_10: 96.8750 (96.5200)  acc5_10: 100.0000 (99.8600)  time: 0.1145  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1466 s / it)
* Acc@1 96.520 Acc@5 99.830 loss 0.273
classifiers_10 : Acc@1 96.520 Acc@5 99.860
Accuracy of the network on the 10000 test images: 96.5%
## Using lr  0.0000550 for BACKBONE, cosine lr = 0.0009834 for PRUNER
Epoch: [57]  [  0/390]  eta: 0:10:48  lr: 0.000055  loss: 1.9509 (1.9509)  time: 1.6618  data: 1.3345  max mem: 14473
Epoch: [57]  [ 10/390]  eta: 0:02:34  lr: 0.000055  loss: 2.5411 (2.4604)  time: 0.4061  data: 0.1216  max mem: 14473
Epoch: [57]  [ 20/390]  eta: 0:02:07  lr: 0.000055  loss: 2.5802 (2.5701)  time: 0.2785  data: 0.0002  max mem: 14473
Epoch: [57]  [ 30/390]  eta: 0:01:56  lr: 0.000055  loss: 2.7758 (2.6388)  time: 0.2763  data: 0.0002  max mem: 14473
Epoch: [57]  [ 40/390]  eta: 0:01:50  lr: 0.000055  loss: 2.8117 (2.6940)  time: 0.2853  data: 0.0002  max mem: 14473
Epoch: [57]  [ 50/390]  eta: 0:01:44  lr: 0.000055  loss: 2.9168 (2.7349)  time: 0.2864  data: 0.0003  max mem: 14473
Epoch: [57]  [ 60/390]  eta: 0:01:40  lr: 0.000055  loss: 2.7691 (2.6783)  time: 0.2782  data: 0.0003  max mem: 14473
Epoch: [57]  [ 70/390]  eta: 0:01:35  lr: 0.000055  loss: 2.4124 (2.6556)  time: 0.2774  data: 0.0003  max mem: 14473
Epoch: [57]  [ 80/390]  eta: 0:01:32  lr: 0.000055  loss: 2.5116 (2.6424)  time: 0.2777  data: 0.0003  max mem: 14473
Epoch: [57]  [ 90/390]  eta: 0:01:28  lr: 0.000055  loss: 2.6470 (2.6429)  time: 0.2807  data: 0.0003  max mem: 14473
Epoch: [57]  [100/390]  eta: 0:01:25  lr: 0.000055  loss: 2.8276 (2.6652)  time: 0.2777  data: 0.0003  max mem: 14473
Epoch: [57]  [110/390]  eta: 0:01:21  lr: 0.000055  loss: 2.8319 (2.6698)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [57]  [120/390]  eta: 0:01:18  lr: 0.000055  loss: 2.7279 (2.6683)  time: 0.2771  data: 0.0002  max mem: 14473
Epoch: [57]  [130/390]  eta: 0:01:15  lr: 0.000055  loss: 2.5977 (2.6648)  time: 0.2772  data: 0.0003  max mem: 14473
Epoch: [57]  [140/390]  eta: 0:01:12  lr: 0.000055  loss: 2.5794 (2.6567)  time: 0.2759  data: 0.0003  max mem: 14473
Epoch: [57]  [150/390]  eta: 0:01:09  lr: 0.000055  loss: 2.6449 (2.6622)  time: 0.2767  data: 0.0003  max mem: 14473
Epoch: [57]  [160/390]  eta: 0:01:06  lr: 0.000055  loss: 2.7158 (2.6645)  time: 0.2778  data: 0.0003  max mem: 14473
Epoch: [57]  [170/390]  eta: 0:01:03  lr: 0.000055  loss: 2.5788 (2.6599)  time: 0.2796  data: 0.0003  max mem: 14473
Epoch: [57]  [180/390]  eta: 0:01:00  lr: 0.000055  loss: 2.7252 (2.6553)  time: 0.2770  data: 0.0003  max mem: 14473
Epoch: [57]  [190/390]  eta: 0:00:57  lr: 0.000055  loss: 2.7697 (2.6550)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [57]  [200/390]  eta: 0:00:54  lr: 0.000055  loss: 2.7697 (2.6470)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [57]  [210/390]  eta: 0:00:51  lr: 0.000055  loss: 2.7730 (2.6568)  time: 0.2766  data: 0.0002  max mem: 14473
Epoch: [57]  [220/390]  eta: 0:00:48  lr: 0.000055  loss: 2.8903 (2.6599)  time: 0.2822  data: 0.0002  max mem: 14473
Epoch: [57]  [230/390]  eta: 0:00:45  lr: 0.000055  loss: 2.8498 (2.6636)  time: 0.2810  data: 0.0003  max mem: 14473
Epoch: [57]  [240/390]  eta: 0:00:42  lr: 0.000055  loss: 2.7941 (2.6659)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [57]  [250/390]  eta: 0:00:39  lr: 0.000055  loss: 2.7505 (2.6567)  time: 0.2786  data: 0.0003  max mem: 14473
Epoch: [57]  [260/390]  eta: 0:00:36  lr: 0.000055  loss: 2.6875 (2.6499)  time: 0.2787  data: 0.0003  max mem: 14473
Epoch: [57]  [270/390]  eta: 0:00:33  lr: 0.000055  loss: 2.5005 (2.6479)  time: 0.2746  data: 0.0003  max mem: 14473
Epoch: [57]  [280/390]  eta: 0:00:31  lr: 0.000055  loss: 2.7545 (2.6564)  time: 0.2742  data: 0.0003  max mem: 14473
Epoch: [57]  [290/390]  eta: 0:00:28  lr: 0.000055  loss: 2.7840 (2.6612)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [57]  [300/390]  eta: 0:00:25  lr: 0.000055  loss: 2.6983 (2.6597)  time: 0.2760  data: 0.0002  max mem: 14473
Epoch: [57]  [310/390]  eta: 0:00:22  lr: 0.000055  loss: 2.5326 (2.6536)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [57]  [320/390]  eta: 0:00:19  lr: 0.000055  loss: 2.5326 (2.6488)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [57]  [330/390]  eta: 0:00:16  lr: 0.000055  loss: 2.6602 (2.6475)  time: 0.2734  data: 0.0003  max mem: 14473
Epoch: [57]  [340/390]  eta: 0:00:14  lr: 0.000055  loss: 2.4331 (2.6381)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [57]  [350/390]  eta: 0:00:11  lr: 0.000055  loss: 2.6009 (2.6421)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [57]  [360/390]  eta: 0:00:08  lr: 0.000055  loss: 2.6009 (2.6353)  time: 0.2740  data: 0.0003  max mem: 14473
Epoch: [57]  [370/390]  eta: 0:00:05  lr: 0.000055  loss: 2.3798 (2.6299)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [57]  [380/390]  eta: 0:00:02  lr: 0.000055  loss: 2.7809 (2.6322)  time: 0.2722  data: 0.0002  max mem: 14473
Epoch: [57]  [389/390]  eta: 0:00:00  lr: 0.000055  loss: 2.7752 (2.6283)  time: 0.2750  data: 0.0001  max mem: 14473
Epoch: [57] Total time: 0:01:49 (0.2808 s / it)
Averaged stats: lr: 0.000055  loss: 2.7752 (2.6283)
Test:  [ 0/53]  eta: 0:01:12  loss: 0.2676 (0.2676)  acc1: 94.7917 (94.7917)  acc5: 100.0000 (100.0000)  acc1_10: 95.3125 (95.3125)  acc5_10: 100.0000 (100.0000)  time: 1.3635  data: 1.2121  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2676 (0.2660)  acc1: 96.8750 (97.0170)  acc5: 100.0000 (99.7633)  acc1_10: 96.8750 (96.8750)  acc5_10: 100.0000 (99.8106)  time: 0.2481  data: 0.1165  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2652 (0.2719)  acc1: 96.8750 (96.8502)  acc5: 100.0000 (99.7768)  acc1_10: 96.8750 (96.7262)  acc5_10: 100.0000 (99.8016)  time: 0.1300  data: 0.0036  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2646 (0.2726)  acc1: 96.8750 (96.8078)  acc5: 100.0000 (99.7648)  acc1_10: 96.8750 (96.6902)  acc5_10: 100.0000 (99.7648)  time: 0.1223  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2841 (0.2759)  acc1: 96.3542 (96.6463)  acc5: 99.4792 (99.7078)  acc1_10: 96.3542 (96.5320)  acc5_10: 99.4792 (99.6951)  time: 0.1203  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2693 (0.2763)  acc1: 96.3542 (96.6503)  acc5: 100.0000 (99.7345)  acc1_10: 96.3542 (96.5482)  acc5_10: 99.4792 (99.7038)  time: 0.1193  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2654 (0.2745)  acc1: 96.8750 (96.6500)  acc5: 100.0000 (99.7400)  acc1_10: 96.3542 (96.5300)  acc5_10: 100.0000 (99.7100)  time: 0.1151  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1479 s / it)
* Acc@1 96.650 Acc@5 99.740 loss 0.275
classifiers_10 : Acc@1 96.530 Acc@5 99.710
Accuracy of the network on the 10000 test images: 96.7%
## Using lr  0.0000532 for BACKBONE, cosine lr = 0.0009454 for PRUNER
Epoch: [58]  [  0/390]  eta: 0:10:00  lr: 0.000053  loss: 3.0701 (3.0701)  time: 1.5393  data: 1.2148  max mem: 14473
Epoch: [58]  [ 10/390]  eta: 0:02:29  lr: 0.000053  loss: 2.6707 (2.7490)  time: 0.3935  data: 0.1107  max mem: 14473
Epoch: [58]  [ 20/390]  eta: 0:02:05  lr: 0.000053  loss: 2.7675 (2.7614)  time: 0.2790  data: 0.0003  max mem: 14473
Epoch: [58]  [ 30/390]  eta: 0:01:54  lr: 0.000053  loss: 2.7675 (2.6902)  time: 0.2756  data: 0.0002  max mem: 14473
Epoch: [58]  [ 40/390]  eta: 0:01:47  lr: 0.000053  loss: 2.7447 (2.7134)  time: 0.2717  data: 0.0003  max mem: 14473
Epoch: [58]  [ 50/390]  eta: 0:01:41  lr: 0.000053  loss: 2.7156 (2.6542)  time: 0.2727  data: 0.0003  max mem: 14473
Epoch: [58]  [ 60/390]  eta: 0:01:37  lr: 0.000053  loss: 2.4628 (2.6181)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [58]  [ 70/390]  eta: 0:01:33  lr: 0.000053  loss: 2.1490 (2.5315)  time: 0.2765  data: 0.0003  max mem: 14473
Epoch: [58]  [ 80/390]  eta: 0:01:30  lr: 0.000053  loss: 2.1841 (2.5342)  time: 0.2761  data: 0.0003  max mem: 14473
Epoch: [58]  [ 90/390]  eta: 0:01:26  lr: 0.000053  loss: 2.5113 (2.5301)  time: 0.2752  data: 0.0003  max mem: 14473
Epoch: [58]  [100/390]  eta: 0:01:23  lr: 0.000053  loss: 2.7089 (2.5392)  time: 0.2755  data: 0.0003  max mem: 14473
Epoch: [58]  [110/390]  eta: 0:01:20  lr: 0.000053  loss: 2.6603 (2.5361)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [58]  [120/390]  eta: 0:01:17  lr: 0.000053  loss: 2.5432 (2.5331)  time: 0.2744  data: 0.0003  max mem: 14473
Epoch: [58]  [130/390]  eta: 0:01:14  lr: 0.000053  loss: 2.7688 (2.5428)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [58]  [140/390]  eta: 0:01:11  lr: 0.000053  loss: 2.8214 (2.5491)  time: 0.2757  data: 0.0003  max mem: 14473
Epoch: [58]  [150/390]  eta: 0:01:08  lr: 0.000053  loss: 2.6875 (2.5445)  time: 0.2745  data: 0.0003  max mem: 14473
Epoch: [58]  [160/390]  eta: 0:01:05  lr: 0.000053  loss: 2.6875 (2.5496)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [58]  [170/390]  eta: 0:01:02  lr: 0.000053  loss: 2.7394 (2.5584)  time: 0.2732  data: 0.0003  max mem: 14473
Epoch: [58]  [180/390]  eta: 0:00:59  lr: 0.000053  loss: 2.8380 (2.5587)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [58]  [190/390]  eta: 0:00:56  lr: 0.000053  loss: 2.7936 (2.5561)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [58]  [200/390]  eta: 0:00:53  lr: 0.000053  loss: 2.6856 (2.5579)  time: 0.2779  data: 0.0003  max mem: 14473
Epoch: [58]  [210/390]  eta: 0:00:50  lr: 0.000053  loss: 2.3736 (2.5483)  time: 0.2781  data: 0.0003  max mem: 14473
Epoch: [58]  [220/390]  eta: 0:00:47  lr: 0.000053  loss: 2.4116 (2.5498)  time: 0.2747  data: 0.0002  max mem: 14473
Epoch: [58]  [230/390]  eta: 0:00:44  lr: 0.000053  loss: 2.7053 (2.5556)  time: 0.2743  data: 0.0003  max mem: 14473
Epoch: [58]  [240/390]  eta: 0:00:42  lr: 0.000053  loss: 2.8742 (2.5607)  time: 0.2753  data: 0.0003  max mem: 14473
Epoch: [58]  [250/390]  eta: 0:00:39  lr: 0.000053  loss: 2.7832 (2.5578)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [58]  [260/390]  eta: 0:00:36  lr: 0.000053  loss: 2.1449 (2.5443)  time: 0.2758  data: 0.0003  max mem: 14473
Epoch: [58]  [270/390]  eta: 0:00:33  lr: 0.000053  loss: 2.3607 (2.5431)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [58]  [280/390]  eta: 0:00:30  lr: 0.000053  loss: 2.6590 (2.5451)  time: 0.2730  data: 0.0003  max mem: 14473
Epoch: [58]  [290/390]  eta: 0:00:27  lr: 0.000053  loss: 2.8216 (2.5505)  time: 0.2751  data: 0.0003  max mem: 14473
Epoch: [58]  [300/390]  eta: 0:00:25  lr: 0.000053  loss: 2.7278 (2.5558)  time: 0.2772  data: 0.0003  max mem: 14473
Epoch: [58]  [310/390]  eta: 0:00:22  lr: 0.000053  loss: 2.5993 (2.5521)  time: 0.2774  data: 0.0003  max mem: 14473
Epoch: [58]  [320/390]  eta: 0:00:19  lr: 0.000053  loss: 2.6365 (2.5518)  time: 0.2771  data: 0.0003  max mem: 14473
Epoch: [58]  [330/390]  eta: 0:00:16  lr: 0.000053  loss: 2.8379 (2.5551)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [58]  [340/390]  eta: 0:00:13  lr: 0.000053  loss: 2.8379 (2.5611)  time: 0.2739  data: 0.0003  max mem: 14473
Epoch: [58]  [350/390]  eta: 0:00:11  lr: 0.000053  loss: 2.7197 (2.5575)  time: 0.2754  data: 0.0003  max mem: 14473
Epoch: [58]  [360/390]  eta: 0:00:08  lr: 0.000053  loss: 2.4735 (2.5572)  time: 0.2778  data: 0.0003  max mem: 14473
Epoch: [58]  [370/390]  eta: 0:00:05  lr: 0.000053  loss: 2.7866 (2.5576)  time: 0.2760  data: 0.0003  max mem: 14473
Epoch: [58]  [380/390]  eta: 0:00:02  lr: 0.000053  loss: 2.7949 (2.5547)  time: 0.2732  data: 0.0002  max mem: 14473
Epoch: [58]  [389/390]  eta: 0:00:00  lr: 0.000053  loss: 2.7798 (2.5611)  time: 0.2753  data: 0.0001  max mem: 14473
Epoch: [58] Total time: 0:01:48 (0.2789 s / it)
Averaged stats: lr: 0.000053  loss: 2.7798 (2.5611)
Test:  [ 0/53]  eta: 0:01:18  loss: 0.2442 (0.2442)  acc1: 96.8750 (96.8750)  acc5: 100.0000 (100.0000)  acc1_10: 97.3958 (97.3958)  acc5_10: 100.0000 (100.0000)  time: 1.4863  data: 1.3288  max mem: 14473
Test:  [10/53]  eta: 0:00:10  loss: 0.2442 (0.2518)  acc1: 96.8750 (97.2064)  acc5: 100.0000 (99.7159)  acc1_10: 96.8750 (97.0170)  acc5_10: 100.0000 (99.9053)  time: 0.2511  data: 0.1211  max mem: 14473
Test:  [20/53]  eta: 0:00:06  loss: 0.2643 (0.2616)  acc1: 96.8750 (96.7510)  acc5: 100.0000 (99.7520)  acc1_10: 96.3542 (96.6518)  acc5_10: 100.0000 (99.9008)  time: 0.1250  data: 0.0003  max mem: 14473
Test:  [30/53]  eta: 0:00:03  loss: 0.2583 (0.2617)  acc1: 96.8750 (96.7238)  acc5: 100.0000 (99.7648)  acc1_10: 96.3542 (96.6902)  acc5_10: 100.0000 (99.8992)  time: 0.1228  data: 0.0003  max mem: 14473
Test:  [40/53]  eta: 0:00:02  loss: 0.2515 (0.2633)  acc1: 96.3542 (96.6336)  acc5: 100.0000 (99.7840)  acc1_10: 96.8750 (96.6336)  acc5_10: 100.0000 (99.8984)  time: 0.1223  data: 0.0002  max mem: 14473
Test:  [50/53]  eta: 0:00:00  loss: 0.2709 (0.2644)  acc1: 96.3542 (96.5686)  acc5: 100.0000 (99.8162)  acc1_10: 96.3542 (96.5584)  acc5_10: 100.0000 (99.8979)  time: 0.1202  data: 0.0001  max mem: 14473
Test:  [52/53]  eta: 0:00:00  loss: 0.2607 (0.2625)  acc1: 96.3542 (96.5800)  acc5: 100.0000 (99.8200)  acc1_10: 96.3542 (96.5700)  acc5_10: 100.0000 (99.9000)  time: 0.1154  data: 0.0001  max mem: 14473
Test: Total time: 0:00:07 (0.1489 s / it)
* Acc@1 96.580 Acc@5 99.820 loss 0.262
classifiers_10 : Acc@1 96.570 Acc@5 99.900
Accuracy of the network on the 10000 test images: 96.6%
## Using lr  0.0000515 for BACKBONE, cosine lr = 0.0009077 for PRUNER
Epoch: [59]  [  0/390]  eta: 0:11:40  lr: 0.000051  loss: 3.2643 (3.2643)  time: 1.7957  data: 1.4759  max mem: 14473
Epoch: [59]  [ 10/390]  eta: 0:02:38  lr: 0.000051  loss: 2.6032 (2.5605)  time: 0.4166  data: 0.1344  max mem: 14473
Epoch: [59]  [ 20/390]  eta: 0:02:08  lr: 0.000051  loss: 2.5055 (2.4478)  time: 0.2758  data: 0.0002  max mem: 14473
Epoch: [59]  [ 30/390]  eta: 0:01:56  lr: 0.000051  loss: 2.5670 (2.4897)  time: 0.2736  data: 0.0003  max mem: 14473
Epoch: [59]  [ 40/390]  eta: 0:01:49  lr: 0.000051  loss: 2.6380 (2.4747)  time: 0.2770  data: 0.0003  max mem: 14473
Epoch: [59]  [ 50/390]  eta: 0:01:44  lr: 0.000051  loss: 2.2577 (2.4488)  time: 0.2802  data: 0.0003  max mem: 14473
Epoch: [59]  [ 60/390]  eta: 0:01:39  lr: 0.000051  loss: 2.7340 (2.4866)  time: 0.2785  data: 0.0003  max mem: 14473
Epoch: [59]  [ 70/390]  eta: 0:01:35  lr: 0.000051  loss: 2.7340 (2.4717)  time: 0.2746  data: 0.0002  max mem: 14473
Epoch: [59]  [ 80/390]  eta: 0:01:31  lr: 0.000051  loss: 2.5715 (2.4937)  time: 0.2747  data: 0.0003  max mem: 14473
Epoch: [59]  [ 90/390]  eta: 0:01:27  lr: 0.000051  loss: 2.8092 (2.5153)  time: 0.2764  data: 0.0003  max mem: 14473
Epoch: [59]  [100/390]  eta: 0:01:24  lr: 0.000051  loss: 2.6660 (2.5058)  time: 0.2756  data: 0.0003  max mem: 14473
Epoch: [59]  [110/390]  eta: 0:01:21  lr: 0.000051  loss: 2.5913 (2.5085)  time: 0.2750  data: 0.0003  max mem: 14473
Epoch: [59]  [120/390]  eta: 0:01:17  lr: 0.000051  loss: 2.4574 (2.4992)  time: 0.2748  data: 0.0003  max mem: 14473
Epoch: [59]  [130/390]  eta: 0:01:14  lr: 0.000051  loss: 2.5032 (2.5044)  time: 0.2739  data: 0.0003  max mem: 14473